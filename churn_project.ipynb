{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONHknrWRmB0LZW8qi0wv1V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INSTALANDO E ATUALIZANDO ALGUMAS BIBLIOTECAS A SEREM UTILIZADAS**"
      ],
      "metadata": {
        "id": "u2DAOAaqOaat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "id": "4oEMMLfyeb_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall scikit-learn --yes"
      ],
      "metadata": {
        "id": "kF4yx_YAktXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall imblearn --yes"
      ],
      "metadata": {
        "id": "t2OnSq6OlAMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn==1.2.2"
      ],
      "metadata": {
        "id": "DK-pUCBxlDIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imblearn"
      ],
      "metadata": {
        "id": "6gaHXfw7lH0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install boruta"
      ],
      "metadata": {
        "id": "8_vlxt64N0PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "BTbqm2bGfgaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANDO BIBLIOTECAS**"
      ],
      "metadata": {
        "id": "Xwoid6lAaWGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import statistics as st\n",
        "import matplotlib.pyplot as plt\n",
        "from boruta import BorutaPy\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Sequential\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, recall_score, ConfusionMatrixDisplay, classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "44m2eT3AaVtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANDO BASE DE DADOS**"
      ],
      "metadata": {
        "id": "PMEOr7YZaQdJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFeTrcpTZklH",
        "outputId": "79cb2453-86e2-4eba-85a2-9a481b9ca4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID  Churn  Tenure PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
            "0       50001      1     4.0         Mobile Phone         3              6.0   \n",
            "1       50002      1     NaN                Phone         1              8.0   \n",
            "2       50003      1     NaN                Phone         1             30.0   \n",
            "3       50004      1     0.0                Phone         3             15.0   \n",
            "4       50005      1     0.0                Phone         1             12.0   \n",
            "\n",
            "  PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
            "0           Debit Card  Female             3.0                         3   \n",
            "1                  UPI    Male             3.0                         4   \n",
            "2           Debit Card    Male             2.0                         4   \n",
            "3           Debit Card    Male             2.0                         4   \n",
            "4                   CC    Male             NaN                         3   \n",
            "\n",
            "     PreferedOrderCat  SatisfactionScore MaritalStatus  NumberOfAddress  \\\n",
            "0  Laptop & Accessory                  2        Single                9   \n",
            "1              Mobile                  3        Single                7   \n",
            "2              Mobile                  3        Single                6   \n",
            "3  Laptop & Accessory                  5        Single                8   \n",
            "4              Mobile                  5        Single                3   \n",
            "\n",
            "   Complain  OrderAmountHikeFromlastYear  CouponUsed  OrderCount  \\\n",
            "0         1                         11.0         1.0         1.0   \n",
            "1         1                         15.0         0.0         1.0   \n",
            "2         1                         14.0         0.0         1.0   \n",
            "3         0                         23.0         0.0         1.0   \n",
            "4         0                         11.0         1.0         1.0   \n",
            "\n",
            "   DaySinceLastOrder  CashbackAmount  \n",
            "0                5.0          159.93  \n",
            "1                0.0          120.90  \n",
            "2                3.0          120.28  \n",
            "3                3.0          134.07  \n",
            "4                3.0          129.60  \n"
          ]
        }
      ],
      "source": [
        "data = pd.read_excel('e_commerce_dataset.xlsx')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECLUwPjZyQOg",
        "outputId": "8f8ba46a-ce0d-4856-fd3e-de46e55b88b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5630, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para averiguar os valores faltantes na base de dados, tem-se que:"
      ],
      "metadata": {
        "id": "Q9mVrKfbOu-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saY4YobXyYFl",
        "outputId": "c670be33-6df8-45e0-a20d-910d03642693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomerID                       0\n",
            "Churn                            0\n",
            "Tenure                         264\n",
            "PreferredLoginDevice             0\n",
            "CityTier                         0\n",
            "WarehouseToHome                251\n",
            "PreferredPaymentMode             0\n",
            "Gender                           0\n",
            "HourSpendOnApp                 255\n",
            "NumberOfDeviceRegistered         0\n",
            "PreferedOrderCat                 0\n",
            "SatisfactionScore                0\n",
            "MaritalStatus                    0\n",
            "NumberOfAddress                  0\n",
            "Complain                         0\n",
            "OrderAmountHikeFromlastYear    265\n",
            "CouponUsed                     256\n",
            "OrderCount                     258\n",
            "DaySinceLastOrder              307\n",
            "CashbackAmount                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao se trabalhar com dados faltantes em análises de dados, tem-se as seguintes hipóteses:\n",
        "\n",
        "*   Caso a quantidade de dados faltantes sejam inferiores à 5%, é permitida a remoção das linhas que contém os dados incompletos;\n",
        "*   Caso a quantidade de dados faltantes estejam entre 5% e 10%, recomenda-se a aplicação do processo de imputação simples, o qual visa completar as lacunas ausentes com a média, mediana ou moda da coluna pertencente ao valor inexistente.\n",
        "\n",
        "\n",
        "Desse modo, é importante saber quantos dados correspondem à 5% e 10% dentro do dataframe a ser trabalhado. Logo:\n"
      ],
      "metadata": {
        "id": "1z1e_fCRPo66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   5% dos valores do dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "RN4fZxRYTobR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantity_5pc = 0.05*(data.shape[0])\n",
        "\n",
        "print (f'5% de valores nulos: {quantity_5pc:.0f} dados.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sadGJPAmTzXN",
        "outputId": "399170ea-a056-4c1a-b3fc-8c22e8ee0441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5% de valores nulos: 282 dados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   10% dos valores do dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "1z9wt-5tT3Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantity_10pc = 0.1*(data.shape[0])\n",
        "\n",
        "print (f'10% de valores nulos: {quantity_10pc:.0f} dados.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHMhXuVIysy6",
        "outputId": "c543bfb4-17da-4d1a-88c7-bd7b131304e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10% de valores nulos: 563 dados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se todas as colunas com ítens faltantes possuíssem, no máximo, 282 valores nulos, seria viável a exclusão dessas linhas. Entretanto, observou-se que a coluna \"DaySinceLastOrder\" possui 307 valores faltante, tornando mais coerente a aplicação do método de imputação simples."
      ],
      "metadata": {
        "id": "tcCRRYvG15aD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MÉTODO DE IMPUTAÇÃO SIMPLES**"
      ],
      "metadata": {
        "id": "dFzTMHOZabCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse tópico, será realizado o método de imputação simples para a correção dos dados faltantes a partir da inserção da mediana das colunas onde tais lacunas estão presentes. Logo, antes da imputação, tem-se que:"
      ],
      "metadata": {
        "id": "xT-gj2FcSr5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "t-ls9xyETOk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ba0565-d076-409c-f264-96e4431dc574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      CustomerID  Churn  Tenure PreferredLoginDevice  CityTier  \\\n",
            "0          50001      1     4.0         Mobile Phone         3   \n",
            "1          50002      1     NaN                Phone         1   \n",
            "2          50003      1     NaN                Phone         1   \n",
            "3          50004      1     0.0                Phone         3   \n",
            "4          50005      1     0.0                Phone         1   \n",
            "...          ...    ...     ...                  ...       ...   \n",
            "5625       55626      0    10.0             Computer         1   \n",
            "5626       55627      0    13.0         Mobile Phone         1   \n",
            "5627       55628      0     1.0         Mobile Phone         1   \n",
            "5628       55629      0    23.0             Computer         3   \n",
            "5629       55630      0     8.0         Mobile Phone         1   \n",
            "\n",
            "      WarehouseToHome PreferredPaymentMode  Gender  HourSpendOnApp  \\\n",
            "0                 6.0           Debit Card  Female             3.0   \n",
            "1                 8.0                  UPI    Male             3.0   \n",
            "2                30.0           Debit Card    Male             2.0   \n",
            "3                15.0           Debit Card    Male             2.0   \n",
            "4                12.0                   CC    Male             NaN   \n",
            "...               ...                  ...     ...             ...   \n",
            "5625             30.0          Credit Card    Male             3.0   \n",
            "5626             13.0          Credit Card    Male             3.0   \n",
            "5627             11.0           Debit Card    Male             3.0   \n",
            "5628              9.0          Credit Card    Male             4.0   \n",
            "5629             15.0          Credit Card    Male             3.0   \n",
            "\n",
            "      NumberOfDeviceRegistered    PreferedOrderCat  SatisfactionScore  \\\n",
            "0                            3  Laptop & Accessory                  2   \n",
            "1                            4              Mobile                  3   \n",
            "2                            4              Mobile                  3   \n",
            "3                            4  Laptop & Accessory                  5   \n",
            "4                            3              Mobile                  5   \n",
            "...                        ...                 ...                ...   \n",
            "5625                         2  Laptop & Accessory                  1   \n",
            "5626                         5             Fashion                  5   \n",
            "5627                         2  Laptop & Accessory                  4   \n",
            "5628                         5  Laptop & Accessory                  4   \n",
            "5629                         2  Laptop & Accessory                  3   \n",
            "\n",
            "     MaritalStatus  NumberOfAddress  Complain  OrderAmountHikeFromlastYear  \\\n",
            "0           Single                9         1                         11.0   \n",
            "1           Single                7         1                         15.0   \n",
            "2           Single                6         1                         14.0   \n",
            "3           Single                8         0                         23.0   \n",
            "4           Single                3         0                         11.0   \n",
            "...            ...              ...       ...                          ...   \n",
            "5625       Married                6         0                         18.0   \n",
            "5626       Married                6         0                         16.0   \n",
            "5627       Married                3         1                         21.0   \n",
            "5628       Married                4         0                         15.0   \n",
            "5629       Married                4         0                         13.0   \n",
            "\n",
            "      CouponUsed  OrderCount  DaySinceLastOrder  CashbackAmount  \n",
            "0            1.0         1.0                5.0          159.93  \n",
            "1            0.0         1.0                0.0          120.90  \n",
            "2            0.0         1.0                3.0          120.28  \n",
            "3            0.0         1.0                3.0          134.07  \n",
            "4            1.0         1.0                3.0          129.60  \n",
            "...          ...         ...                ...             ...  \n",
            "5625         1.0         2.0                4.0          150.71  \n",
            "5626         1.0         2.0                NaN          224.91  \n",
            "5627         1.0         2.0                4.0          186.42  \n",
            "5628         2.0         2.0                9.0          178.90  \n",
            "5629         2.0         2.0                3.0          169.04  \n",
            "\n",
            "[5630 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando-se o método de imputação simples:"
      ],
      "metadata": {
        "id": "thBMCdnZx42B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "\n",
        "Tenure = data['Tenure'].values.reshape(-1, 1)\n",
        "\n",
        "WarehouseToHome = data['WarehouseToHome'].values.reshape(-1, 1)\n",
        "\n",
        "HourSpendOnApp = data['HourSpendOnApp'].values.reshape(-1, 1)\n",
        "\n",
        "OrderAmountHikeFromlastYear = data['OrderAmountHikeFromlastYear'].values.reshape(-1, 1)\n",
        "\n",
        "CouponUsed = data['CouponUsed'].values.reshape(-1, 1)\n",
        "\n",
        "OrderCount = data['OrderCount'].values.reshape(-1, 1)\n",
        "\n",
        "DaySinceLastOrder = data['DaySinceLastOrder'].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "Tenure_imputed = imputer.fit_transform(Tenure)\n",
        "\n",
        "WarehouseToHome_imputed = imputer.fit_transform(WarehouseToHome)\n",
        "\n",
        "HourSpendOnApp_imputed = imputer.fit_transform(HourSpendOnApp)\n",
        "\n",
        "OrderAmountHikeFromlastYear_imputed = imputer.fit_transform(OrderAmountHikeFromlastYear)\n",
        "\n",
        "CouponUsed_imputed = imputer.fit_transform(CouponUsed)\n",
        "\n",
        "OrderCount_imputed = imputer.fit_transform(OrderCount)\n",
        "\n",
        "DaySinceLastOrder_imputed = imputer.fit_transform(DaySinceLastOrder)\n",
        "\n",
        "\n",
        "data['Tenure'] = Tenure_imputed\n",
        "\n",
        "data['WarehouseToHome'] = WarehouseToHome_imputed\n",
        "\n",
        "data['HourSpendOnApp'] = HourSpendOnApp_imputed\n",
        "\n",
        "data['OrderAmountHikeFromlastYear'] = OrderAmountHikeFromlastYear_imputed\n",
        "\n",
        "data['CouponUsed'] = CouponUsed_imputed\n",
        "\n",
        "data['OrderCount'] = OrderCount_imputed\n",
        "\n",
        "data['DaySinceLastOrder'] = DaySinceLastOrder_imputed"
      ],
      "metadata": {
        "id": "t7gvUk_ZafcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a imputação, tem-se os seguintes resultados:"
      ],
      "metadata": {
        "id": "82B2zn1xTQkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFjsm8dA7eld",
        "outputId": "b36c5beb-873d-4d59-efdc-633cac0cbad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      CustomerID  Churn  Tenure PreferredLoginDevice  CityTier  \\\n",
            "0          50001      1     4.0         Mobile Phone         3   \n",
            "1          50002      1     9.0                Phone         1   \n",
            "2          50003      1     9.0                Phone         1   \n",
            "3          50004      1     0.0                Phone         3   \n",
            "4          50005      1     0.0                Phone         1   \n",
            "...          ...    ...     ...                  ...       ...   \n",
            "5625       55626      0    10.0             Computer         1   \n",
            "5626       55627      0    13.0         Mobile Phone         1   \n",
            "5627       55628      0     1.0         Mobile Phone         1   \n",
            "5628       55629      0    23.0             Computer         3   \n",
            "5629       55630      0     8.0         Mobile Phone         1   \n",
            "\n",
            "      WarehouseToHome PreferredPaymentMode  Gender  HourSpendOnApp  \\\n",
            "0                 6.0           Debit Card  Female             3.0   \n",
            "1                 8.0                  UPI    Male             3.0   \n",
            "2                30.0           Debit Card    Male             2.0   \n",
            "3                15.0           Debit Card    Male             2.0   \n",
            "4                12.0                   CC    Male             3.0   \n",
            "...               ...                  ...     ...             ...   \n",
            "5625             30.0          Credit Card    Male             3.0   \n",
            "5626             13.0          Credit Card    Male             3.0   \n",
            "5627             11.0           Debit Card    Male             3.0   \n",
            "5628              9.0          Credit Card    Male             4.0   \n",
            "5629             15.0          Credit Card    Male             3.0   \n",
            "\n",
            "      NumberOfDeviceRegistered    PreferedOrderCat  SatisfactionScore  \\\n",
            "0                            3  Laptop & Accessory                  2   \n",
            "1                            4              Mobile                  3   \n",
            "2                            4              Mobile                  3   \n",
            "3                            4  Laptop & Accessory                  5   \n",
            "4                            3              Mobile                  5   \n",
            "...                        ...                 ...                ...   \n",
            "5625                         2  Laptop & Accessory                  1   \n",
            "5626                         5             Fashion                  5   \n",
            "5627                         2  Laptop & Accessory                  4   \n",
            "5628                         5  Laptop & Accessory                  4   \n",
            "5629                         2  Laptop & Accessory                  3   \n",
            "\n",
            "     MaritalStatus  NumberOfAddress  Complain  OrderAmountHikeFromlastYear  \\\n",
            "0           Single                9         1                         11.0   \n",
            "1           Single                7         1                         15.0   \n",
            "2           Single                6         1                         14.0   \n",
            "3           Single                8         0                         23.0   \n",
            "4           Single                3         0                         11.0   \n",
            "...            ...              ...       ...                          ...   \n",
            "5625       Married                6         0                         18.0   \n",
            "5626       Married                6         0                         16.0   \n",
            "5627       Married                3         1                         21.0   \n",
            "5628       Married                4         0                         15.0   \n",
            "5629       Married                4         0                         13.0   \n",
            "\n",
            "      CouponUsed  OrderCount  DaySinceLastOrder  CashbackAmount  \n",
            "0            1.0         1.0                5.0          159.93  \n",
            "1            0.0         1.0                0.0          120.90  \n",
            "2            0.0         1.0                3.0          120.28  \n",
            "3            0.0         1.0                3.0          134.07  \n",
            "4            1.0         1.0                3.0          129.60  \n",
            "...          ...         ...                ...             ...  \n",
            "5625         1.0         2.0                4.0          150.71  \n",
            "5626         1.0         2.0                3.0          224.91  \n",
            "5627         1.0         2.0                4.0          186.42  \n",
            "5628         2.0         2.0                9.0          178.90  \n",
            "5629         2.0         2.0                3.0          169.04  \n",
            "\n",
            "[5630 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para confirmar a inexistência dos dados faltantes após a imputação:"
      ],
      "metadata": {
        "id": "vAdkXH0OTZwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_post_treatment = data.isnull().sum()\n",
        "print(missing_values_post_treatment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-VJBp0Z7heu",
        "outputId": "49398d17-b702-4e68-aa8d-46205d20339d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomerID                     0\n",
            "Churn                          0\n",
            "Tenure                         0\n",
            "PreferredLoginDevice           0\n",
            "CityTier                       0\n",
            "WarehouseToHome                0\n",
            "PreferredPaymentMode           0\n",
            "Gender                         0\n",
            "HourSpendOnApp                 0\n",
            "NumberOfDeviceRegistered       0\n",
            "PreferedOrderCat               0\n",
            "SatisfactionScore              0\n",
            "MaritalStatus                  0\n",
            "NumberOfAddress                0\n",
            "Complain                       0\n",
            "OrderAmountHikeFromlastYear    0\n",
            "CouponUsed                     0\n",
            "OrderCount                     0\n",
            "DaySinceLastOrder              0\n",
            "CashbackAmount                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, para se avaliar a presença de \"IDs\" duplicados (para evitar informações duplicadas), tem-se que:"
      ],
      "metadata": {
        "id": "Y50YsLsEU6rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['CustomerID'].duplicated().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hOhjkuq8RH-",
        "outputId": "9dd0eec1-8b15-460f-8bb9-1fcdc213ee2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logo, não há linhas duplicadas no conjunto de dados."
      ],
      "metadata": {
        "id": "56R440fyyHS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ELIMINANDO A COLUNA \"CustomerID\", VISTO QUE ELA NÃO POSSUI IMPACTO NA ETAPA DE PREDIÇÃO (SERVE APENAS PARA IDENTIFICAÇÃO)**"
      ],
      "metadata": {
        "id": "rhzadRq_dPkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(\"CustomerID\", axis = 1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "b-Zm3xf8fET2",
        "outputId": "dead4bf2-14fe-45c3-8be9-56dcccc06ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Churn  Tenure PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
              "0         1     4.0         Mobile Phone         3              6.0   \n",
              "1         1     9.0                Phone         1              8.0   \n",
              "2         1     9.0                Phone         1             30.0   \n",
              "3         1     0.0                Phone         3             15.0   \n",
              "4         1     0.0                Phone         1             12.0   \n",
              "...     ...     ...                  ...       ...              ...   \n",
              "5625      0    10.0             Computer         1             30.0   \n",
              "5626      0    13.0         Mobile Phone         1             13.0   \n",
              "5627      0     1.0         Mobile Phone         1             11.0   \n",
              "5628      0    23.0             Computer         3              9.0   \n",
              "5629      0     8.0         Mobile Phone         1             15.0   \n",
              "\n",
              "     PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
              "0              Debit Card  Female             3.0                         3   \n",
              "1                     UPI    Male             3.0                         4   \n",
              "2              Debit Card    Male             2.0                         4   \n",
              "3              Debit Card    Male             2.0                         4   \n",
              "4                      CC    Male             3.0                         3   \n",
              "...                   ...     ...             ...                       ...   \n",
              "5625          Credit Card    Male             3.0                         2   \n",
              "5626          Credit Card    Male             3.0                         5   \n",
              "5627           Debit Card    Male             3.0                         2   \n",
              "5628          Credit Card    Male             4.0                         5   \n",
              "5629          Credit Card    Male             3.0                         2   \n",
              "\n",
              "        PreferedOrderCat  SatisfactionScore MaritalStatus  NumberOfAddress  \\\n",
              "0     Laptop & Accessory                  2        Single                9   \n",
              "1                 Mobile                  3        Single                7   \n",
              "2                 Mobile                  3        Single                6   \n",
              "3     Laptop & Accessory                  5        Single                8   \n",
              "4                 Mobile                  5        Single                3   \n",
              "...                  ...                ...           ...              ...   \n",
              "5625  Laptop & Accessory                  1       Married                6   \n",
              "5626             Fashion                  5       Married                6   \n",
              "5627  Laptop & Accessory                  4       Married                3   \n",
              "5628  Laptop & Accessory                  4       Married                4   \n",
              "5629  Laptop & Accessory                  3       Married                4   \n",
              "\n",
              "      Complain  OrderAmountHikeFromlastYear  CouponUsed  OrderCount  \\\n",
              "0            1                         11.0         1.0         1.0   \n",
              "1            1                         15.0         0.0         1.0   \n",
              "2            1                         14.0         0.0         1.0   \n",
              "3            0                         23.0         0.0         1.0   \n",
              "4            0                         11.0         1.0         1.0   \n",
              "...        ...                          ...         ...         ...   \n",
              "5625         0                         18.0         1.0         2.0   \n",
              "5626         0                         16.0         1.0         2.0   \n",
              "5627         1                         21.0         1.0         2.0   \n",
              "5628         0                         15.0         2.0         2.0   \n",
              "5629         0                         13.0         2.0         2.0   \n",
              "\n",
              "      DaySinceLastOrder  CashbackAmount  \n",
              "0                   5.0          159.93  \n",
              "1                   0.0          120.90  \n",
              "2                   3.0          120.28  \n",
              "3                   3.0          134.07  \n",
              "4                   3.0          129.60  \n",
              "...                 ...             ...  \n",
              "5625                4.0          150.71  \n",
              "5626                3.0          224.91  \n",
              "5627                4.0          186.42  \n",
              "5628                9.0          178.90  \n",
              "5629                3.0          169.04  \n",
              "\n",
              "[5630 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03858f79-a213-4770-9d86-827d7b3c660d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Churn</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>PreferredLoginDevice</th>\n",
              "      <th>CityTier</th>\n",
              "      <th>WarehouseToHome</th>\n",
              "      <th>PreferredPaymentMode</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourSpendOnApp</th>\n",
              "      <th>NumberOfDeviceRegistered</th>\n",
              "      <th>PreferedOrderCat</th>\n",
              "      <th>SatisfactionScore</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>NumberOfAddress</th>\n",
              "      <th>Complain</th>\n",
              "      <th>OrderAmountHikeFromlastYear</th>\n",
              "      <th>CouponUsed</th>\n",
              "      <th>OrderCount</th>\n",
              "      <th>DaySinceLastOrder</th>\n",
              "      <th>CashbackAmount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Mobile Phone</td>\n",
              "      <td>3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Debit Card</td>\n",
              "      <td>Female</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Laptop &amp; Accessory</td>\n",
              "      <td>2</td>\n",
              "      <td>Single</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>159.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Phone</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>UPI</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>3</td>\n",
              "      <td>Single</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Phone</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Debit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>3</td>\n",
              "      <td>Single</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>120.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Phone</td>\n",
              "      <td>3</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Debit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Laptop &amp; Accessory</td>\n",
              "      <td>5</td>\n",
              "      <td>Single</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>134.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Phone</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>CC</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mobile</td>\n",
              "      <td>5</td>\n",
              "      <td>Single</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>129.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5625</th>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Computer</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Laptop &amp; Accessory</td>\n",
              "      <td>1</td>\n",
              "      <td>Married</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>150.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5626</th>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Mobile Phone</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>Fashion</td>\n",
              "      <td>5</td>\n",
              "      <td>Married</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>224.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5627</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Mobile Phone</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Debit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Laptop &amp; Accessory</td>\n",
              "      <td>4</td>\n",
              "      <td>Married</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>186.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5628</th>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>Computer</td>\n",
              "      <td>3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>Laptop &amp; Accessory</td>\n",
              "      <td>4</td>\n",
              "      <td>Married</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>178.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5629</th>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Mobile Phone</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Laptop &amp; Accessory</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5630 rows × 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03858f79-a213-4770-9d86-827d7b3c660d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03858f79-a213-4770-9d86-827d7b3c660d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03858f79-a213-4770-9d86-827d7b3c660d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b2a8c08-f641-4058-9b50-ef6e419e50c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b2a8c08-f641-4058-9b50-ef6e419e50c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b2a8c08-f641-4058-9b50-ef6e419e50c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3ac6d7fc-2abb-48b8-95ae-200b811f20ce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3ac6d7fc-2abb-48b8-95ae-200b811f20ce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5630,\n  \"fields\": [\n    {\n      \"column\": \"Churn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.357951166584485,\n        \"min\": 0.0,\n        \"max\": 61.0,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          61.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreferredLoginDevice\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Mobile Phone\",\n          \"Phone\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CityTier\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WarehouseToHome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.345961296394036,\n        \"min\": 5.0,\n        \"max\": 127.0,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          14.0,\n          23.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreferredPaymentMode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Debit Card\",\n          \"UPI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Male\",\n          \"Female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HourSpendOnApp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7055280039478681,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumberOfDeviceRegistered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreferedOrderCat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Laptop & Accessory\",\n          \"Mobile\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SatisfactionScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MaritalStatus\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Single\",\n          \"Divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumberOfAddress\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          5,\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Complain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OrderAmountHikeFromlastYear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5910576608583926,\n        \"min\": 11.0,\n        \"max\": 26.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          11.0,\n          15.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CouponUsed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.857639777461501,\n        \"min\": 0.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OrderCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8792477181293767,\n        \"min\": 1.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DaySinceLastOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.570625540419597,\n        \"min\": 0.0,\n        \"max\": 46.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          5.0,\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CashbackAmount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.20703617486409,\n        \"min\": 0.0,\n        \"max\": 324.99,\n        \"num_unique_values\": 2586,\n        \"samples\": [\n          125.19,\n          137.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DIVIDINDO AS VARIÁVEIS DE ENTRADA E SAÍDA**"
      ],
      "metadata": {
        "id": "CMPO8OM4hcad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.iloc[:,0]\n",
        "x = data.iloc[:,1:]"
      ],
      "metadata": {
        "id": "flyatgbehj5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRANSFORMANDO DADOS CATEGÓRICOS EM NUMÉRICOS - LABEL ENCODER**"
      ],
      "metadata": {
        "id": "xzcYywlzsXtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tendo em vista que o algoritmo BorutaPy utilizado mais adiante será baseado em árvores de decisões, é mais viável utilizar o encoder categórico Label Encoder para evitar a esparsidade do banco de dados, o que prejudicaria a predição do modelo. Logo:"
      ],
      "metadata": {
        "id": "43KyBYnHy3jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_encode = [\"PreferredLoginDevice\", \"PreferredPaymentMode\", \"Gender\", \"PreferedOrderCat\", \"MaritalStatus\"]"
      ],
      "metadata": {
        "id": "h2DO7FwIzW4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "iz7Jh0llzbzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_le = x"
      ],
      "metadata": {
        "id": "MhZ6bxYJzjQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns_to_encode:\n",
        "\n",
        "    x_le[column] = encoder.fit_transform(x_le[column])"
      ],
      "metadata": {
        "id": "nMtMoTqDzdg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_le"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "e7t7I2lKzst-",
        "outputId": "e6b7f9ff-7250-4166-e49f-e33922c01a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Tenure  PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
              "0        4.0                     1         3              6.0   \n",
              "1        9.0                     2         1              8.0   \n",
              "2        9.0                     2         1             30.0   \n",
              "3        0.0                     2         3             15.0   \n",
              "4        0.0                     2         1             12.0   \n",
              "...      ...                   ...       ...              ...   \n",
              "5625    10.0                     0         1             30.0   \n",
              "5626    13.0                     1         1             13.0   \n",
              "5627     1.0                     1         1             11.0   \n",
              "5628    23.0                     0         3              9.0   \n",
              "5629     8.0                     1         1             15.0   \n",
              "\n",
              "      PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
              "0                        4       0             3.0                         3   \n",
              "1                        6       1             3.0                         4   \n",
              "2                        4       1             2.0                         4   \n",
              "3                        4       1             2.0                         4   \n",
              "4                        0       1             3.0                         3   \n",
              "...                    ...     ...             ...                       ...   \n",
              "5625                     3       1             3.0                         2   \n",
              "5626                     3       1             3.0                         5   \n",
              "5627                     4       1             3.0                         2   \n",
              "5628                     3       1             4.0                         5   \n",
              "5629                     3       1             3.0                         2   \n",
              "\n",
              "      PreferedOrderCat  SatisfactionScore  MaritalStatus  NumberOfAddress  \\\n",
              "0                    2                  2              2                9   \n",
              "1                    3                  3              2                7   \n",
              "2                    3                  3              2                6   \n",
              "3                    2                  5              2                8   \n",
              "4                    3                  5              2                3   \n",
              "...                ...                ...            ...              ...   \n",
              "5625                 2                  1              1                6   \n",
              "5626                 0                  5              1                6   \n",
              "5627                 2                  4              1                3   \n",
              "5628                 2                  4              1                4   \n",
              "5629                 2                  3              1                4   \n",
              "\n",
              "      Complain  OrderAmountHikeFromlastYear  CouponUsed  OrderCount  \\\n",
              "0            1                         11.0         1.0         1.0   \n",
              "1            1                         15.0         0.0         1.0   \n",
              "2            1                         14.0         0.0         1.0   \n",
              "3            0                         23.0         0.0         1.0   \n",
              "4            0                         11.0         1.0         1.0   \n",
              "...        ...                          ...         ...         ...   \n",
              "5625         0                         18.0         1.0         2.0   \n",
              "5626         0                         16.0         1.0         2.0   \n",
              "5627         1                         21.0         1.0         2.0   \n",
              "5628         0                         15.0         2.0         2.0   \n",
              "5629         0                         13.0         2.0         2.0   \n",
              "\n",
              "      DaySinceLastOrder  CashbackAmount  \n",
              "0                   5.0          159.93  \n",
              "1                   0.0          120.90  \n",
              "2                   3.0          120.28  \n",
              "3                   3.0          134.07  \n",
              "4                   3.0          129.60  \n",
              "...                 ...             ...  \n",
              "5625                4.0          150.71  \n",
              "5626                3.0          224.91  \n",
              "5627                4.0          186.42  \n",
              "5628                9.0          178.90  \n",
              "5629                3.0          169.04  \n",
              "\n",
              "[5630 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bbf2d2e-fc6f-43f8-a1f6-7ff0c14ef4ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tenure</th>\n",
              "      <th>PreferredLoginDevice</th>\n",
              "      <th>CityTier</th>\n",
              "      <th>WarehouseToHome</th>\n",
              "      <th>PreferredPaymentMode</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourSpendOnApp</th>\n",
              "      <th>NumberOfDeviceRegistered</th>\n",
              "      <th>PreferedOrderCat</th>\n",
              "      <th>SatisfactionScore</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>NumberOfAddress</th>\n",
              "      <th>Complain</th>\n",
              "      <th>OrderAmountHikeFromlastYear</th>\n",
              "      <th>CouponUsed</th>\n",
              "      <th>OrderCount</th>\n",
              "      <th>DaySinceLastOrder</th>\n",
              "      <th>CashbackAmount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>159.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>120.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>134.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>129.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5625</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>150.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5626</th>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>224.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5627</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>186.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5628</th>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>178.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5629</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>169.04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5630 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bbf2d2e-fc6f-43f8-a1f6-7ff0c14ef4ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4bbf2d2e-fc6f-43f8-a1f6-7ff0c14ef4ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4bbf2d2e-fc6f-43f8-a1f6-7ff0c14ef4ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5fcab46-642d-4c4f-b6e7-e9835dd91954\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5fcab46-642d-4c4f-b6e7-e9835dd91954')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5fcab46-642d-4c4f-b6e7-e9835dd91954 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_caa57686-647b-445c-a600-56ea9e5ec2ee\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_caa57686-647b-445c-a600-56ea9e5ec2ee button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x",
              "summary": "{\n  \"name\": \"x\",\n  \"rows\": 5630,\n  \"fields\": [\n    {\n      \"column\": \"Tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.357951166584485,\n        \"min\": 0.0,\n        \"max\": 61.0,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          61.0,\n          1.0,\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreferredLoginDevice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CityTier\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WarehouseToHome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.345961296394036,\n        \"min\": 5.0,\n        \"max\": 127.0,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          14.0,\n          23.0,\n          34.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreferredPaymentMode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HourSpendOnApp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7055280039478681,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumberOfDeviceRegistered\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PreferedOrderCat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SatisfactionScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MaritalStatus\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumberOfAddress\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          5,\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Complain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OrderAmountHikeFromlastYear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5910576608583926,\n        \"min\": 11.0,\n        \"max\": 26.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          11.0,\n          15.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CouponUsed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.857639777461501,\n        \"min\": 0.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OrderCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8792477181293767,\n        \"min\": 1.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DaySinceLastOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.570625540419597,\n        \"min\": 0.0,\n        \"max\": 46.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          5.0,\n          13.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CashbackAmount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.20703617486409,\n        \"min\": 0.0,\n        \"max\": 324.99,\n        \"num_unique_values\": 2586,\n        \"samples\": [\n          125.19,\n          137.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SELECIONANDO FEATURES - BORUTAPY**"
      ],
      "metadata": {
        "id": "ZVQk5Tb3t8iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BorutaPy é uma implementação em Python do algoritmo Boruta, usado para seleção de variáveis em modelos de aprendizado de máquina. Ele serve para identificar quais características de um conjunto de dados são mais relevantes para a predição, eliminando aquelas que são irrelevantes ou redundantes. O BorutaPy realiza múltiplas iterações de treinamento de um modelo com árvores de decisão, avaliando a importância de cada característica em comparação com variáveis artificiais. É útil para melhorar a eficiência e a interpretabilidade dos modelos."
      ],
      "metadata": {
        "id": "Pzz4OpQR0SRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando o BorutaPy, tem-se que:"
      ],
      "metadata": {
        "id": "BNDXCA7j1FX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "YBN_26gNuC0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boruta_selector = BorutaPy(estimator=rf, n_estimators='auto', verbose=2, random_state=42)"
      ],
      "metadata": {
        "id": "so7T9c8luQMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_le1 = x_le.values"
      ],
      "metadata": {
        "id": "QnIut1nz2HUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Para evitar problemas de compatibilidade para os diversos tipos de variáveis no BorutaPy\n",
        "\n",
        "np.int = np.int32\n",
        "np.float = np.float64\n",
        "np.bool = np.bool_"
      ],
      "metadata": {
        "id": "vdIlXcUY1z_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boruta_selector.fit(x_le1, y)"
      ],
      "metadata": {
        "id": "lLrIUP9TuQDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2064
        },
        "outputId": "d1df4a26-89a3-46dd-e4c2-7121de14b9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: \t1 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 100\n",
            "Confirmed: \t0\n",
            "Tentative: \t18\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t3\n",
            "Rejected: \t9\n",
            "Iteration: \t9 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t3\n",
            "Rejected: \t9\n",
            "Iteration: \t10 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t3\n",
            "Rejected: \t9\n",
            "Iteration: \t11 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t3\n",
            "Rejected: \t9\n",
            "Iteration: \t12 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t13 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t14 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t15 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t16 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t17 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t18 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t19 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t20 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t21 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t22 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t23 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t24 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t25 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t1\n",
            "Rejected: \t11\n",
            "Iteration: \t26 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t0\n",
            "Rejected: \t12\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t27 / 100\n",
            "Confirmed: \t6\n",
            "Tentative: \t0\n",
            "Rejected: \t12\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BorutaPy(estimator=RandomForestClassifier(n_estimators=37,\n",
              "                                          random_state=RandomState(MT19937) at 0x7F8898DAF740),\n",
              "         n_estimators='auto',\n",
              "         random_state=RandomState(MT19937) at 0x7F8898DAF740, verbose=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(n_estimators=37,\n",
              "                                          random_state=RandomState(MT19937) at 0x7F8898DAF740),\n",
              "         n_estimators=&#x27;auto&#x27;,\n",
              "         random_state=RandomState(MT19937) at 0x7F8898DAF740, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=RandomForestClassifier(n_estimators=37,\n",
              "                                          random_state=RandomState(MT19937) at 0x7F8898DAF740),\n",
              "         n_estimators=&#x27;auto&#x27;,\n",
              "         random_state=RandomState(MT19937) at 0x7F8898DAF740, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=37,\n",
              "                       random_state=RandomState(MT19937) at 0x7F8898DAF740)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=37,\n",
              "                       random_state=RandomState(MT19937) at 0x7F8898DAF740)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = x_le.columns[boruta_selector.support_]"
      ],
      "metadata": {
        "id": "qoNxYXT36C1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features_df = pd.DataFrame(selected_features, columns=[\"Características selecionadas\"])\n",
        "print(selected_features_df)"
      ],
      "metadata": {
        "id": "vJ8TftsH-osq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bc8418-abfd-4d30-b0bc-a118ab6ae84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Características selecionadas\n",
            "0                       Tenure\n",
            "1              WarehouseToHome\n",
            "2              NumberOfAddress\n",
            "3                     Complain\n",
            "4            DaySinceLastOrder\n",
            "5               CashbackAmount\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Novo dataframe de X com as melhores features escolhidas anteriormente:\n",
        "\n"
      ],
      "metadata": {
        "id": "YDQs_ByUf4Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_best = x[['Tenure', 'CashbackAmount', 'WarehouseToHome', 'NumberOfAddress',\n",
        "            'DaySinceLastOrder','Complain']]"
      ],
      "metadata": {
        "id": "PgoH67m_3fhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_best"
      ],
      "metadata": {
        "id": "YCHPzLEZXTrr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fe9ed240-c3f2-4581-dc0c-74268137d28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Tenure  CashbackAmount  WarehouseToHome  NumberOfAddress  \\\n",
              "0        4.0          159.93              6.0                9   \n",
              "1        9.0          120.90              8.0                7   \n",
              "2        9.0          120.28             30.0                6   \n",
              "3        0.0          134.07             15.0                8   \n",
              "4        0.0          129.60             12.0                3   \n",
              "...      ...             ...              ...              ...   \n",
              "5625    10.0          150.71             30.0                6   \n",
              "5626    13.0          224.91             13.0                6   \n",
              "5627     1.0          186.42             11.0                3   \n",
              "5628    23.0          178.90              9.0                4   \n",
              "5629     8.0          169.04             15.0                4   \n",
              "\n",
              "      DaySinceLastOrder  Complain  \n",
              "0                   5.0         1  \n",
              "1                   0.0         1  \n",
              "2                   3.0         1  \n",
              "3                   3.0         0  \n",
              "4                   3.0         0  \n",
              "...                 ...       ...  \n",
              "5625                4.0         0  \n",
              "5626                3.0         0  \n",
              "5627                4.0         1  \n",
              "5628                9.0         0  \n",
              "5629                3.0         0  \n",
              "\n",
              "[5630 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30e10dce-1706-4de0-a176-e9060789557e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tenure</th>\n",
              "      <th>CashbackAmount</th>\n",
              "      <th>WarehouseToHome</th>\n",
              "      <th>NumberOfAddress</th>\n",
              "      <th>DaySinceLastOrder</th>\n",
              "      <th>Complain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>159.93</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.0</td>\n",
              "      <td>120.90</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.0</td>\n",
              "      <td>120.28</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>134.07</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>129.60</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5625</th>\n",
              "      <td>10.0</td>\n",
              "      <td>150.71</td>\n",
              "      <td>30.0</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5626</th>\n",
              "      <td>13.0</td>\n",
              "      <td>224.91</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5627</th>\n",
              "      <td>1.0</td>\n",
              "      <td>186.42</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5628</th>\n",
              "      <td>23.0</td>\n",
              "      <td>178.90</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5629</th>\n",
              "      <td>8.0</td>\n",
              "      <td>169.04</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5630 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30e10dce-1706-4de0-a176-e9060789557e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30e10dce-1706-4de0-a176-e9060789557e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30e10dce-1706-4de0-a176-e9060789557e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc23ffaf-a9b5-416e-a224-73099fca842e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc23ffaf-a9b5-416e-a224-73099fca842e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc23ffaf-a9b5-416e-a224-73099fca842e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_796c3016-a667-4be9-a94d-dbba52abf61e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x_best')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_796c3016-a667-4be9-a94d-dbba52abf61e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x_best');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_best",
              "summary": "{\n  \"name\": \"x_best\",\n  \"rows\": 5630,\n  \"fields\": [\n    {\n      \"column\": \"Tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.357951166584485,\n        \"min\": 0.0,\n        \"max\": 61.0,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          61.0,\n          1.0,\n          27.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CashbackAmount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.20703617486409,\n        \"min\": 0.0,\n        \"max\": 324.99,\n        \"num_unique_values\": 2586,\n        \"samples\": [\n          125.19,\n          137.32,\n          270.99\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WarehouseToHome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.345961296394036,\n        \"min\": 5.0,\n        \"max\": 127.0,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          14.0,\n          23.0,\n          34.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumberOfAddress\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          5,\n          21,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DaySinceLastOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.570625540419597,\n        \"min\": 0.0,\n        \"max\": 46.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          5.0,\n          13.0,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Complain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que nenhuma coluna de dados categóricos foi selecionada pelo BorutaPy, o que culmina na não necessidade da aplicação do One Hot Encoder para a categorização dos dados a serem utilizados nas redes neurais posteriormente."
      ],
      "metadata": {
        "id": "xvd9wTDkCrcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DIVIDINDO DADOS DE TREINO E TESTE**"
      ],
      "metadata": {
        "id": "hwNYq3t0alGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_best,y,test_size = 0.3, stratify = y, random_state = 42)"
      ],
      "metadata": {
        "id": "HIwLQsOBap22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "id": "qmLhT004Ww_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9b9d1443-9e70-45cc-f62a-b33fae36e2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Tenure  CashbackAmount  WarehouseToHome  NumberOfAddress  \\\n",
              "1186     9.0          115.14             20.0                2   \n",
              "3145     7.0          286.84              7.0                6   \n",
              "608      0.0          154.72              8.0                2   \n",
              "5202    18.0          156.62             12.0                5   \n",
              "4133    16.0          313.80              9.0                7   \n",
              "...      ...             ...              ...              ...   \n",
              "1916     0.0          143.64              6.0                4   \n",
              "5038    16.0          187.72              9.0                9   \n",
              "1384     6.0          153.76              6.0                3   \n",
              "4026    29.0          151.62              9.0               10   \n",
              "2761    11.0          144.40              7.0                1   \n",
              "\n",
              "      DaySinceLastOrder  Complain  \n",
              "1186                0.0         0  \n",
              "3145                6.0         0  \n",
              "608                 3.0         0  \n",
              "5202                4.0         0  \n",
              "4133               15.0         0  \n",
              "...                 ...       ...  \n",
              "1916                0.0         0  \n",
              "5038                4.0         0  \n",
              "1384                3.0         0  \n",
              "4026                5.0         0  \n",
              "2761                8.0         0  \n",
              "\n",
              "[3941 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42c67829-d647-466a-8984-913aa156f95a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tenure</th>\n",
              "      <th>CashbackAmount</th>\n",
              "      <th>WarehouseToHome</th>\n",
              "      <th>NumberOfAddress</th>\n",
              "      <th>DaySinceLastOrder</th>\n",
              "      <th>Complain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>9.0</td>\n",
              "      <td>115.14</td>\n",
              "      <td>20.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3145</th>\n",
              "      <td>7.0</td>\n",
              "      <td>286.84</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>0.0</td>\n",
              "      <td>154.72</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>18.0</td>\n",
              "      <td>156.62</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4133</th>\n",
              "      <td>16.0</td>\n",
              "      <td>313.80</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1916</th>\n",
              "      <td>0.0</td>\n",
              "      <td>143.64</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5038</th>\n",
              "      <td>16.0</td>\n",
              "      <td>187.72</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1384</th>\n",
              "      <td>6.0</td>\n",
              "      <td>153.76</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4026</th>\n",
              "      <td>29.0</td>\n",
              "      <td>151.62</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2761</th>\n",
              "      <td>11.0</td>\n",
              "      <td>144.40</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3941 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42c67829-d647-466a-8984-913aa156f95a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42c67829-d647-466a-8984-913aa156f95a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42c67829-d647-466a-8984-913aa156f95a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4ed60737-0f64-40f7-bf3d-9421255edd34\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ed60737-0f64-40f7-bf3d-9421255edd34')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4ed60737-0f64-40f7-bf3d-9421255edd34 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eeb6450a-0493-45fd-a093-06d53443a4a5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eeb6450a-0493-45fd-a093-06d53443a4a5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x_train",
              "summary": "{\n  \"name\": \"x_train\",\n  \"rows\": 3941,\n  \"fields\": [\n    {\n      \"column\": \"Tenure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.357439665004101,\n        \"min\": 0.0,\n        \"max\": 61.0,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          21.0,\n          23.0,\n          30.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CashbackAmount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 48.817098450559065,\n        \"min\": 0.0,\n        \"max\": 324.99,\n        \"num_unique_values\": 2324,\n        \"samples\": [\n          166.51,\n          167.33,\n          264.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WarehouseToHome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.28401051453421,\n        \"min\": 5.0,\n        \"max\": 127.0,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          5.0,\n          13.0,\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NumberOfAddress\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          8,\n          20,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DaySinceLastOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5597239760517354,\n        \"min\": 0.0,\n        \"max\": 46.0,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.0,\n          10.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Complain\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "_WUPkwzXWxek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2379fb-e091-47d3-ec1a-e9123881f6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1186    0\n",
              "3145    0\n",
              "608     0\n",
              "5202    0\n",
              "4133    0\n",
              "       ..\n",
              "1916    0\n",
              "5038    0\n",
              "1384    0\n",
              "4026    0\n",
              "2761    0\n",
              "Name: Churn, Length: 3941, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VERIFICANDO O DESBALANCEAMENTO DOS DADOS E APLICANDO OS MÉTODOS DE CORREÇÃO**"
      ],
      "metadata": {
        "id": "GJDmi1FggOix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para avaliarmos a proporção entre dados de ambas as classes avaliadas, tem-se que:"
      ],
      "metadata": {
        "id": "2DcVcdD7ZTm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "wr6cX4lAemoX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c123791d-378b-4cb1-c764-77d9c30e25ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Churn\n",
              "0    3277\n",
              "1     664\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se um evidente desbalanceamento entre essas classes. Para corrigir isso, avaliaremos as técnicas SMOTE e NEAR MISS."
      ],
      "metadata": {
        "id": "d43CsjDHgYTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   SMOTE\n",
        "\n"
      ],
      "metadata": {
        "id": "X828BUJJgoZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smt = SMOTE()\n",
        "x_train_smt, y_train_smt = smt.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "vhKDiqkPgqKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.bincount(y_train_smt)"
      ],
      "metadata": {
        "id": "e2prYPJFng-b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8983c9ec-c53b-4f51-866f-995e983d60db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3277, 3277])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   NEAR MISS\n",
        "\n"
      ],
      "metadata": {
        "id": "yYQ_juDlgqnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nr = NearMiss()\n",
        "x_train_nm, y_train_nm = nr.fit_resample(x_train, y_train)"
      ],
      "metadata": {
        "id": "-YiG2dNTgtUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.bincount(y_train_nm)"
      ],
      "metadata": {
        "id": "zQUSKzvwoSyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced2a72b-6f54-48f6-ebf5-fcfffbdc71b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([664, 664])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   QUAL O MELHOR BALANCEAMENTO?\n",
        "\n"
      ],
      "metadata": {
        "id": "CsGqGVizgtrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O melhor método de balanceamento será identificado mais adiante, após as predições com os dados provenientes das duas técnicas citadas anteriormente."
      ],
      "metadata": {
        "id": "bqamAJxMgw20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NORMALIZANDO DADOS**"
      ],
      "metadata": {
        "id": "7TXkcnI1aqZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc_smt = StandardScaler()\n",
        "x_train_smt = sc_smt.fit_transform(x_train_smt)\n",
        "x_test_smt = sc_smt.transform(x_test)\n",
        "\n",
        "sc_nm = StandardScaler()\n",
        "x_train_nm = sc_nm.fit_transform(x_train_nm)\n",
        "x_test_nm = sc_nm.transform(x_test)"
      ],
      "metadata": {
        "id": "qXCHeWAJat0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_smt"
      ],
      "metadata": {
        "id": "y3aNaK8BXiCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67c1708-97f5-43b7-c828-3c7eabe2328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.18524068, -1.23587091,  0.46642491, -0.86667845, -1.15923874,\n",
              "        -0.64439513],\n",
              "       [-0.06778313,  2.580729  , -1.10126778,  0.72575512,  0.6080652 ,\n",
              "        -0.64439513],\n",
              "       [-0.95336644, -0.35607461, -0.98067604, -0.86667845, -0.27558677,\n",
              "        -0.64439513],\n",
              "       ...,\n",
              "       [-0.95336644, -1.04849023, -0.25712556, -0.86667845, -0.57013743,\n",
              "         1.55184288],\n",
              "       [-0.82685454, -0.36962711, -0.68117593, -0.86667845, -0.86468808,\n",
              "        -0.64439513],\n",
              "       [-0.82685454,  1.17367731,  0.46642491,  0.32764673, -0.27558677,\n",
              "         1.55184288]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_smt"
      ],
      "metadata": {
        "id": "AQO-T1fSXm9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6742e821-a907-471b-ef5e-8ea77345bf7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.0829192 , -0.35385178, -0.98067604,  0.72575512, -0.57013743,\n",
              "        -0.64439513],\n",
              "       [-0.82685454, -0.77641186, -0.01594207, -0.46857006, -0.86468808,\n",
              "        -0.64439513],\n",
              "       [-0.44731883,  0.16228945,  2.15470936,  1.92008031,  1.19716651,\n",
              "        -0.64439513],\n",
              "       ...,\n",
              "       [ 2.58896681,  1.7022664 , -1.22185953, -0.46857006, -1.15923874,\n",
              "        -0.64439513],\n",
              "       [-0.57383073, -0.35563005, -0.01594207,  2.71629709, -0.27558677,\n",
              "        -0.64439513],\n",
              "       [ 0.69128828, -0.54123639,  0.46642491, -0.86667845, -0.57013743,\n",
              "        -0.64439513]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_nm"
      ],
      "metadata": {
        "id": "qXrGmvftpjdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966387d7-4593-4ea2-a7c1-bf7a10a3549c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.7818288 , -0.84591421, -0.17110579, -0.71955822, -0.35442195,\n",
              "        -0.73040215],\n",
              "       [-0.7818288 , -0.84591421, -0.17110579, -0.71955822, -0.35442195,\n",
              "        -0.73040215],\n",
              "       [-0.7818288 , -0.80729605, -0.03884241, -0.71955822, -0.35442195,\n",
              "        -0.73040215],\n",
              "       ...,\n",
              "       [-0.7818288 , -0.9234778 , -0.17110579, -0.31084423, -0.35442195,\n",
              "         1.36910879],\n",
              "       [-0.57392559, -0.03100562,  0.35794774, -0.31084423, -0.71843768,\n",
              "         1.36910879],\n",
              "       [ 1.08930012, -1.03475046,  0.35794774, -0.71955822, -1.08245342,\n",
              "        -0.73040215]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_nm"
      ],
      "metadata": {
        "id": "mEO8D_RYplXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15a54bb-f34c-436e-f31b-1eef8ee237c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4.20784833,  0.09401248, -0.96468609,  0.91529775, -0.35442195,\n",
              "        -0.73040215],\n",
              "       [-0.57392559, -0.52813259,  0.09342097, -0.31084423, -0.71843768,\n",
              "        -0.73040215],\n",
              "       [ 0.04978405,  0.85393929,  2.47416186,  2.14143972,  1.82967247,\n",
              "        -0.73040215],\n",
              "       ...,\n",
              "       [ 5.03946118,  3.12128335, -1.22921285, -0.31084423, -1.08245342,\n",
              "        -0.73040215],\n",
              "       [-0.15811916,  0.0913943 ,  0.09342097,  2.9588677 ,  0.00959379,\n",
              "        -0.73040215],\n",
              "       [ 1.92091298, -0.18187826,  0.6224745 , -0.71955822, -0.35442195,\n",
              "        -0.73040215]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONSTRUINDO A RNA (BALANCEAMENTO SMOTE)**"
      ],
      "metadata": {
        "id": "7oBTZphRroAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Seleção do número de neurônios da camada de processamento:\n",
        "\n"
      ],
      "metadata": {
        "id": "JWqogu5oZX1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Return_Recall_smt(x_test_smt, y_test):\n",
        "    y_pred_smt = ann_smt.predict(x_test_smt)\n",
        "    y_pred_smt = (y_pred_smt > 0.5)\n",
        "\n",
        "    score_smt1 = recall_score(y_test, y_pred_smt)*100\n",
        "    score_smt2 = accuracy_score(y_test, y_pred_smt)*100\n",
        "\n",
        "    ann_smt_2 = KerasClassifier(model=ann_smt, epochs=50, batch_size=64, verbose=0)\n",
        "    # Como o cross_val_score é incompatível com o Sequential, ele foi encapsulado no KerasClassifier.\n",
        "\n",
        "    score_model_smt = cross_val_score(ann_smt_2, x_test_smt, y_test, cv=5, scoring='accuracy')\n",
        "\n",
        "    list_scoresm_smt.append (score_model_smt)\n",
        "    list_ReturnRecall_smt.append (score_smt1)\n",
        "    list_ReturnAccuracy_smt.append (score_smt2)\n",
        "\n",
        "    return print(f\"Recall e Acurácia (SMOTE) com a validação (%):{score_smt1} e {score_smt2}. Scores do modelo: {score_model_smt}\")"
      ],
      "metadata": {
        "id": "jrxmn5uyhTRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_ReturnRecall_smt = []\n",
        "list_ReturnAccuracy_smt = []\n",
        "list_scoresm_smt = []\n",
        "\n",
        "list_neurons_smt = [2,4,6,8]\n",
        "\n",
        "for i in list_neurons_smt:\n",
        "    ann_smt = Sequential()\n",
        "\n",
        "    ann_smt.add (tf.keras.layers.Dense (units=i, activation='relu', kernel_initializer = 'he_normal'))\n",
        "    ann_smt.add (tf.keras.layers.Dense (units=1, activation='sigmoid', kernel_initializer = 'he_normal'))\n",
        "\n",
        "    optimize = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "    ann_smt.compile(optimizer=optimize, loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
        "\n",
        "    ann_smt.fit(x_train_smt, y_train_smt, batch_size=64, epochs=50)\n",
        "\n",
        "    Return_Recall_smt(x_test_smt, y_test)"
      ],
      "metadata": {
        "id": "9hkR2sPEho7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd577b5-53ee-4c6d-98b0-e0966e6bc81c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.6473 - recall_7: 0.6535\n",
            "Epoch 2/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5209 - recall_7: 0.7586\n",
            "Epoch 3/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5222 - recall_7: 0.7484\n",
            "Epoch 4/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5128 - recall_7: 0.7518\n",
            "Epoch 5/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5097 - recall_7: 0.7369\n",
            "Epoch 6/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5100 - recall_7: 0.7313\n",
            "Epoch 7/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5099 - recall_7: 0.7316\n",
            "Epoch 8/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5107 - recall_7: 0.7328\n",
            "Epoch 9/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5058 - recall_7: 0.7248\n",
            "Epoch 10/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4983 - recall_7: 0.7356\n",
            "Epoch 11/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5033 - recall_7: 0.7194\n",
            "Epoch 12/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4973 - recall_7: 0.7317\n",
            "Epoch 13/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4973 - recall_7: 0.7087\n",
            "Epoch 14/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4921 - recall_7: 0.7166\n",
            "Epoch 15/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4971 - recall_7: 0.7121\n",
            "Epoch 16/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4897 - recall_7: 0.7126\n",
            "Epoch 17/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4961 - recall_7: 0.7077\n",
            "Epoch 18/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4821 - recall_7: 0.7535\n",
            "Epoch 19/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4977 - recall_7: 0.7316\n",
            "Epoch 20/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4914 - recall_7: 0.7581\n",
            "Epoch 21/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4976 - recall_7: 0.7408\n",
            "Epoch 22/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5032 - recall_7: 0.7353\n",
            "Epoch 23/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4850 - recall_7: 0.7663\n",
            "Epoch 24/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4845 - recall_7: 0.7425\n",
            "Epoch 25/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4987 - recall_7: 0.7402\n",
            "Epoch 26/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4879 - recall_7: 0.7495\n",
            "Epoch 27/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4969 - recall_7: 0.7254\n",
            "Epoch 28/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4957 - recall_7: 0.7442\n",
            "Epoch 29/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4886 - recall_7: 0.7404\n",
            "Epoch 30/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4944 - recall_7: 0.7409\n",
            "Epoch 31/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4901 - recall_7: 0.7390\n",
            "Epoch 32/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4915 - recall_7: 0.7390\n",
            "Epoch 33/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4705 - recall_7: 0.7568\n",
            "Epoch 34/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4856 - recall_7: 0.7440\n",
            "Epoch 35/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4748 - recall_7: 0.7542\n",
            "Epoch 36/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4853 - recall_7: 0.7348\n",
            "Epoch 37/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4897 - recall_7: 0.7223\n",
            "Epoch 38/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4973 - recall_7: 0.7391\n",
            "Epoch 39/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4820 - recall_7: 0.7452\n",
            "Epoch 40/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4850 - recall_7: 0.7531\n",
            "Epoch 41/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4977 - recall_7: 0.7304\n",
            "Epoch 42/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4909 - recall_7: 0.7361\n",
            "Epoch 43/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5037 - recall_7: 0.7316\n",
            "Epoch 44/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5029 - recall_7: 0.7288\n",
            "Epoch 45/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5008 - recall_7: 0.7366\n",
            "Epoch 46/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4876 - recall_7: 0.7359\n",
            "Epoch 47/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4812 - recall_7: 0.7483\n",
            "Epoch 48/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4880 - recall_7: 0.7391\n",
            "Epoch 49/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4945 - recall_7: 0.7317\n",
            "Epoch 50/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5008 - recall_7: 0.7394\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Recall e Acurácia (SMOTE) com a validação (%):72.53521126760563 e 80.46181172291297. Scores do modelo: [0.86982249 0.85798817 0.87869822 0.84911243 0.86053412]\n",
            "Epoch 1/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.6134 - recall_8: 0.8029\n",
            "Epoch 2/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5221 - recall_8: 0.7422\n",
            "Epoch 3/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4968 - recall_8: 0.7405\n",
            "Epoch 4/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4784 - recall_8: 0.7843\n",
            "Epoch 5/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4690 - recall_8: 0.7955\n",
            "Epoch 6/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4747 - recall_8: 0.8039\n",
            "Epoch 7/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4589 - recall_8: 0.8045\n",
            "Epoch 8/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4772 - recall_8: 0.7890\n",
            "Epoch 9/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4778 - recall_8: 0.7914\n",
            "Epoch 10/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4869 - recall_8: 0.7828\n",
            "Epoch 11/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4556 - recall_8: 0.8050\n",
            "Epoch 12/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4709 - recall_8: 0.7990\n",
            "Epoch 13/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4721 - recall_8: 0.7818\n",
            "Epoch 14/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4661 - recall_8: 0.8087\n",
            "Epoch 15/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4616 - recall_8: 0.7960\n",
            "Epoch 16/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4626 - recall_8: 0.7869\n",
            "Epoch 17/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4685 - recall_8: 0.7895\n",
            "Epoch 18/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4680 - recall_8: 0.7785\n",
            "Epoch 19/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4751 - recall_8: 0.7962\n",
            "Epoch 20/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4699 - recall_8: 0.7893\n",
            "Epoch 21/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4703 - recall_8: 0.7793\n",
            "Epoch 22/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4684 - recall_8: 0.7758\n",
            "Epoch 23/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4659 - recall_8: 0.7936\n",
            "Epoch 24/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4692 - recall_8: 0.7787\n",
            "Epoch 25/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4670 - recall_8: 0.7792\n",
            "Epoch 26/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4734 - recall_8: 0.8001\n",
            "Epoch 27/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4730 - recall_8: 0.7926\n",
            "Epoch 28/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4726 - recall_8: 0.7932\n",
            "Epoch 29/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4770 - recall_8: 0.7522\n",
            "Epoch 30/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4567 - recall_8: 0.7891\n",
            "Epoch 31/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4777 - recall_8: 0.7875\n",
            "Epoch 32/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4685 - recall_8: 0.7898\n",
            "Epoch 33/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4709 - recall_8: 0.7762\n",
            "Epoch 34/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4736 - recall_8: 0.7854\n",
            "Epoch 35/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4628 - recall_8: 0.7921\n",
            "Epoch 36/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4767 - recall_8: 0.7893\n",
            "Epoch 37/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4648 - recall_8: 0.7862\n",
            "Epoch 38/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4699 - recall_8: 0.7894\n",
            "Epoch 39/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4647 - recall_8: 0.7958\n",
            "Epoch 40/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4661 - recall_8: 0.7848\n",
            "Epoch 41/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4611 - recall_8: 0.7890\n",
            "Epoch 42/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4685 - recall_8: 0.7999\n",
            "Epoch 43/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4661 - recall_8: 0.7821\n",
            "Epoch 44/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4713 - recall_8: 0.7929\n",
            "Epoch 45/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4628 - recall_8: 0.7842\n",
            "Epoch 46/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4668 - recall_8: 0.7888\n",
            "Epoch 47/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4762 - recall_8: 0.7803\n",
            "Epoch 48/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4561 - recall_8: 0.7984\n",
            "Epoch 49/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4582 - recall_8: 0.7994\n",
            "Epoch 50/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4675 - recall_8: 0.7882\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Recall e Acurácia (SMOTE) com a validação (%):80.28169014084507 e 79.33688573120189. Scores do modelo: [0.87573964 0.89940828 0.89053254 0.86094675 0.88724036]\n",
            "Epoch 1/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6925 - recall_9: 0.5199\n",
            "Epoch 2/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5436 - recall_9: 0.8245\n",
            "Epoch 3/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5200 - recall_9: 0.7374\n",
            "Epoch 4/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4891 - recall_9: 0.7537\n",
            "Epoch 5/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4991 - recall_9: 0.7630\n",
            "Epoch 6/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4893 - recall_9: 0.7776\n",
            "Epoch 7/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4757 - recall_9: 0.7740\n",
            "Epoch 8/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4681 - recall_9: 0.7927\n",
            "Epoch 9/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4685 - recall_9: 0.7738\n",
            "Epoch 10/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4562 - recall_9: 0.7834\n",
            "Epoch 11/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4535 - recall_9: 0.7845\n",
            "Epoch 12/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4519 - recall_9: 0.7835\n",
            "Epoch 13/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4544 - recall_9: 0.7815\n",
            "Epoch 14/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4443 - recall_9: 0.7880\n",
            "Epoch 15/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4492 - recall_9: 0.7806\n",
            "Epoch 16/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4439 - recall_9: 0.7787\n",
            "Epoch 17/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4358 - recall_9: 0.7924\n",
            "Epoch 18/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4483 - recall_9: 0.7954\n",
            "Epoch 19/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4456 - recall_9: 0.7951\n",
            "Epoch 20/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4392 - recall_9: 0.7981\n",
            "Epoch 21/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4497 - recall_9: 0.8010\n",
            "Epoch 22/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4454 - recall_9: 0.8122\n",
            "Epoch 23/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4452 - recall_9: 0.7983\n",
            "Epoch 24/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4434 - recall_9: 0.7906\n",
            "Epoch 25/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4432 - recall_9: 0.8003\n",
            "Epoch 26/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4583 - recall_9: 0.7887\n",
            "Epoch 27/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4429 - recall_9: 0.8015\n",
            "Epoch 28/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4381 - recall_9: 0.8086\n",
            "Epoch 29/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4367 - recall_9: 0.8101\n",
            "Epoch 30/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4410 - recall_9: 0.7785\n",
            "Epoch 31/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4407 - recall_9: 0.7837\n",
            "Epoch 32/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4439 - recall_9: 0.7882\n",
            "Epoch 33/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4450 - recall_9: 0.7949\n",
            "Epoch 34/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4361 - recall_9: 0.8050\n",
            "Epoch 35/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4434 - recall_9: 0.7826\n",
            "Epoch 36/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4391 - recall_9: 0.7832\n",
            "Epoch 37/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4452 - recall_9: 0.7919\n",
            "Epoch 38/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4372 - recall_9: 0.7966\n",
            "Epoch 39/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4345 - recall_9: 0.8145\n",
            "Epoch 40/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4354 - recall_9: 0.7865\n",
            "Epoch 41/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4373 - recall_9: 0.7881\n",
            "Epoch 42/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4308 - recall_9: 0.8044\n",
            "Epoch 43/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4271 - recall_9: 0.8009\n",
            "Epoch 44/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4351 - recall_9: 0.8060\n",
            "Epoch 45/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4330 - recall_9: 0.8024\n",
            "Epoch 46/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - recall_9: 0.7829\n",
            "Epoch 47/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4349 - recall_9: 0.8127\n",
            "Epoch 48/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4285 - recall_9: 0.7931\n",
            "Epoch 49/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4373 - recall_9: 0.7976\n",
            "Epoch 50/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4365 - recall_9: 0.7851\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Recall e Acurácia (SMOTE) com a validação (%):80.63380281690141 e 80.52101835405566. Scores do modelo: [0.8816568  0.89349112 0.86982249 0.84615385 0.88130564]\n",
            "Epoch 1/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7334 - recall_10: 0.6625\n",
            "Epoch 2/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5186 - recall_10: 0.7744\n",
            "Epoch 3/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4871 - recall_10: 0.7871\n",
            "Epoch 4/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4791 - recall_10: 0.7970\n",
            "Epoch 5/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4762 - recall_10: 0.7973\n",
            "Epoch 6/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4791 - recall_10: 0.7728\n",
            "Epoch 7/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4661 - recall_10: 0.7762\n",
            "Epoch 8/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4767 - recall_10: 0.7878\n",
            "Epoch 9/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4464 - recall_10: 0.8037\n",
            "Epoch 10/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4566 - recall_10: 0.7924\n",
            "Epoch 11/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4611 - recall_10: 0.7928\n",
            "Epoch 12/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4540 - recall_10: 0.7991\n",
            "Epoch 13/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4388 - recall_10: 0.7968\n",
            "Epoch 14/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4504 - recall_10: 0.7849\n",
            "Epoch 15/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4355 - recall_10: 0.7847\n",
            "Epoch 16/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4468 - recall_10: 0.7922\n",
            "Epoch 17/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4452 - recall_10: 0.7815\n",
            "Epoch 18/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4511 - recall_10: 0.7976\n",
            "Epoch 19/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4398 - recall_10: 0.8010\n",
            "Epoch 20/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4464 - recall_10: 0.7933\n",
            "Epoch 21/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4434 - recall_10: 0.8083\n",
            "Epoch 22/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4506 - recall_10: 0.7789\n",
            "Epoch 23/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4530 - recall_10: 0.7804\n",
            "Epoch 24/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4314 - recall_10: 0.8040\n",
            "Epoch 25/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4303 - recall_10: 0.7951\n",
            "Epoch 26/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4385 - recall_10: 0.7920\n",
            "Epoch 27/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4315 - recall_10: 0.8020\n",
            "Epoch 28/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4521 - recall_10: 0.7924\n",
            "Epoch 29/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4384 - recall_10: 0.8003\n",
            "Epoch 30/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4403 - recall_10: 0.7994\n",
            "Epoch 31/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4401 - recall_10: 0.7813\n",
            "Epoch 32/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4391 - recall_10: 0.7920\n",
            "Epoch 33/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4260 - recall_10: 0.8081\n",
            "Epoch 34/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4474 - recall_10: 0.7906\n",
            "Epoch 35/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4370 - recall_10: 0.7951\n",
            "Epoch 36/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4358 - recall_10: 0.8084\n",
            "Epoch 37/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4343 - recall_10: 0.7823\n",
            "Epoch 38/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4316 - recall_10: 0.7944\n",
            "Epoch 39/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4419 - recall_10: 0.7829\n",
            "Epoch 40/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4323 - recall_10: 0.8023\n",
            "Epoch 41/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4378 - recall_10: 0.7855\n",
            "Epoch 42/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4513 - recall_10: 0.7924\n",
            "Epoch 43/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4391 - recall_10: 0.7873\n",
            "Epoch 44/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4333 - recall_10: 0.8083\n",
            "Epoch 45/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4417 - recall_10: 0.7875\n",
            "Epoch 46/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4560 - recall_10: 0.7798\n",
            "Epoch 47/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4443 - recall_10: 0.7903\n",
            "Epoch 48/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4268 - recall_10: 0.8106\n",
            "Epoch 49/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4457 - recall_10: 0.7795\n",
            "Epoch 50/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4305 - recall_10: 0.7942\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Recall e Acurácia (SMOTE) com a validação (%):81.33802816901408 e 81.17229129662522. Scores do modelo: [0.89053254 0.89349112 0.88757396 0.86094675 0.88724036]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Recall, Acurácia e Score da validação cruzada do modelo para cada quantidade de neurônios na camada intermediária:\n",
        "\n"
      ],
      "metadata": {
        "id": "hAV-frMlgWVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_scoresm_average_smt = []\n",
        "\n",
        "for w in list_scoresm_smt:\n",
        "\n",
        "  average = st.mean(w)\n",
        "\n",
        "  list_scoresm_average_smt.append(average*100)\n",
        "\n",
        "\n",
        "data_df = {'Recall': list_ReturnRecall_smt, 'Accuracy': list_ReturnAccuracy_smt, 'SCORE': list_scoresm_average_smt}\n",
        "\n",
        "df_neurons_smt = pd.DataFrame (data_df, index = list_neurons_smt, columns = ['Recall', 'Accuracy', 'SCORE']).sort_values('Recall',\n",
        "                                                                                                      ascending=False)\n",
        "df_neurons_smt"
      ],
      "metadata": {
        "id": "S_UB0cGqiNIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "f1dd186b-6982-41de-8920-62432ddc6739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Recall   Accuracy      SCORE\n",
              "8  81.338028  81.172291  88.395695\n",
              "6  80.633803  80.521018  87.448598\n",
              "4  80.281690  79.336886  88.277352\n",
              "2  72.535211  80.461812  86.323109"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8cbe0b6-eeec-4174-a125-85b1b7c77d3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>81.338028</td>\n",
              "      <td>81.172291</td>\n",
              "      <td>88.395695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>80.633803</td>\n",
              "      <td>80.521018</td>\n",
              "      <td>87.448598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80.281690</td>\n",
              "      <td>79.336886</td>\n",
              "      <td>88.277352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72.535211</td>\n",
              "      <td>80.461812</td>\n",
              "      <td>86.323109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8cbe0b6-eeec-4174-a125-85b1b7c77d3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8cbe0b6-eeec-4174-a125-85b1b7c77d3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8cbe0b6-eeec-4174-a125-85b1b7c77d3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-987e61aa-aea3-4eb2-ac4a-81d2d59a5905\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-987e61aa-aea3-4eb2-ac4a-81d2d59a5905')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-987e61aa-aea3-4eb2-ac4a-81d2d59a5905 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_40e23e88-0bbc-40a6-9a2c-c7c4cd799067\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_neurons_smt')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_40e23e88-0bbc-40a6-9a2c-c7c4cd799067 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_neurons_smt');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_neurons_smt",
              "summary": "{\n  \"name\": \"df_neurons_smt\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.131388710515973,\n        \"min\": 72.53521126760563,\n        \"max\": 81.33802816901408,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          80.63380281690141,\n          72.53521126760563,\n          81.33802816901408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7620578084194931,\n        \"min\": 79.33688573120189,\n        \"max\": 81.17229129662522,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          80.52101835405566,\n          80.46181172291297,\n          81.17229129662522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9565230106272119,\n        \"min\": 86.32310852808456,\n        \"max\": 88.39569469562622,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          87.44859796674452,\n          86.32310852808456,\n          88.39569469562622\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list_neurons_smt, list_ReturnRecall_smt, marker = 'o')\n",
        "plt.plot(list_neurons_smt, list_ReturnAccuracy_smt, marker = 's')\n",
        "plt.plot(list_neurons_smt, list_scoresm_average_smt, marker = 'X')\n",
        "plt.xlabel ('Número de neurônios na camada intermediária')\n",
        "plt.ylabel ('Métricas da RNA')\n",
        "plt.legend (['Recall', 'Accuracy', 'SCORE MODEL VALIDATION'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ulVQr1BkHnM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "5bd3e7f5-5dc7-4059-a855-c27d0034ab2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que tais indicadores se mantêm equilibrados para 4, 6 e 8 neurônios na camada intermediária. Entretanto, nota-se uma certa superioridade dos indicadores para 8 neurônios, quantidade essa que será adotada para o treino da RNA."
      ],
      "metadata": {
        "id": "JO-KWRBo8pUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Treino da RNA:\n",
        "\n"
      ],
      "metadata": {
        "id": "PmTTr3x2a-53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann_smt = Sequential()\n",
        "\n",
        "ann_smt.add (tf.keras.layers.Dense (units=8, activation='relu', kernel_initializer = 'he_normal'))\n",
        "ann_smt.add (tf.keras.layers.Dense (units=1, activation='sigmoid', kernel_initializer = 'he_normal'))\n",
        "\n",
        "optimize = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "ann_smt.compile(optimizer=optimize, loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
        "\n",
        "ann_smt.fit(x_train_smt, y_train_smt, batch_size=64, epochs=50)"
      ],
      "metadata": {
        "id": "xgLG6bnipB4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4131f3d9-c96a-4a5b-d3f2-5942f50d4b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6182 - recall_11: 0.7058\n",
            "Epoch 2/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4945 - recall_11: 0.7715\n",
            "Epoch 3/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4886 - recall_11: 0.7737\n",
            "Epoch 4/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4784 - recall_11: 0.7881\n",
            "Epoch 5/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4690 - recall_11: 0.7891\n",
            "Epoch 6/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4593 - recall_11: 0.7896\n",
            "Epoch 7/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4632 - recall_11: 0.7851\n",
            "Epoch 8/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4535 - recall_11: 0.7999\n",
            "Epoch 9/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4473 - recall_11: 0.7888\n",
            "Epoch 10/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4545 - recall_11: 0.7779\n",
            "Epoch 11/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4516 - recall_11: 0.7798\n",
            "Epoch 12/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4420 - recall_11: 0.7947\n",
            "Epoch 13/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4472 - recall_11: 0.7840\n",
            "Epoch 14/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4423 - recall_11: 0.8000\n",
            "Epoch 15/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4433 - recall_11: 0.7881\n",
            "Epoch 16/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4421 - recall_11: 0.7779\n",
            "Epoch 17/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4237 - recall_11: 0.7981\n",
            "Epoch 18/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4403 - recall_11: 0.7814\n",
            "Epoch 19/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4441 - recall_11: 0.7810\n",
            "Epoch 20/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4391 - recall_11: 0.7802\n",
            "Epoch 21/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4327 - recall_11: 0.7918\n",
            "Epoch 22/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4405 - recall_11: 0.7828\n",
            "Epoch 23/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4206 - recall_11: 0.7997\n",
            "Epoch 24/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4344 - recall_11: 0.8062\n",
            "Epoch 25/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4320 - recall_11: 0.7879\n",
            "Epoch 26/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4465 - recall_11: 0.7872\n",
            "Epoch 27/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4408 - recall_11: 0.7755\n",
            "Epoch 28/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4308 - recall_11: 0.7892\n",
            "Epoch 29/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4256 - recall_11: 0.8057\n",
            "Epoch 30/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4234 - recall_11: 0.8038\n",
            "Epoch 31/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4266 - recall_11: 0.8036\n",
            "Epoch 32/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4336 - recall_11: 0.7915\n",
            "Epoch 33/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4267 - recall_11: 0.7866\n",
            "Epoch 34/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4296 - recall_11: 0.7952\n",
            "Epoch 35/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4356 - recall_11: 0.8014\n",
            "Epoch 36/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4291 - recall_11: 0.8110\n",
            "Epoch 37/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4374 - recall_11: 0.7711\n",
            "Epoch 38/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4373 - recall_11: 0.7839\n",
            "Epoch 39/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4284 - recall_11: 0.7864\n",
            "Epoch 40/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4125 - recall_11: 0.8063\n",
            "Epoch 41/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4278 - recall_11: 0.7989\n",
            "Epoch 42/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4312 - recall_11: 0.7799\n",
            "Epoch 43/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4304 - recall_11: 0.8141\n",
            "Epoch 44/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4369 - recall_11: 0.8013\n",
            "Epoch 45/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.4263 - recall_11: 0.7990\n",
            "Epoch 46/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4280 - recall_11: 0.8001\n",
            "Epoch 47/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4274 - recall_11: 0.8005\n",
            "Epoch 48/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4263 - recall_11: 0.8062\n",
            "Epoch 49/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4327 - recall_11: 0.8005\n",
            "Epoch 50/50\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4331 - recall_11: 0.7917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f88818cfa00>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Predição da RNA e resultados:\n",
        "\n"
      ],
      "metadata": {
        "id": "JZ2aPgU8bEEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a predição da rede, será adotado 3 valores de thresholds e avaliado qual o melhor desempenho dentre eles."
      ],
      "metadata": {
        "id": "hM6YKEj7Bo7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = [0.4, 0.5, 0.6]\n",
        "\n",
        "for i in thresholds:\n",
        "\n",
        "  y_pred_smt = ann_smt.predict(x_test_smt)\n",
        "  y_pred_smt = (y_pred_smt > i)\n",
        "\n",
        "  pred_array_smt = 1 * y_pred_smt.reshape(len(y_pred_smt), 1)\n",
        "  test_array_smt = y_test.values.reshape(len(y_test), 1)\n",
        "\n",
        "  ann_smt_2 = KerasClassifier(model=ann_smt, epochs=50, batch_size=64, verbose=0)\n",
        "  # Como o cross_val_score é incompatível com o Sequential, ele foi encapsulado no KerasClassifier.\n",
        "\n",
        "  score_model_smt = cross_val_score(ann_smt_2, x_test_smt, y_test, cv=5, scoring='accuracy')\n",
        "  score_model_smt = st.mean(score_model_smt)\n",
        "\n",
        "  cm_smt = confusion_matrix(test_array_smt, pred_array_smt)\n",
        "\n",
        "  cm_display_smt = ConfusionMatrixDisplay(confusion_matrix = cm_smt, display_labels = [\"Not churn\", \"Churn\"])\n",
        "\n",
        "  cm_display_smt.plot()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Recall da validação (%): \", ((recall_score(y_test, y_pred_smt)*100)))\n",
        "  print(\"Acurácia da validação (%): \", ((accuracy_score(y_test, y_pred_smt)*100)))\n",
        "  print(\"SCORE do modelo (%): \", (score_model_smt*100))"
      ],
      "metadata": {
        "id": "725IUeTMqSDr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1523
        },
        "outputId": "ad93f551-1534-4e56-b746-cb0e2bcc9678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAGwCAYAAABGogSnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBuElEQVR4nO3daXgUZfb38V8nkJUsBElCJCxhX0UBMYIgEgnKo6D4Z3CigKI4CCK74sgWEBAUMQyCihJQ0HEGZQQVRVxACDCgOChhFWQNqCGExWzd9bxg0mOT0KTTHZJUfz/XVdfYVXdVnWaiOZxz31UWwzAMAQAAeAmf8g4AAADgaiL5AQAAXoXkBwAAeBWSHwAA4FVIfgAAgFch+QEAAF6F5AcAAHiVKuUdAErGZrPp+PHjCgkJkcViKe9wAAAuMgxDZ8+eVUxMjHx8yq72kJOTo7y8PLev4+fnp4CAAA9EVPGQ/FQSx48fV2xsbHmHAQBw05EjR1S7du0yuXZOTo7q162mjFNWt68VHR2tgwcPmjIBIvmpJEJCQiRJP39bT6HV6FbCnLo9+3B5hwCUGWt+jr7/YJr9v+dlIS8vTxmnrPp5ez2FhpT+d0X2WZvqtj2kvLw8kh+Un8JWV2g1H7d+oIGKzNfPfP+RBS51NaYuVAuxqFpI6e9jk7mnV5D8AABgMlbDJqsbb+60GjbPBVMBkfwAAGAyNhmyqfTZjzvnVgb0TwAAgFeh8gMAgMnYZJM7jSv3zq74SH4AADAZq2HIapS+deXOuZUBbS8AAOBVqPwAAGAyTHh2juQHAACTscmQleTnsmh7AQAAr0LlBwAAk6Ht5RzJDwAAJsNqL+doewEAAK9C5QcAAJOx/Xdz53wzI/kBAMBkrG6u9nLn3MqA5AcAAJOxGnLzre6ei6UiYs4PAADwKlR+AAAwGeb8OEflBwAAk7HJIqsbm00Wl++5fv163XXXXYqJiZHFYtHKlSsdjhuGoYkTJ6pWrVoKDAxUQkKC9u3b5zAmMzNTSUlJCg0NVXh4uAYNGqRz5845jPnPf/6jW265RQEBAYqNjdWsWbNcjpXkBwAAuO38+fO67rrrNH/+/GKPz5o1SykpKVq4cKG2bNmi4OBgJSYmKicnxz4mKSlJP/74o9auXavVq1dr/fr1Gjx4sP14dna2unfvrrp162r79u2aPXu2Jk+erNdee82lWGl7AQBgMjbj4ubO+a664447dMcddxR7zDAMzZ07V88++6x69eolSVq6dKmioqK0cuVK9evXT+np6VqzZo3+/e9/q127dpKkefPm6c4779QLL7ygmJgYLVu2THl5eXrzzTfl5+enFi1aaMeOHZozZ45DknQlVH4AADAZd1pehZt0sdLyxy03N7dU8Rw8eFAZGRlKSEiw7wsLC1OHDh2UlpYmSUpLS1N4eLg98ZGkhIQE+fj4aMuWLfYxnTt3lp+fn31MYmKi9uzZo9OnT5c4HpIfAABQrNjYWIWFhdm3GTNmlOo6GRkZkqSoqCiH/VFRUfZjGRkZioyMdDhepUoVRUREOIwp7hp/vEdJ0PYCAMBk/li9Ke35knTkyBGFhoba9/v7+7sdW0VA8gMAgMnYDItsRumTn8JzQ0NDHZKf0oqOjpYknTx5UrVq1bLvP3nypNq0aWMfc+rUKYfzCgoKlJmZaT8/OjpaJ0+edBhT+LlwTEnQ9gIAAGWqfv36io6O1rp16+z7srOztWXLFsXHx0uS4uPjlZWVpe3bt9vHfPHFF7LZbOrQoYN9zPr165Wfn28fs3btWjVp0kTVq1cvcTwkPwAAmIynJjy74ty5c9qxY4d27Ngh6eIk5x07dujw4cOyWCwaMWKEpk2bpg8//FA7d+5U//79FRMTo969e0uSmjVrph49eujRRx/V1q1btXHjRg0bNkz9+vVTTEyMJOnPf/6z/Pz8NGjQIP3444/6+9//rpdfflmjRo1yKVbaXgAAmIxVPrK6Ud+wluKcbdu2qWvXrvbPhQnJgAEDlJqaqnHjxun8+fMaPHiwsrKy1KlTJ61Zs0YBAQH2c5YtW6Zhw4apW7du8vHxUZ8+fZSSkmI/HhYWps8++0xDhw5V27Ztdc0112jixIkuLXOXJIthGCZ/fZk5ZGdnKywsTKf3xik0hIIdzOmmsX8p7xCAMmPNy9G37z2rM2fOeGQeTXEKf1es21lHwW78rjh/1qZurQ6Xaazlid+iAADAq9D2AgDAZDy11N2sSH4AADAZq+Ejq+HGnB+TT4ih7QUAALwKlR8AAEzGJotsbtQ3bDJ36YfkBwAAk2HOj3O0vQAAgFeh8gMAgMm4P+GZthcAAKhELs75cePFprS9AAAAzIPKDwAAJmNz891erPYCAACVCnN+nCP5AQDAZGzy4Tk/TjDnBwAAeBUqPwAAmIzVsMhquPGQQzfOrQxIfgAAMBmrmxOerbS9AAAAzIPKDwAAJmMzfGRzY7WXjdVeAACgMqHt5RxtLwAA4FWo/AAAYDI2ubdiy+a5UCokkh8AAEzG/YccmrsxZO5vBwAAcAkqPwAAmIz77/Yyd22E5AcAAJOxySKb3JnzwxOeAQBAJULlxzlzfzsAAIBLUPkBAMBk3H/IoblrIyQ/AACYjM2wyObOc35M/lZ3c6d2AAAAl6DyAwCAydjcbHuZ/SGHJD8AAJiM+291N3fyY+5vBwAAcAkqPwAAmIxVFlndeFChO+dWBiQ/AACYDG0v58z97QAAAC5B5QcAAJOxyr3WldVzoVRIJD8AAJgMbS/nSH4AADAZXmzqnLm/HQAAwCWo/AAAYDKGLLK5MefHYKk7AACoTGh7OWfubwcAAHAJKj8AAJiMzbDIZpS+deXOuZUByQ8AACZjdfOt7u6cWxmY+9sBAABcgsoPAAAmQ9vLOZIfAABMxiYf2dxo7rhzbmVg7m8HAABwCSo/AACYjNWwyOpG68qdcysDkh8AAEyGOT/OkfwAAGAyhptvdTd4wjMAAIB5UPkBAMBkrLLI6sbLSd05tzIg+QEAwGRshnvzdmyGB4OpgGh7AQAAr0LlB6a2c3Ow/vFKpPbtDFLmyaqa9MZB3XzHGftxw5CWzo7WmuU1dC7bV83bndfwmUd0bVyew3W2fB6qZS9F6WB6oPz8bWp103lNXnzQfjwxpk2Re49/5ZBu7Z1VVl8NKNa98T/q3vhdqlX9rCTpp5PV9ebatkrbU+eSkYZeGvSJ4pse0bjU7lr/Y337kajwsxp37zdq2+C4LuRV0cfbGmvBJx1ktfH35crC5uaEZ3fOrQxIfv4gNTVVI0aMUFZWVnmHAg/JueCjuBa/K/H+TCUPql/k+HvzI/WvN2tqzNyfFV0nT0tm1dIzf26g17/aLb+Ai3XfDR+Fae7YWD309Am16XhOVqt0aHdgkWuNfumw2nXNtn+uFmotuy8GXMaprGDN/7iDjv4aJslQz3Z7NWvgp+o/t48Onoywj+t3y04ZxbQ2fCw2vfjwGmWeDdSj83vpmpALmtjvSxVYfbRwTYer90XgFpsssrkxb8edcyuDck3tBg4cKIvFopkzZzrsX7lypSwW1/7g69Wrp7lz53owOphB+9vOauBTGer4h2pPIcOQVi6qqfufzNDNPbIV1zxH41J+1m8nq2rTmjBJkrVAWjjxWj367HH9v/6/qXaDXNVtnKsud2cVuV61UKsiIgvsW2HyBFxN36TXU9ruOjrya5iO/BquhWtu1IW8qmpZ55R9TKOYX/Xnzv/RtH/cWuT8Do2Pqn7UaU1+5zbtO36N0vbU0Wufttd9N+9SFV8SephDude1AgIC9Pzzz+v06dPlHUqZycvLu/IgXHUZh/2UeaqqbrjlnH1fcKhNTa+/oPTtwZKkfTuD9OsJP1l8pMdvb6z727TQX5PidGh3QJHr/e2v1+r/WrTUE3c20qfvRBT7t2rgavKx2JRw3X4F+uVr589RkiT/qvlK/vM6zV7ZSZlng4qc07LuSR3IiFDmuf8d27yntqoF5ikuyrz/nTabwic8u7OZWbknPwkJCYqOjtaMGTOcjluxYoVatGghf39/1atXTy+++KL92K233qqff/5ZI0eOlMVicVo1ysrK0mOPPaaoqCgFBASoZcuWWr16tcOYTz/9VM2aNVO1atXUo0cPnThxwuFeI0aMcBjfu3dvDRw40P65Xr16mjp1qvr376/Q0FANHjxYqampCg8Pd3ptXF2Zpy52fcNr5jvsD6+Zbz+W8bOfJOntF6N1/4iTSl76k6qFWTW2T0Nln/a1n9N/7An9deHPmvHuAXW684zmPVNb/3rjmqv0TQBHDaJ/0xfT3tD6GYv0VJ8NempJog6dqi5JGnF3mnYeitaGH+sVe26NkAvKPOvY1s08F2g/hsqhcM6PO5uZlfu38/X11fTp0zVv3jwdPXq02DHbt29X37591a9fP+3cuVOTJ0/WhAkTlJqaKkl6//33Vbt2bSUnJ+vEiROXTShsNpvuuOMObdy4UW+//bZ27dqlmTNnytf3f7/ELly4oBdeeEFvvfWW1q9fr8OHD2vMmDEuf68XXnhB1113nb777jtNmDDB5Wvn5uYqOzvbYcPVZ7Nd/N/7nzypW3qeUaPWv2v0S4dlsUgbVofbxyWNPKkWN55Xw1a/60/DTun/hpzSPxZElk/Q8Ho//xKu/i/dp0Hz7tH7ac018U9fql7kad3S/JDaNTimlz68ubxDhMlYrVZNmDBB9evXV2BgoBo0aKCpU6fK+EMJ3DAMTZw4UbVq1VJgYKASEhK0b98+h+tkZmYqKSlJoaGhCg8P16BBg3Tu3LlLb+e2CjHh+Z577lGbNm00adIkvfHGG0WOz5kzR926dbMnEY0bN9auXbs0e/ZsDRw4UBEREfL19VVISIiio6Mve5/PP/9cW7duVXp6uho3bixJiouLcxiTn5+vhQsXqkGDBpKkYcOGKTk52eXvdNttt2n06NH2zxs2bHDp2jNmzNCUKVNcvi9KLiKyQJKU9UtV1YgqsO/P+qWqGrT4/eKY/+6v0yjHftzP31B03VydOlb1stduesMFLZ8brbxci/z86X/h6iqw+urobxfnre05VlPNY3/Rn27Zqdx8X11bI1trkxc7jJ/Rf62+Pxitxxferd/OBql5nV8cjkdUu/jvw2/FtMlQMdnk5ru9XJzw/Pzzz2vBggVasmSJWrRooW3btumhhx5SWFiYhg8fLkmaNWuWUlJStGTJEtWvX18TJkxQYmKidu3apYCAi1MJkpKSdOLECa1du1b5+fl66KGHNHjwYC1fvrzU36U45V75KfT8889ryZIlSk9PL3IsPT1dHTt2dNjXsWNH7du3T1ZrySfg7dixQ7Vr17YnPsUJCgqyJyeSVKtWLZ06deqy4y+nXbt2bl17/PjxOnPmjH07cuSIyzHAueg6eYqIzNd331Sz7zt/1ke7vwtSs7bnJUmNWl9QVX+bjh7wt48pyJdOHvFTVO38ItcsdODHQFULLyDxQYVgsRjyq2LV0i+v1wNz/k/9X7rPvknSyx/Ga+rfb5Uk/fBzlBpEZ6p68O/2829sfFTnfvfTwZPVyyN8lILx39Vepd0MF5OfTZs2qVevXurZs6fq1aun++67T927d9fWrVsvxmMYmjt3rp599ln16tVLrVu31tKlS3X8+HGtXLlS0sXf9WvWrNGiRYvUoUMHderUSfPmzdO7776r48ePe/TPp8IkP507d1ZiYqLGjx9fZvcIDCy6PPlSVas6/m3eYrE4lO18fHwcPksXq0WXCg4Odvnaf+Tv76/Q0FCHDa77/byPDvwQqAM/XPz/PuOInw78EKhTR6vKYpF6P/KL3nk5SmmfhupgeoBmD6+rGlH5urnHxdVhwSE29XzwN731YrS2fxWiI/v9Ne/pWEnSLf8vS5K0+bNQfbIsQod2B+jYQT+tWlJD76ZEqtdDv5bLd4Z3G3LHFrWpf1y1qp9Vg+jfNOSOLboh7rg+/baRMs8G6aeTEQ6bJGVkVdOJ0xf/G7Nlb20dPFldk+7/Qg1r/aYOjY/osR7/1j83NVe+1dfZrVGBFL7V3Z1NUpHpF7m5ucXe7+abb9a6deu0d+9eSdL333+vb775RnfccYck6eDBg8rIyFBCQoL9nLCwMHXo0EFpaWmSpLS0NIWHhzsUDxISEuTj46MtW7Z49M+nQrS9Cs2cOVNt2rRRkyZNHPY3a9ZMGzdudNi3ceNGNW7c2D5fx8/P74pVoNatW+vo0aPau3ev0+qPMzVr1nSYU2S1WvXDDz+oa9eupboeytbe74M07r6G9s+vTr5WknR730yNmXtYfYeeUs4FH708Llbnsn3Vov15PbfsJ4dl6o9OOCZfX0OzhtdRXo6Pmlx/Qc//44BCwi/+vPlWNbQq9Rq9OtlfhiHF1MvTY5OP646k367ulwUkVa/2uyb1+1I1Qi/oXI6fDpyooRGLemrrvtolOt9m+GjMmz007t4NWjRspX7Pq6KPtzfW65+1L+PIURHFxsY6fJ40aZImT55cZNzTTz+t7OxsNW3aVL6+vrJarXruueeUlJQkScrIyJAkRUVFOZwXFRVlP5aRkaHISMe5klWqVFFERIR9jKdUqOSnVatWSkpKUkpKisP+0aNHq3379po6dar+9Kc/KS0tTX/729/0yiuv2MfUq1dP69evV79+/eTv769rrim60qZLly7q3Lmz+vTpozlz5qhhw4bavXu3LBaLevToUaIYb7vtNo0aNUofffSRGjRooDlz5vBQxArsupvP6dPjOy573GKRBozL0IBxl/8Xq0pVafCk4xo8qfiya/uuZ9W+61l3QwU8Ynoxz+5x5qaxjxXZl5EVolFv3umhiFAePPWE5yNHjjh0Hvz9/Ysd/95772nZsmVavny5WrRooR07dmjEiBGKiYnRgAEDSh1HWakwba9CycnJshUusfmvG264Qe+9957effddtWzZUhMnTlRycrLD8vLk5GQdOnRIDRo0UM2aNS97/RUrVqh9+/a6//771bx5c40bN86leUMPP/ywBgwYoP79+6tLly6Ki4uj6gMAqFA81fa6dPrF5ZKfsWPH6umnn1a/fv3UqlUrPfjggxo5cqT9MTaFi5FOnjzpcN7Jkyftx6Kjo4vMgy0oKFBmZqbTxUylYTEuN+kEFUp2drbCwsJ0em+cQkMqXM4KeMRNY/9S3iEAZcaal6Nv33tWZ86cKbN5nIW/K3p99rCqBvuV+jr55/P0r+5vljjWGjVqaNq0aRoyZIh934wZM7R48WLt3btXhmEoJiZGY8aMsa+Ezs7OVmRkpFJTU9WvXz+lp6erefPm2rZtm9q2bStJ+uyzz9SjRw8dPXpUMTExpf4+l6pQbS8AAOC+q/1ur7vuukvPPfec6tSpoxYtWui7777TnDlz9PDDD0u6uMBnxIgRmjZtmho1amRf6h4TE6PevXtLuji/t0ePHnr00Ue1cOFC5efna9iwYerXr59HEx+J5AcAANP5Y+uqtOe7Yt68eZowYYIef/xxnTp1SjExMXrsscc0ceJE+5hx48bp/PnzGjx4sLKystSpUyetWbPG/owfSVq2bJmGDRumbt26ycfHR3369CkyD9gTaHtVErS94A1oe8HMrmbbq+enj7jd9voocVGZxlqeqPwAAGAyV7vyU9mQ/AAAYDIkP87RPwEAAF6Fyg8AACZD5cc5kh8AAEzGkOvL1S8938xIfgAAMBkqP84x5wcAAHgVKj8AAJgMlR/nSH4AADAZkh/naHsBAACvQuUHAACTofLjHMkPAAAmYxgWGW4kMO6cWxnQ9gIAAF6Fyg8AACZjk8Wthxy6c25lQPIDAIDJMOfHOdpeAADAq1D5AQDAZJjw7BzJDwAAJkPbyzmSHwAATIbKj3PM+QEAAF6Fyg8AACZjuNn2Mnvlh+QHAACTMSQZhnvnmxltLwAA4FWo/AAAYDI2WWThCc+XRfIDAIDJsNrLOdpeAADAq1D5AQDAZGyGRRYecnhZJD8AAJiMYbi52svky71oewEAAK9C5QcAAJNhwrNzJD8AAJgMyY9zJD8AAJgME56dY84PAADwKlR+AAAwGVZ7OUfyAwCAyVxMftyZ8+PBYCog2l4AAMCrUPkBAMBkWO3lHMkPAAAmY/x3c+d8M6PtBQAAvAqVHwAATIa2l3MkPwAAmA19L6dIfgAAMBs3Kz8yeeWHOT8AAMCrUPkBAMBkeMKzcyQ/AACYDBOenaPtBQAAvAqVHwAAzMawuDdp2eSVH5IfAABMhjk/ztH2AgAAXoXKDwAAZsNDDp0i+QEAwGRY7eVciZKfDz/8sMQXvPvuu0sdDAAAQFkrUfLTu3fvEl3MYrHIarW6Ew8AAPAEk7eu3FGi5Mdms5V1HAAAwENoeznn1mqvnJwcT8UBAAA8xfDAZmIuJz9Wq1VTp07Vtddeq2rVqumnn36SJE2YMEFvvPGGxwMEAADwJJeTn+eee06pqamaNWuW/Pz87PtbtmypRYsWeTQ4AABQGhYPbOblcvKzdOlSvfbaa0pKSpKvr699/3XXXafdu3d7NDgAAFAKtL2ccjn5OXbsmBo2bFhkv81mU35+vkeCAgAAKCsuJz/NmzfXhg0biuz/5z//qeuvv94jQQEAADdQ+XHK5Sc8T5w4UQMGDNCxY8dks9n0/vvva8+ePVq6dKlWr15dFjECAABX8FZ3p1yu/PTq1UurVq3S559/ruDgYE2cOFHp6elatWqVbr/99rKIEQAAVHDHjh3TAw88oBo1aigwMFCtWrXStm3b7McNw9DEiRNVq1YtBQYGKiEhQfv27XO4RmZmppKSkhQaGqrw8HANGjRI586d83ispXq31y233KK1a9d6OhYAAOABhnFxc+d8V5w+fVodO3ZU165d9cknn6hmzZrat2+fqlevbh8za9YspaSkaMmSJapfv74mTJigxMRE7dq1SwEBAZKkpKQknThxQmvXrlV+fr4eeughDR48WMuXLy/9lylGqV9sum3bNqWnp0u6OA+obdu2HgsKAAC44Sq/1f35559XbGysFi9ebN9Xv379/13OMDR37lw9++yz6tWrl6SLq8ejoqK0cuVK9evXT+np6VqzZo3+/e9/q127dpKkefPm6c4779QLL7ygmJgYN76QI5fbXkePHtUtt9yiG2+8UU8++aSefPJJtW/fXp06ddLRo0c9FhgAAChf2dnZDltubm6x4z788EO1a9dO//d//6fIyEhdf/31ev311+3HDx48qIyMDCUkJNj3hYWFqUOHDkpLS5MkpaWlKTw83J74SFJCQoJ8fHy0ZcsWj34vl5OfRx55RPn5+UpPT1dmZqYyMzOVnp4um82mRx55xKPBAQCAUiic8OzOJik2NlZhYWH2bcaMGcXe7qefftKCBQvUqFEjffrppxoyZIiGDx+uJUuWSJIyMjIkSVFRUQ7nRUVF2Y9lZGQoMjLS4XiVKlUUERFhH+MpLre9vv76a23atElNmjSx72vSpInmzZunW265xaPBAQAA11mMi5s750vSkSNHFBoaat/v7+9f7HibzaZ27dpp+vTpkqTrr79eP/zwgxYuXKgBAwaUPpAy4nLlJzY2ttiHGVqtVo/24wAAQCl56Dk/oaGhDtvlkp9atWqpefPmDvuaNWumw4cPS5Kio6MlSSdPnnQYc/LkSfux6OhonTp1yuF4QUGBMjMz7WM8xeXkZ/bs2XriiScclq9t27ZNTz75pF544QWPBgcAACq+jh07as+ePQ779u7dq7p160q6OPk5Ojpa69atsx/Pzs7Wli1bFB8fL0mKj49XVlaWtm/fbh/zxRdfyGazqUOHDh6Nt0Rtr+rVq8ti+d8Dj86fP68OHTqoSpWLpxcUFKhKlSp6+OGH1bt3b48GCAAAXHSVH3I4cuRI3XzzzZo+fbr69u2rrVu36rXXXtNrr70mSbJYLBoxYoSmTZumRo0a2Ze6x8TE2POGZs2aqUePHnr00Ue1cOFC5efna9iwYerXr5/HO0slSn7mzp3r0ZsCAIAydJWXurdv314ffPCBxo8fr+TkZNWvX19z585VUlKSfcy4ceN0/vx5DR48WFlZWerUqZPWrFljf8aPJC1btkzDhg1Tt27d5OPjoz59+iglJcWNL1I8i2G48xgkXC3Z2dkKCwvT6b1xCg1xuVsJVAo3jf1LeYcAlBlrXo6+fe9ZnTlzxmESsScV/q6InTNVPoEBVz7hMmy/5+jIqAllGmt5KvVDDiUpJydHeXl5DvvM+IcEAEClcpUrP5WNyyWE8+fPa9iwYYqMjFRwcLCqV6/usAEAgHLGW92dcjn5GTdunL744gstWLBA/v7+WrRokaZMmaKYmBgtXbq0LGIEAADwGJfbXqtWrdLSpUt166236qGHHtItt9yihg0bqm7dulq2bJnD5CYAAFAOrvJqr8rG5cpPZmam4uLiJF2c35OZmSlJ6tSpk9avX+/Z6AAAgMsKn/DszmZmLic/cXFxOnjwoCSpadOmeu+99yRdrAiFh4d7NDgAAABPczn5eeihh/T9999Lkp5++mnNnz9fAQEBGjlypMaOHevxAAEAgIuY8OyUy3N+Ro4caf/nhIQE7d69W9u3b1fDhg3VunVrjwYHAADgaW4950eS6tata393BwAAKH8WuflWd49FUjGVKPlx5dHSw4cPL3UwAAAAZa1Eyc9LL71UootZLBaSnzJ2T+NWqmKpWt5hAGWiWte8Kw8CKqmCgqv4881Sd6dKlPwUru4CAACVAK+3cIo3ZAIAAK/i9oRnAABQwVD5cYrkBwAAk3H3Kc084RkAAMBEqPwAAGA2tL2cKlXlZ8OGDXrggQcUHx+vY8eOSZLeeustffPNNx4NDgAAlAKvt3DK5eRnxYoVSkxMVGBgoL777jvl5uZKks6cOaPp06d7PEAAAABPcjn5mTZtmhYuXKjXX39dVav+72F7HTt21LfffuvR4AAAgOsKJzy7s5mZy3N+9uzZo86dOxfZHxYWpqysLE/EBAAA3METnp1yufITHR2t/fv3F9n/zTffKC4uziNBAQAANzDnxymXk59HH31UTz75pLZs2SKLxaLjx49r2bJlGjNmjIYMGVIWMQIAAHiMy22vp59+WjabTd26ddOFCxfUuXNn+fv7a8yYMXriiSfKIkYAAOACHnLonMvJj8Vi0V//+leNHTtW+/fv17lz59S8eXNVq1atLOIDAACu4jk/TpX6IYd+fn5q3ry5J2MBAAAocy4nP127dpXFcvlZ4F988YVbAQEAADe5u1ydyo+jNm3aOHzOz8/Xjh079MMPP2jAgAGeigsAAJQWbS+nXE5+XnrppWL3T548WefOnXM7IAAAgLLksbe6P/DAA3rzzTc9dTkAAFBaPOfHKY+91T0tLU0BAQGeuhwAACgllro753Lyc++99zp8NgxDJ06c0LZt2zRhwgSPBQYAAFAWXE5+wsLCHD77+PioSZMmSk5OVvfu3T0WGAAAQFlwKfmxWq166KGH1KpVK1WvXr2sYgIAAO5gtZdTLk149vX1Vffu3Xl7OwAAFVjhnB93NjNzebVXy5Yt9dNPP5VFLAAAAGXO5eRn2rRpGjNmjFavXq0TJ04oOzvbYQMAABUAy9wvq8RzfpKTkzV69GjdeeedkqS7777b4TUXhmHIYrHIarV6PkoAAFByzPlxqsTJz5QpU/SXv/xFX375ZVnGAwAAUKZKnPwYxsU0sEuXLmUWDAAAcB8POXTOpaXuzt7mDgAAKgjaXk65lPw0btz4iglQZmamWwEBAACUJZeSnylTphR5wjMAAKhYaHs551Ly069fP0VGRpZVLAAAwBNoezlV4uf8MN8HAACYgcurvQAAQAVH5cepEic/NputLOMAAAAewpwf51ya8wMAACoBKj9OufxuLwAAgMqMyg8AAGZD5ccpkh8AAEyGOT/O0fYCAABehcoPAABmQ9vLKZIfAABMhraXc7S9AACAV6HyAwCA2dD2corkBwAAsyH5cYq2FwAA8CpUfgAAMBnLfzd3zjczkh8AAMyGtpdTJD8AAJgMS92dY84PAADwqJkzZ8pisWjEiBH2fTk5ORo6dKhq1KihatWqqU+fPjp58qTDeYcPH1bPnj0VFBSkyMhIjR07VgUFBR6Pj+QHAACzMTywldK///1vvfrqq2rdurXD/pEjR2rVqlX6xz/+oa+//lrHjx/Xvffeaz9utVrVs2dP5eXladOmTVqyZIlSU1M1ceLE0gdzGSQ/AACYUTkkPufOnVNSUpJef/11Va9e3b7/zJkzeuONNzRnzhzddtttatu2rRYvXqxNmzZp8+bNkqTPPvtMu3bt0ttvv602bdrojjvu0NSpUzV//nzl5eWVPqhikPwAAIBiZWdnO2y5ublOxw8dOlQ9e/ZUQkKCw/7t27crPz/fYX/Tpk1Vp04dpaWlSZLS0tLUqlUrRUVF2cckJiYqOztbP/74owe/FckPAACmUzjh2Z1NkmJjYxUWFmbfZsyYcdl7vvvuu/r222+LHZORkSE/Pz+Fh4c77I+KilJGRoZ9zB8Tn8Ljhcc8idVeAACYjYeWuh85ckShoaH23f7+/sUOP3LkiJ588kmtXbtWAQEBbtz46qDyAwAAihUaGuqwXS752b59u06dOqUbbrhBVapUUZUqVfT1118rJSVFVapUUVRUlPLy8pSVleVw3smTJxUdHS1Jio6OLrL6q/Bz4RhPIfkBAMBkPNX2Kqlu3bpp586d2rFjh31r166dkpKS7P9ctWpVrVu3zn7Onj17dPjwYcXHx0uS4uPjtXPnTp06dco+Zu3atQoNDVXz5s098udSiLYXAABmc5Wf8BwSEqKWLVs67AsODlaNGjXs+wcNGqRRo0YpIiJCoaGheuKJJxQfH6+bbrpJktS9e3c1b95cDz74oGbNmqWMjAw9++yzGjp06GUrTqVF8gMAAMrcSy+9JB8fH/Xp00e5ublKTEzUK6+8Yj/u6+ur1atXa8iQIYqPj1dwcLAGDBig5ORkj8dC8gMAgMlUhNdbfPXVVw6fAwICNH/+fM2fP/+y59StW1cff/yx+ze/ApIfAADMhhebOkXyAwCA2ZD8OMVqLwAA4FWo/AAAYDIVYc5PRUbyAwCA2dD2coq2FwAA8CpUfgAAMBmLYchilL584865lQHJDwAAZkPbyynaXgAAwKtQ+QEAwGRY7eUcyQ8AAGZD28sp2l4AAMCrUPkBAMBkaHs5R/IDAIDZ0PZyiuQHAACTofLjHHN+AACAV6HyAwCA2dD2corkBwAAEzJ768odtL0AAIBXofIDAIDZGMbFzZ3zTYzkBwAAk2G1l3O0vQAAgFeh8gMAgNmw2sspkh8AAEzGYru4uXO+mdH2AgAAXoXKD/AHfYed1KBnMvTB69do4aRrJUlV/W0aPOm4br07S1X9DW3/KkTzxl+rrF+rlnO0gKP77/6POrX7WbExWcrNq6Jd+yL1+rvtdPREWDGjDU0ft1Y3XndME+fcpk3b6xYZEVotR6/O+JdqRlxQr0f/rPMX/Mv+S8AzaHs5ReXnDywWi1auXFneYaCcNL7ugno+kKmffgxw2P+Xycd10+3ZmvZYXY25t4EiovI18Y1D5RMk4ETrphn61+dN9cSk/6enZiaqiq9Nzz/9qQL884uM7dNj1xVXM49+dKN+Oly9jKJFWSpc7eXOZmZelfxkZGToiSeeUFxcnPz9/RUbG6u77rpL69atK+/QUM4Cgqx66m8/a+7Y2jp7xte+PyjEqsT7M/Xq5Bh9vzFE+3cGac6oWLVof0FNbzhfjhEDRY2f1V2frW+kn49V10+HIzTr1VsUdc15Nar/m8O4BnV/0309f9ALr3W67LXu6rZb1YLy9I+PWpZ12CgLhc/5cWczMa9Jfg4dOqS2bdvqiy++0OzZs7Vz506tWbNGXbt21dChQ8vsvnl5eWV2bXjOsOnHtHVdqL7bEOKwv1HrC6rqZzjsP7I/QCePVlWztheudpiAS4KDLv735+y5/7Wr/P0K9MzQrzUv9SadPhNU7Hl1rs3SA/fs0PMLb5FhWK5KrMDV5DXJz+OPPy6LxaKtW7eqT58+aty4sVq0aKFRo0Zp8+bN9nG//vqr7rnnHgUFBalRo0b68MMP7cdSU1MVHh7ucN2VK1fKYvnffxwmT56sNm3aaNGiRapfv74CAi62UCwWixYtWnTZa18qNzdX2dnZDhvKRpdep9Ww1e96c0atIsciIguUl2vR+Wxfh/1Zv1RRRGTRVgJQUVgshh5/cIt+2BOpQ0f/17oa8sAW/bg3stg5PpJUtYpVfx36lV57p71O/VbtaoULD6Pt5ZxXJD+ZmZlas2aNhg4dquDg4CLH/5jQTJkyRX379tV//vMf3XnnnUpKSlJmZqZL99u/f79WrFih999/Xzt27CjVtWfMmKGwsDD7Fhsb61IMKJmaMXkaknxczw+ro/xcr/jXAV5i+MA01audpWl/u9W+L/6Gw2rT4oReeavDZc8b9KftOnw8XOs2NrgKUaLMGB7YTMwrVnvt379fhmGoadOmVxw7cOBA3X///ZKk6dOnKyUlRVu3blWPHj1KfL+8vDwtXbpUNWvWLPW1x48fr1GjRtk/Z2dnkwCVgYatf1f1mgWa/+le+z7fKlKrm87r7od+1TN/jpOfv6HgUKtD9Se8ZoEyT7HaCxXTsAFp6nD9EY2aeqd+zfzfX/jaND+hmMiz+tfryxzGTxrxpX7YHaXRz92hNi1OqH7saXW+MfXiwf8Wtt9f+I6W/es6LV1x/VX6FkDZ8Yrkx3Bh4lbr1q3t/xwcHKzQ0FCdOnXKpfvVrVu3SOLj6rX9/f3l78+y0rK2Y0M1De7a2GHf6JeO6Mj+AL03v6Z+Oe6n/DyLru90Vt98HC5Jqt0gR1G185W+vfj5EkD5MTRswGZ1andYo6f1UMYvjnPY3l3VSp985fjzvuj5lVrw9o3a/O3Fv1xNmdtV/n5W+/Emcb9q7GPfaETynTpxyvF6qLh4t5dzXpH8NGrUSBaLRbt3777i2KpVHf82b7FYZLNdfNSlj49PkUQqP7/ovI/iWmtXujbKx+/nffXznkCHfTkXfHT29P/2f/pOhAZPPq6zWVV0/qyPhj53TLu2BWn3t8X//wyUl+EDN+u2m3/SxDnddCGnqqqHXZyUf/6Cn/Lyq+j0maBiJzmf+jXYniidOBXqcCwsJEeSdPh4GM/5qUx4q7tTXpH8REREKDExUfPnz9fw4cOLJCdZWVlFJjIXp2bNmjp79qzOnz9vv8Yf5/TAnBZOjpHNkCa8fkhV/Q1t+ypEfxt/bXmHBRRx9+0X/4I3Z8InDvtnvdpJn61vVB4hARWSVyQ/kjR//nx17NhRN954o5KTk9W6dWsVFBRo7dq1WrBggdLT0694jQ4dOigoKEjPPPOMhg8fri1btig1NbXsg8dVNe6+hg6f83N9NP+Z2pr/TO1yiggomYSkhzx+zvfptUp1XZQv2l7Oec3ylri4OH377bfq2rWrRo8erZYtW+r222/XunXrtGDBghJdIyIiQm+//bY+/vhjtWrVSu+8844mT55ctoEDAOAqVns5ZTFcmQ2McpOdna2wsDDdql6qYmGVEczJ2vWG8g4BKDMFBTnasD5ZZ86cUWho6JVPKIXC3xXxPZJVpWrAlU+4jIL8HKWtmVimsZYnr2l7AQDgLWh7OUfyAwCA2diMi5s755sYyQ8AAGbj7rwdc+c+3jPhGQAAQKLyAwCA6Vjk5pwfj0VSMZH8AABgNjzh2SnaXgAAwKtQ+QEAwGRY6u4cyQ8AAGbDai+naHsBAACvQuUHAACTsRiGLG5MWnbn3MqA5AcAALOx/Xdz53wTo+0FAAC8CpUfAABMhraXcyQ/AACYDau9nCL5AQDAbHjCs1PM+QEAAF6Fyg8AACbDE56dI/kBAMBsaHs5RdsLAAB4FSo/AACYjMV2cXPnfDMj+QEAwGxoezlF2wsAAHgVkh8AAMzG8MDmghkzZqh9+/YKCQlRZGSkevfurT179jiMycnJ0dChQ1WjRg1Vq1ZNffr00cmTJx3GHD58WD179lRQUJAiIyM1duxYFRQUuPrtr4jkBwAAkyl8vYU7myu+/vprDR06VJs3b9batWuVn5+v7t276/z58/YxI0eO1KpVq/SPf/xDX3/9tY4fP657773Xftxqtapnz57Ky8vTpk2btGTJEqWmpmrixIke+3MpxJwfAADgljVr1jh8Tk1NVWRkpLZv367OnTvrzJkzeuONN7R8+XLddtttkqTFixerWbNm2rx5s2666SZ99tln2rVrlz7//HNFRUWpTZs2mjp1qp566ilNnjxZfn5+HouXyg8AAGZTOOHZnU1Sdna2w5abm1ui2585c0aSFBERIUnavn278vPzlZCQYB/TtGlT1alTR2lpaZKktLQ0tWrVSlFRUfYxiYmJys7O1o8//uiRP5ZCJD8AAJiNIcnmxvbfrldsbKzCwsLs24wZM654a5vNphEjRqhjx45q2bKlJCkjI0N+fn4KDw93GBsVFaWMjAz7mD8mPoXHC495Em0vAABMpjTzdi49X5KOHDmi0NBQ+35/f/8rnjt06FD98MMP+uabb0p9/7JG5QcAABQrNDTUYbtS8jNs2DCtXr1aX375pWrXrm3fHx0drby8PGVlZTmMP3nypKKjo+1jLl39Vfi5cIynkPwAAGA2htyc8+Pi7QxDw4YN0wcffKAvvvhC9evXdzjetm1bVa1aVevWrbPv27Nnjw4fPqz4+HhJUnx8vHbu3KlTp07Zx6xdu1ahoaFq3rx5qf8oikPbCwAAs7nKT3geOnSoli9frn/9618KCQmxz9EJCwtTYGCgwsLCNGjQII0aNUoREREKDQ3VE088ofj4eN10002SpO7du6t58+Z68MEHNWvWLGVkZOjZZ5/V0KFDS9RucwXJDwAAcMuCBQskSbfeeqvD/sWLF2vgwIGSpJdeekk+Pj7q06ePcnNzlZiYqFdeecU+1tfXV6tXr9aQIUMUHx+v4OBgDRgwQMnJyR6Pl+QHAACzsUmyuHm+C4wSVIoCAgI0f/58zZ8//7Jj6tatq48//ti1m5cCyQ8AACbjqdVeZsWEZwAA4FWo/AAAYDZXecJzZUPyAwCA2ZD8OEXbCwAAeBUqPwAAmA2VH6dIfgAAMJurvNS9siH5AQDAZFjq7hxzfgAAgFeh8gMAgNkw58cpkh8AAMzGZkgWNxIYm7mTH9peAADAq1D5AQDAbGh7OUXyAwCA6biZ/MjcyQ9tLwAA4FWo/AAAYDa0vZwi+QEAwGxshtxqXbHaCwAAwDyo/AAAYDaG7eLmzvkmRvIDAIDZMOfHKZIfAADMhjk/TjHnBwAAeBUqPwAAmA1tL6dIfgAAMBtDbiY/HoukQqLtBQAAvAqVHwAAzIa2l1MkPwAAmI3NJsmNZ/XYzP2cH9peAADAq1D5AQDAbGh7OUXyAwCA2ZD8OEXbCwAAeBUqPwAAmA2vt3CK5AcAAJMxDJsMN97M7s65lQHJDwAAZmMY7lVvmPMDAABgHlR+AAAwG8PNOT8mr/yQ/AAAYDY2m2RxY96Oyef80PYCAABehcoPAABmQ9vLKZIfAABMxrDZZLjR9jL7UnfaXgAAwKtQ+QEAwGxoezlF8gMAgNnYDMlC8nM5tL0AAIBXofIDAIDZGIYkd57zY+7KD8kPAAAmY9gMGW60vQySHwAAUKkYNrlX+WGpOwAAgGlQ+QEAwGRoezlH8gMAgNnQ9nKK5KeSKMzCC5Tv1nOrgIrMWpBT3iEAZaagIFfS1amquPu7okD5ngumArIYZq9tmcTRo0cVGxtb3mEAANx05MgR1a5du0yunZOTo/r16ysjI8Pta0VHR+vgwYMKCAjwQGQVC8lPJWGz2XT8+HGFhITIYrGUdzheITs7W7GxsTpy5IhCQ0PLOxzA4/gZv7oMw9DZs2cVExMjH5+yW2+Uk5OjvLw8t6/j5+dnysRHou1Vafj4+JTZ3xTgXGhoKL8YYGr8jF89YWFhZX6PgIAA0yYtnsJSdwAA4FVIfgAAgFch+QEuw9/fX5MmTZK/v395hwKUCX7G4a2Y8AwAALwKlR8AAOBVSH4AAIBXIfkBAABeheQHKKHU1FSFh4eXdxhAiVgsFq1cubK8wwAqJJIfVFgDBw6UxWLRzJkzHfavXLnS5adc16tXT3PnzvVgdED5ysjI0BNPPKG4uDj5+/srNjZWd911l9atW1feoQEVHskPKrSAgAA9//zzOn36dHmHUmY88Rh6eJdDhw6pbdu2+uKLLzR79mzt3LlTa9asUdeuXTV06NAyuy8/qzALkh9UaAkJCYqOjtaMGTOcjluxYoVatGghf39/1atXTy+++KL92K233qqff/5ZI0eOlMVicVo1ysrK0mOPPaaoqCgFBASoZcuWWr16tcOYTz/9VM2aNVO1atXUo0cPnThxwuFeI0aMcBjfu3dvDRw40P65Xr16mjp1qvr376/Q0FANHjzY3lJzdm2g0OOPPy6LxaKtW7eqT58+aty4sVq0aKFRo0Zp8+bN9nG//vqr7rnnHgUFBalRo0b68MMP7ceKa+NeWlWdPHmy2rRpo0WLFql+/fr2VyZYLBYtWrTostcGKjqSH1Rovr6+mj59uubNm6ejR48WO2b79u3q27ev+vXrp507d2ry5MmaMGGCUlNTJUnvv/++ateureTkZJ04ceKyCYXNZtMdd9yhjRs36u2339auXbs0c+ZM+fr62sdcuHBBL7zwgt566y2tX79ehw8f1pgxY1z+Xi+88IKuu+46fffdd5owYYJHrw1zy8zM1Jo1azR06FAFBwcXOf7HhGbKlCnq27ev/vOf/+jOO+9UUlKSMjMzXbrf/v37tWLFCr3//vvasWOHR68NlBdebIoK75577lGbNm00adIkvfHGG0WOz5kzR926dbMnEY0bN9auXbs0e/ZsDRw4UBEREfL19VVISIiio6Mve5/PP/9cW7duVXp6uho3bixJiouLcxiTn5+vhQsXqkGDBpKkYcOGKTk52eXvdNttt2n06NH2zxs2bPDYtWFu+/fvl2EYatq06RXHDhw4UPfff78kafr06UpJSdHWrVvVo0ePEt8vLy9PS5cuVc2aNT1+baC8UPlBpfD8889ryZIlSk9PL3IsPT1dHTt2dNjXsWNH7du3T1artcT32LFjh2rXrm1PfIoTFBRkT04kqVatWjp16lSJ71GoXbt2ZXZtmJsrD+Vv3bq1/Z+Dg4MVGhrq8s9U3bp1iyQ+nro2UF5IflApdO7cWYmJiRo/fnyZ3SMwMPCKY6pWrerw2WKxOPwy8vHxKfLLKT8/v8h1imtXXOnagCQ1atRIFotFu3fvvuLY4n6mbDabJPd+Vq90baCiI/lBpTFz5kytWrVKaWlpDvubNWumjRs3OuzbuHGjGjdubJ+v4+fnd8UqUOvWrXX06FHt3bu31DHWrFnTYU6R1WrVDz/8UOrrAZeKiIhQYmKi5s+fr/Pnzxc5npWVVaLr1KxZU2fPnnW4xh/n9ABmRvKDSqNVq1ZKSkpSSkqKw/7Ro0dr3bp1mjp1qvbu3aslS5bob3/7m8Nk4Xr16mn9+vU6duyYfv3112Kv36VLF3Xu3Fl9+vTR2rVrdfDgQX3yySdas2ZNiWO87bbb9NFHH+mjjz7S7t27NWTIkBL/MgJKav78+bJarbrxxhu1YsUK7du3T+np6UpJSVF8fHyJrtGhQwcFBQXpmWee0YEDB7R8+XL7IgHA7Eh+UKkkJycXKa3fcMMNeu+99/Tuu++qZcuWmjhxopKTkx2WlycnJ+vQoUNq0KBBsfMXCq1YsULt27fX/fffr+bNm2vcuHEuzRt6+OGHNWDAAPXv319dunRRXFycunbt6vL3BJyJi4vTt99+q65du2r06NFq2bKlbr/9dq1bt04LFiwo0TUiIiL09ttv6+OPP1arVq30zjvvaPLkyWUbOFBBWAwmFQAAAC9C5QcAAHgVkh8AAOBVSH4AAIBXIfkBAABeheQHAAB4FZIfAADgVUh+AACAVyH5AQAAXoXkB0CJDRw4UL1797Z/vvXWWzVixIirHsdXX30li8Xi9NUhFotFK1euLPE1J0+erDZt2rgV16FDh2SxWHhHFlDBkfwAldzAgQNlsVhksVjk5+enhg0bKjk5WQUFBWV+7/fff19Tp04t0diSJCwAcDVUKe8AALivR48eWrx4sXJzc/Xxxx9r6NChqlq1qsaPH19kbF5envz8/Dxy34iICI9cBwCuJio/gAn4+/srOjpadevW1ZAhQ5SQkKAPP/xQ0v9aVc8995xiYmLUpEkTSdKRI0fUt29fhYeHKyIiQr169dKhQ4fs17RarRo1apTCw8NVo0YNjRs3Tpe+CvDStldubq6eeuopxcbGyt/fXw0bNtQbb7yhQ4cO2V/wWr16dVksFvuLZ202m2bMmKH69esrMDBQ1113nf75z3863Ofjjz9W48aNFRgYqK5duzrEWVJPPfWUGjdurKCgIMXFxWnChAnKz88vMu7VV19VbGysgoKC1LdvX505c8bh+KJFi9SsWTMFBASoadOmeuWVV1yOBUD5IvkBTCgwMFB5eXn2z+vWrdOePXu0du1arV69Wvn5+UpMTFRISIg2bNigjRs3qlq1aurRo4f9vBdffFGpqal688039c033ygzM1MffPCB0/v2799f77zzjlJSUpSenq5XX31V1apVU2xsrFasWCFJ2rNnj06cOKGXX35ZkjRjxgwtXbpUCxcu1I8//qiRI0fqgQce0Ndffy3pYpJ277336q677tKOHTv0yCOP6Omnn3b5zyQkJESpqanatWuXXn75Zb3++ut66aWXHMbs379f7733nlatWqU1a9bou+++0+OPP24/vmzZMk2cOFHPPfec0tPTNX36dE2YMEFLlixxOR4A5cgAUKkNGDDA6NWrl2EYhmGz2Yy1a9ca/v7+xpgxY+zHo6KijNzcXPs5b731ltGkSRPDZrPZ9+Xm5hqBgYHGp59+ahiGYdSqVcuYNWuW/Xh+fr5Ru3Zt+70MwzC6dOliPPnkk4ZhGMaePXsMScbatWuLjfPLL780JBmnT5+278vJyTGCgoKMTZs2OYwdNGiQcf/99xuGYRjjx483mjdv7nD8qaeeKnKtS0kyPvjgg8senz17ttG2bVv750mTJhm+vr7G0aNH7fs++eQTw8fHxzhx4oRhGIbRoEEDY/ny5Q7XmTp1qhEfH28YhmEcPHjQkGR89913l70vgPLHnB/ABFavXq1q1aopPz9fNptNf/7znzV58mT78VatWjnM8/n++++1f/9+hYSEOFwnJydHBw4c0JkzZ3TixAl16NDBfqxKlSpq165dkdZXoR07dsjX11ddunQpcdz79+/XhQsXdPvttzvsz8vL0/XXXy9JSk9Pd4hDkuLj40t8j0J///vflZKSogMHDujcuXMqKChQaGiow5g6dero2muvdbiPzWbTnj17FBISogMHDmjQoEF69NFH7WMKCgoUFhbmcjwAyg/JD2ACXbt21YIFC+Tn56eYmBhVqeL4r3ZwcLDD53Pnzqlt27ZatmxZkWvVrFmzVDEEBga6fM65c+ckSR999JFD0iFdnMfkKWlpaUpKStKUKVOUmJiosLAwvfvuu3rxxRddjvX1118vkoz5+vp6LFYAZY/kBzCB4OBgNWzYsMTjb7jhBv39739XZGRkkepHoVq1amnLli3q3LmzpIsVju3bt+uGG24odnyrVq1ks9n09ddfKyEhocjxwsqT1Wq172vevLn8/f11+PDhy1aMmjVrZp+8XWjz5s1X/pJ/sGnTJtWtW1d//etf7ft+/vnnIuMOHz6s48ePKyYmxn4fHx8fNWnSRFFRUYqJidFPP/2kpKQkl+4PoGJhwjPghZKSknTNNdeoV69e2rBhgw4ePKivvvpKw4cP19GjRyVJTz75pGbOnKmVK1dq9+7devzxx50+o6devXoaMGCAHn74Ya1cudJ+zffee0+SVLduXVksFq1evVq//PKLzp07p5CQEI0ZM0YjR47UkiVLdODAAX377beaN2+efRLxX/7yF+3bt09jx47Vnj17tHz5cqWmprr0fRs1aqTDhw/r3Xff1YEDB5SSklLs5O2AgAANGDBA33//vTZs2KDhw4erb9++io6OliRNmTJFM2bMUEpKivbu3audO3dq8eLFmjNnjkvxAChfJD+AFwoKCtL69etVp04d3XvvvWrWrJkGDRqknJwceyVo9OjRevDBBzVgwADFx8crJCRE99xzj9PrLliwQPfdd58ef/xxNW3aVI8++qjOnz8vSbr22ms1ZcoUPf3004qKitKwYcMkSVOnTtWECRM0Y8YMNWvWTD169NBHH32k+vXrS7o4D2fFihVauXKlrrvuOi1cuFDTp0936fvefffdGjlypIYNG6Y2bdpo06ZNmjBhQpFxDRs21L333qs777xT3bt3V+vWrR2Wsj/yyCNatGiRFi9erFatWqlLly5KTU21xwqgcrAYl5u9CAAAYEJUfgAAgFch+QEAAF6F5AcAAHgVkh8AAOBVSH4AAIBXIfkBAABeheQHAAB4FZIfAADgVUh+AACAVyH5AQAAXoXkBwAAeJX/D7mAPV5zkupeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall da validação (%):  85.91549295774648\n",
            "Acurácia da validação (%):  77.50148016577857\n",
            "SCORE do modelo (%):  87.80362755254333\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall da validação (%):  82.04225352112677\n",
            "Acurácia da validação (%):  81.23149792776792\n",
            "SCORE do modelo (%):  87.92249749793689\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAGyCAYAAAALaqWsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFJUlEQVR4nO3deXgUVbrH8V9nX0gnBCEhEtn3VUGZiCJIJIALKF4uGhWEEUcJyubCjCAEJYCIGAbBERVQcJlBuYiKRpwBhAiCRBHDKsoaUEMSFrN11/2DSWsLtOl0hyTV38/z1PPYVadOvZXJpF/ec06VxTAMQwAAAD7Cr6oDAAAAuJhIfgAAgE8h+QEAAD6F5AcAAPgUkh8AAOBTSH4AAIBPIfkBAAA+heQHAAD4FJIfAADgUwKqOgCUj91u15EjRxQRESGLxVLV4QAA3GQYhk6ePKm4uDj5+VVe7aGwsFDFxcUe9xMUFKSQkBAvRFQNGagRDh48aEhiY2NjY6vh28GDByvtu+KXX34xYuv5eyXO2NhY45dffin3tdeuXWvcdNNNRv369Q1Jxrvvvus4VlxcbDz66KNGu3btjLCwMKN+/frG3XffbRw+fNipj59//tm48847jYiICCMyMtIYNmyYcfLkSac2X331lXHNNdcYwcHBRoMGDYwZM2a4/XOi8lNDRERESJJ++LKRrLUYrYQ53d7npqoOAag0pfYirf3+Rcff88pQXFysnOM2/bC1kawRFf+uKDhpV8PO36u4uLjc1Z/Tp0+rY8eOGjZsmG677TanY2fOnNGXX36piRMnqmPHjjpx4oQefvhh3XLLLdqyZYujXXJyso4ePaqMjAyVlJTo3nvv1YgRI7Rs2bKzcRUUqHfv3kpMTNSCBQu0fft2DRs2TFFRURoxYkS574/kp4YoG+qy1vLz6BcaqM4C/IOrOgSg0l2MqQu1IiyqFVHx69jl/rl9+/ZV3759z3ssMjJSGRkZTvv+/ve/66qrrtKBAwd02WWXKTs7W6tXr9YXX3yhLl26SJLmzp2rfv36adasWYqLi9PSpUtVXFysV155RUFBQWrbtq2ysrI0e/Zst5IfvkUBADAZm2H3eJPOVlp+uxUVFXktxvz8fFksFkVFRUmSMjMzFRUV5Uh8JCkxMVF+fn7atGmTo0337t0VFBTkaJOUlKRdu3bpxIkT5b42yQ8AACZjl+HxJknx8fGKjIx0bGlpaV6Jr7CwUI899pjuuOMOWa1WSVJOTo7q1avn1C4gIEDR0dHKyclxtImJiXFqU/a5rE15MOwFAADO6+DBg47kRJKCgz0fmi4pKdGgQYNkGIbmz5/vcX8VQfIDAIDJ2GWX3cPzJclqtTolP54qS3x++OEHffrpp059x8bG6vjx407tS0tLlZubq9jYWEebY8eOObUp+1zWpjwY9gIAwGRshuHx5m1lic+ePXv0ySefqE6dOk7HExISlJeXp61btzr2ffrpp7Lb7erataujzbp161RSUuJok5GRoZYtW6p27drljoXkBwAAeOzUqVPKyspSVlaWJGn//v3KysrSgQMHVFJSottvv11btmzR0qVLZbPZlJOTo5ycHMcDGVu3bq0+ffrovvvu0+bNm7VhwwalpKRo8ODBiouLkyTdeeedCgoK0vDhw7Vjxw699dZbev755zV27Fi3YmXYCwAAk/ntpOWKnu+uLVu2qGfPno7PZQnJkCFDNHnyZK1cuVKS1KlTJ6fz/v3vf6tHjx6SpKVLlyolJUW9evWSn5+fBg4cqPT0dEfbyMhIffzxxxo5cqQ6d+6sSy65RJMmTXJrmbtE8gMAgOnYZch2kZOfHj16yHAxXObqWJno6GjHAw0vpEOHDlq/fr3b8f0Ww14AAMCnUPkBAMBkqmLYqyYh+QEAwGQ8XbFVGau9qhOGvQAAgE+h8gMAgMnY/7t5cr6ZkfwAAGAyNg9Xe3lybk1A8gMAgMnYjLObJ+ebGXN+AACAT6HyAwCAyTDnxzWSHwAATMYui2yyeHS+mTHsBQAAfAqVHwAATMZunN08Od/MSH4AADAZm4fDXp6cWxMw7AUAAHwKlR8AAEyGyo9rJD8AAJiM3bDIbniw2suDc2sChr0AAIBPofIDAIDJMOzlGskPAAAmY5OfbB4M7ti8GEt1RPIDAIDJGB7O+TGY8wMAAGAeVH4AADAZ5vy4RvIDAIDJ2Aw/2QwP5vyY/PUWDHsBAACfQuUHAACTscsiuwf1DbvMXfoh+QEAwGSY8+Maw14AAMCnUPkBAMBkPJ/wzLAXAACoQc7O+fHgxaYMewEAAJgHlR8AAEzG7uG7vVjtBQAAahTm/LhG8gMAgMnY5cdzflxgzg8AAPApVH4AADAZm2GRzfDgIYcenFsTkPwAAGAyNg8nPNsY9gIAADAPKj8AAJiM3fCT3YPVXnZWewEAgJqEYS/XGPYCAAA+hcoPAAAmY5dnK7bs3gulWiL5AQDAZDx/yKG5B4bMfXcAAAC/Q+UHAACT8fzdXuaujZD8AABgMnZZZJcnc354wjMAAKhBqPy4Zu67AwAA+B0qPwAAmIznDzk0d22E5AcAAJOxGxbZPXnOj8nf6m7u1A4AAOB3qPwAAGAydg+Hvcz+kEOSHwAATMbzt7qbO/kx990BAAD8DpUfAABMxiaLbB48qNCTc2sCKj8AAJhM2bCXJ5u71q1bp5tvvllxcXGyWCxasWKF03HDMDRp0iTVr19foaGhSkxM1J49e5za5ObmKjk5WVarVVFRURo+fLhOnTrl1Obrr7/Wtddeq5CQEMXHx2vmzJlux0ryAwAAPHb69Gl17NhR8+bNO+/xmTNnKj09XQsWLNCmTZsUHh6upKQkFRYWOtokJydrx44dysjI0KpVq7Ru3TqNGDHCcbygoEC9e/dWw4YNtXXrVj3zzDOaPHmy/vGPf7gVK8NeAACYjE2eDV3ZKnBO37591bdv3/MeMwxDc+bM0RNPPKH+/ftLkpYsWaKYmBitWLFCgwcPVnZ2tlavXq0vvvhCXbp0kSTNnTtX/fr106xZsxQXF6elS5equLhYr7zyioKCgtS2bVtlZWVp9uzZTknSH6HyAwCAyXhr2KugoMBpKyoqqlA8+/fvV05OjhITEx37IiMj1bVrV2VmZkqSMjMzFRUV5Uh8JCkxMVF+fn7atGmTo0337t0VFBTkaJOUlKRdu3bpxIkT5Y6H5AcAAJMpe7GpJ5skxcfHKzIy0rGlpaVVKJ6cnBxJUkxMjNP+mJgYx7GcnBzVq1fP6XhAQICio6Od2pyvj99eozwY9gIAAOd18OBBWa1Wx+fg4OAqjMZ7qPwAAGAyhiyye7AZ/50vZLVanbaKJj+xsbGSpGPHjjntP3bsmONYbGysjh8/7nS8tLRUubm5Tm3O18dvr1EeJD8AAJiMt4a9vKVx48aKjY3VmjVrHPsKCgq0adMmJSQkSJISEhKUl5enrVu3Otp8+umnstvt6tq1q6PNunXrVFJS4miTkZGhli1bqnbt2uWOh+QHAAB47NSpU8rKylJWVpaks5Ocs7KydODAAVksFo0ePVpPPfWUVq5cqe3bt+uee+5RXFycBgwYIElq3bq1+vTpo/vuu0+bN2/Whg0blJKSosGDBysuLk6SdOeddyooKEjDhw/Xjh079NZbb+n555/X2LFj3YqVOT8AAJiM3bDIblR8qXtFzt2yZYt69uzp+FyWkAwZMkSLFi3So48+qtOnT2vEiBHKy8vTNddco9WrVyskJMRxztKlS5WSkqJevXrJz89PAwcOVHp6uuN4ZGSkPv74Y40cOVKdO3fWJZdcokmTJrm1zF2SLIZhGG7fIS66goICRUZG6sTuJrJGULCDOfXrfmtVhwBUmlJbkdZ8l678/HynScTeVPZdMXrDLQquFVjhfopOlWhOt5WVGmtV4lsUAAD4FIa9AAAwmaoY9qpJSH4AADAZu/xk92Bwx5NzawJz3x0AAMDvUPkBAMBkbIZFNg+Grjw5tyYg+QEAwGSY8+MayQ8AACZj/ObN7BU938zMfXcAAAC/Q+UHAACTsckimzyY8+PBuTUByQ8AACZjNzybt2M3+bsfGPYCAAA+hcrPbyxatEijR49WXl5eVYcCL9n+ebj++UI97dkeptxjgXry5f26um++JKm0RFo0o76++NSqoz8EKdxq1+XXntTwvx5RndhSRx/Lno/R5k+s+m5HqAKCDL2zc7vTNQpy/TU9paH2Z4fq5Al/RdYpVUJSvu6dcFThEfaLer9Au44/aeDgPWrWMl91LinU1L9epczP4hzHo2oX6t6/7NAVV/6o8Fol+uarOlrwfAcdOVRLklQrolh3DcvWFVf+qLoxZ5SfF6zM9fX12sutdeZ0xd8VhYvL7uGEZ0/OrQmq9O6GDh0qi8Wi6dOnO+1fsWKFLBb3ynWNGjXSnDlzvBgdzKDwjJ+atP1FKdMOnXOs6Bc/7d0epjtHH9O8j3Zr0sL9OrQvWE8ObeLUrrTYou435+nGIT+d9xoWPykhKV9TFn2nlz/L1vg5B7RtfYTSH4uvlHsCXAkJsWn/vki98FyH8xw1NPHpTaofd0apf+2qUcN76PixME2bvUHBIWcT/jqXFKrOJYVa+EJbPTCkl55Lu0Jduh7T6Me2XdwbgUfssni8mVmVV35CQkI0Y8YM3X///apdu3ZVh1MpiouLFRQUVNVh+KQrrz+pK68/ed5j4Va7pr+1z2nfyKcP6aF+LXX8UKDqNSiRJN3zSI4k6eO3os/bT0SUTTcP+dnxOaZBiW4e8pP+Ob+eN24BcMuWTTHasinmvMcubXBardud0F/uuV4Hvj/7pu55z3bU0hUfqkevQ/ro/Ub6Yb9VT0/s6jgn50i4Fr/URo88sVV+/nbZbeauCMA3VPlvcWJiomJjY5WWluay3fLly9W2bVsFBwerUaNGevbZZx3HevTooR9++EFjxoyRxWJxWTXKy8vT/fffr5iYGIWEhKhdu3ZatWqVU5uPPvpIrVu3Vq1atdSnTx8dPXrU6VqjR492aj9gwAANHTrU8blRo0aaOnWq7rnnHlmtVo0YMUKLFi1SVFSUy75R9U4X+MtiMRQeaatwHz/nBGjDh1HqkHDKi5EBngsMOvt7XVzs79hnGBaVlPirTYefL3SawsNLdOZMAIlPDVL2hGdPNjOr8t9kf39/TZs2TXPnztWhQ+cOTUjS1q1bNWjQIA0ePFjbt2/X5MmTNXHiRC1atEiS9M4776hBgwZKTU3V0aNHL5hQ2O129e3bVxs2bNDrr7+ub7/9VtOnT5e//69/CM6cOaNZs2bptdde07p163TgwAGNHz/e7fuaNWuWOnbsqG3btmnixIle7RuVo7jQopefjlOPAScqNFcn7YGGuqVJB915RTuF1bJpzKyDlRAlUHEHf4jQ8ZxQ3Ttih2rVKlZAgF2337lbdev9oug6Rec9xxpZpDuG7NKHKxtd3GDhkbI5P55sZlblw16SdOutt6pTp0568skn9fLLL59zfPbs2erVq5cjiWjRooW+/fZbPfPMMxo6dKiio6Pl7++viIgIxcbGXvA6n3zyiTZv3qzs7Gy1aNFCktSkifP8jpKSEi1YsEBNmzaVJKWkpCg1NdXte7r++us1btw4x+f169e71XdRUZGKin79Y1RQUOB2DCi/0hLp6fsbSYY0avr5k/A/cv+Uw0oem6PD3wXrlbT6enHKpRqVVrG+gMpgs/npqSe66uHHvtTbH3wgW6lF27bW1Refx8iic9c2h4aVaMqMz3Xg+wgtfbVVFUQMVI5qk9rNmDFDixcvVnZ29jnHsrOz1a1bN6d93bp10549e2SzlX94IisrSw0aNHAkPucTFhbmSE4kqX79+jp+/Hi5r1GmS5cuHvWdlpamyMhIxxYfz+TZylKW+Bw7HKS0N/dVeIVWdL1SXda8SAlJBXp4xiGtWnyJfj5WLf59ATjs3R2lUcOv1+19b1TyrX006ZGrZbUWK+douFO70NASTZ2VqTNnAjT1ia6yMeRVo9hlcbzfq0KbySc8V5vf5u7duyspKUkTJkyotGuEhob+YZvAQOelnBaLRYbx67+I/Pz8nD5LZ6tFvxceHn7Ovj/q+7cmTJig/Px8x3bwIEMolaEs8Tm8P1jT39ora3TF5/r8Vtn/rCXF1eb/YoCTM6cDVZAfrLgGp9Ss5QllflbfcSw0rERPPbtRpSUWpU7oqpLfzBFCzWB4uNLLMHnyU63+WTp9+nR16tRJLVu2dNrfunVrbdiwwWnfhg0b1KJFC8d8naCgoD+sAnXo0EGHDh3S7t27XVZ/XKlbt67TnCKbzaZvvvlGPXv2rFB/FxIcHKzg4GCv9umLfjntpyP7f/055hwM0r5vQhURVaromBJNva+x9m4PVeqS72S3WZR7/Oz/JSKibAoMOpvBHD8UqJN5ATp+OFB2m7Tvm7NJdFzjIoWG27V5TYRO/Biolp3OKCTcrh92hWjh1Di1vfKUYuOLL/5Nw6eFhJYq7tJfJ9vH1D+jJs3ydLIgSD8eD9M1PQ4rPy9IPx4LU6OmBbp/1Nf6/LP62vbF2dWJoWElevrZjQoOsemZp7ooLLxUYeFnl8Hn5wXLbjf3l6JZ8FZ316pV8tO+fXslJycrPT3daf+4ceN05ZVXaurUqfrf//1fZWZm6u9//7teeOEFR5tGjRpp3bp1Gjx4sIKDg3XJJZec0/91112n7t27a+DAgZo9e7aaNWumnTt3ymKxqE+fPuWK8frrr9fYsWP1/vvvq2nTppo9ezYPRazGdn8Vpkdvb+b4/OLkSyVJNwzK1V3jcvT5x5GSpAdvcJ7PMPNfe9Xx6rNfIEtm1VfG278uc3+wd0unNkEhhj5cWkcvTr5UJcUW1Y0rVre++frfFPeHSwFPNW95QjPSf/3H4ohR30iSMj6M13NpnRVdp1D3pXyjqNqFOvFziNZ8FK83Fv/6+9+sRZ5atT0hSXrlzQynvocOukHHc86tagM1TbVKfiQpNTVVb731ltO+K664Qm+//bYmTZqkqVOnqn79+kpNTXVaXp6amqr7779fTZs2VVFR0QWHk5YvX67x48frjjvu0OnTp9WsWbNzHrLoyrBhw/TVV1/pnnvuUUBAgMaMGeP1qg+8p+PVp/TRkawLHnd1rMz4OQc0fs6BCx7v1O2U5ry3pwLRAd63Pauu+nUfcMHjK5c31crlTS94/I/OR83AE55dsxgXyhJQrRQUFCgyMlIndjeRNcLcv5TwXf2631rVIQCVptRWpDXfpSs/P19Wq7VSrlH2XdH/42EKDK/4w3VLThfr/3q/UqmxViW+RQEAgE+pdsNeAADAM56+n8vsS91JfgAAMBlWe7nGsBcAAPApVH4AADAZKj+ukfwAAGAyJD+uMewFAAB8CpUfAABMhsqPayQ/AACYjCHPlqub/enHJD8AAJgMlR/XmPMDAAB8CpUfAABMhsqPayQ/AACYDMmPawx7AQAAn0LlBwAAk6Hy4xrJDwAAJmMYFhkeJDCenFsTMOwFAAB8CpUfAABMxi6LRw859OTcmoDkBwAAk2HOj2sMewEAAJ9C5QcAAJNhwrNrJD8AAJgMw16ukfwAAGAyVH5cY84PAADwKVR+AAAwGcPDYS+zV35IfgAAMBlDkmF4dr6ZMewFAAB8CpUfAABMxi6LLDzh+YJIfgAAMBlWe7nGsBcAAPApVH4AADAZu2GRhYccXhCVHwAATMYwPN/cYbPZNHHiRDVu3FihoaFq2rSppk6dKuM3HRmGoUmTJql+/foKDQ1VYmKi9uzZ49RPbm6ukpOTZbVaFRUVpeHDh+vUqVPe+JE4IfkBAAAemTFjhubPn6+///3vys7O1owZMzRz5kzNnTvX0WbmzJlKT0/XggULtGnTJoWHhyspKUmFhYWONsnJydqxY4cyMjK0atUqrVu3TiNGjPB6vAx7AQBgMhd7wvPGjRvVv39/3XjjjZKkRo0a6Y033tDmzZv/25+hOXPm6IknnlD//v0lSUuWLFFMTIxWrFihwYMHKzs7W6tXr9YXX3yhLl26SJLmzp2rfv36adasWYqLi6vw/fwelR8AAEymLPnxZJOkgoICp62oqOi817v66qu1Zs0a7d69W5L01Vdf6bPPPlPfvn0lSfv371dOTo4SExMd50RGRqpr167KzMyUJGVmZioqKsqR+EhSYmKi/Pz8tGnTJq/+fKj8AABgMt6a8BwfH++0/8knn9TkyZPPaf/444+roKBArVq1kr+/v2w2m55++mklJydLknJyciRJMTExTufFxMQ4juXk5KhevXpOxwMCAhQdHe1o4y0kPwAA4LwOHjwoq9Xq+BwcHHzedm+//baWLl2qZcuWqW3btsrKytLo0aMVFxenIUOGXKxwy43kBwAAk6nIiq3fny9JVqvVKfm5kEceeUSPP/64Bg8eLElq3769fvjhB6WlpWnIkCGKjY2VJB07dkz169d3nHfs2DF16tRJkhQbG6vjx4879VtaWqrc3FzH+d7CnB8AAEzmbPLjyZwf96535swZ+fk5pxT+/v6y2+2SpMaNGys2NlZr1qxxHC8oKNCmTZuUkJAgSUpISFBeXp62bt3qaPPpp5/Kbrera9euFfxJnB+VHwAA4JGbb75ZTz/9tC677DK1bdtW27Zt0+zZszVs2DBJksVi0ejRo/XUU0+pefPmaty4sSZOnKi4uDgNGDBAktS6dWv16dNH9913nxYsWKCSkhKlpKRo8ODBXl3pJZH8AABgOhd7qfvcuXM1ceJEPfjggzp+/Lji4uJ0//33a9KkSY42jz76qE6fPq0RI0YoLy9P11xzjVavXq2QkBBHm6VLlyolJUW9evWSn5+fBg4cqPT09Arfx4VYDMOTUUFcLAUFBYqMjNSJ3U1kjWC0EubUr/utVR0CUGlKbUVa81268vPzyzWPpiLKviuavjZB/mEhf3zCBdjOFGrf3WmVGmtV4lsUAAD4FIa9AAAwmYs97FXTkPwAAGA2xn83T843MZIfAADMxsPKj0xe+WHODwAA8ClUfgAAMBlvPeHZrEh+AAAwGSY8u8awFwAA8ClUfgAAMBvD4tmkZZNXfkh+AAAwGeb8uMawFwAA8ClUfgAAMBsecuhSuZKflStXlrvDW265pcLBAAAAz7Hay7VyJT8DBgwoV2cWi0U2m82TeAAAACpVuZIfu91e2XEAAABvMvnQlSc8mvNTWFiokJAQb8UCAAC8gGEv19xe7WWz2TR16lRdeumlqlWrlr777jtJ0sSJE/Xyyy97PUAAAOAmwwubibmd/Dz99NNatGiRZs6cqaCgIMf+du3aaeHChV4NDgAAwNvcTn6WLFmif/zjH0pOTpa/v79jf8eOHbVz506vBgcAACrC4oXNvNye83P48GE1a9bsnP12u10lJSVeCQoAAHiA5/y45Hblp02bNlq/fv05+//1r3/p8ssv90pQAAAAlcXtys+kSZM0ZMgQHT58WHa7Xe+884527dqlJUuWaNWqVZURIwAAcAeVH5fcrvz0799f7733nj755BOFh4dr0qRJys7O1nvvvacbbrihMmIEAADuKHuruyebiVXoOT/XXnutMjIyvB0LAABApavwQw63bNmi7OxsSWfnAXXu3NlrQQEAgIozjLObJ+ebmdvJz6FDh3THHXdow4YNioqKkiTl5eXp6quv1ptvvqkGDRp4O0YAAOAO5vy45Pacnz//+c8qKSlRdna2cnNzlZubq+zsbNntdv35z3+ujBgBAAC8xu3Kz9q1a7Vx40a1bNnSsa9ly5aaO3eurr32Wq8GBwAAKsDTSctMeHYWHx9/3ocZ2mw2xcXFeSUoAABQcRbj7ObJ+Wbm9rDXM888o1GjRmnLli2OfVu2bNHDDz+sWbNmeTU4AABQAbzY1KVyVX5q164ti+XXEtjp06fVtWtXBQScPb20tFQBAQEaNmyYBgwYUCmBAgAAeEO5kp85c+ZUchgAAMBrmPPjUrmSnyFDhlR2HAAAwFtY6u5ShR9yKEmFhYUqLi522me1Wj0KCAAAoDK5PeH59OnTSklJUb169RQeHq7atWs7bQAAoIox4dklt5OfRx99VJ9++qnmz5+v4OBgLVy4UFOmTFFcXJyWLFlSGTECAAB3kPy45Paw13vvvaclS5aoR48euvfee3XttdeqWbNmatiwoZYuXark5OTKiBMAAMAr3K785ObmqkmTJpLOzu/Jzc2VJF1zzTVat26dd6MDAADuK1vt5clmYm4nP02aNNH+/fslSa1atdLbb78t6WxFqOxFpwAAoOqUPeHZk83M3E5+7r33Xn311VeSpMcff1zz5s1TSEiIxowZo0ceecTrAQIAAHiT23N+xowZ4/jvxMRE7dy5U1u3blWzZs3UoUMHrwYHAAAqgOf8uOTRc34kqWHDhmrYsKE3YgEAAKh05Up+0tPTy93hQw89VOFgAACA5yzy8K3uXoukeipX8vPcc8+VqzOLxULyAwAAqrVyJT9lq7tQ9W5t0V4BlsCqDgOoFP6tPR6JB6ovP9vFuxYvNnWJvzQAAJgNE55dcnupOwAAQE1G5QcAALOh8uMSyQ8AACbj6VOaecIzAACAiVQo+Vm/fr3uuusuJSQk6PDhw5Kk1157TZ999plXgwMAABVgeGEzMbeTn+XLlyspKUmhoaHatm2bioqKJEn5+fmaNm2a1wMEAABuIvlxye3k56mnntKCBQv00ksvKTDw1+fNdOvWTV9++aVXgwMAAPA2tyc879q1S927dz9nf2RkpPLy8rwREwAA8AATnl1zu/ITGxurvXv3nrP/s88+U5MmTbwSFAAA8EDZE5492dx0+PBh3XXXXapTp45CQ0PVvn17bdmy5deQDEOTJk1S/fr1FRoaqsTERO3Zs8epj9zcXCUnJ8tqtSoqKkrDhw/XqVOnPP5x/J7byc99992nhx9+WJs2bZLFYtGRI0e0dOlSjR8/Xg888IDXAwQAAG66yHN+Tpw4oW7duikwMFAffvihvv32Wz377LOqXbu2o83MmTOVnp6uBQsWaNOmTQoPD1dSUpIKCwsdbZKTk7Vjxw5lZGRo1apVWrdunUaMGFHRn8IFuT3s9fjjj8tut6tXr146c+aMunfvruDgYI0fP16jRo3yeoAAAKB6mzFjhuLj4/Xqq6869jVu3Njx34ZhaM6cOXriiSfUv39/SdKSJUsUExOjFStWaPDgwcrOztbq1av1xRdfqEuXLpKkuXPnql+/fpo1a5bi4uK8Fq/blR+LxaK//e1vys3N1TfffKPPP/9cP/74o6ZOneq1oAAAQMWVzfnxZJOkgoICp61shffvrVy5Ul26dNH//M//qF69err88sv10ksvOY7v379fOTk5SkxMdOyLjIxU165dlZmZKUnKzMxUVFSUI/GRpMTERPn5+WnTpk1e/flU+CGHQUFBatOmja666irVqlXLmzEBAABPeGnYKz4+XpGRkY4tLS3tvJf77rvvNH/+fDVv3lwfffSRHnjgAT300ENavHixJCknJ0eSFBMT43ReTEyM41hOTo7q1avndDwgIEDR0dGONt7i9rBXz549ZbFceCLUp59+6lFAAACgejh48KCsVqvjc3Bw8Hnb2e12denSxfG8v8svv1zffPONFixYoCFDhlyUWN3hdvLTqVMnp88lJSXKysrSN998Uy1vEAAAn+PhUveyyo/VanVKfi6kfv36atOmjdO+1q1ba/ny5ZLOrhSXpGPHjql+/fqONseOHXPkFbGxsTp+/LhTH6WlpcrNzXWc7y1uJz/PPffcefdPnjy5UpajAQAAN13kt7p369ZNu3btctq3e/duNWzYUNLZyc+xsbFas2aNI9kpKCjQpk2bHCvFExISlJeXp61bt6pz586Szo4m2e12de3a1YObOZfXXmx611136ZVXXvFWdwAAoIYYM2aMPv/8c02bNk179+7VsmXL9I9//EMjR46UdHax1OjRo/XUU09p5cqV2r59u+655x7FxcVpwIABks5Wivr06aP77rtPmzdv1oYNG5SSkqLBgwd7daWXVIHKz4VkZmYqJCTEW90BAICKusiVnyuvvFLvvvuuJkyYoNTUVDVu3Fhz5sxRcnKyo82jjz6q06dPa8SIEcrLy9M111yj1atXO+UOS5cuVUpKinr16iU/Pz8NHDhQ6enpHtzI+bmd/Nx2221Onw3D0NGjR7VlyxZNnDjRa4EBAICKqYrXW9x000266aabLtynxaLU1FSlpqZesE10dLSWLVvm/sXd5HbyExkZ6fTZz89PLVu2VGpqqnr37u21wAAAACqDW8mPzWbTvffeq/bt2zs9shoAAKCmcGvCs7+/v3r37s3b2wEAqM4u8ru9ahq3V3u1a9dO3333XWXEAgAAvMBbr7cwK7eTn6eeekrjx4/XqlWrdPTo0XPe+wEAAFCdlXvOT2pqqsaNG6d+/fpJkm655Ran11wYhiGLxSKbzeb9KAEAgHtMXr3xRLmTnylTpugvf/mL/v3vf1dmPAAAwFMX+Tk/NU25kx/DOPuTuO666yotGAAAgMrm1lJ3V29zBwAA1UNVPOSwJnEr+WnRosUfJkC5ubkeBQQAADzEsJdLbiU/U6ZMOecJzwAAADWJW8nP4MGDVa9evcqKBQAAeAHDXq6VO/lhvg8AADUEw14ulfshh2WrvQAAAGqycld+7HZ7ZcYBAAC8hcqPS27N+QEAANUfc35cI/kBAMBsqPy45PaLTQEAAGoyKj8AAJgNlR+XSH4AADAZ5vy4xrAXAADwKVR+AAAwG4a9XCL5AQDAZBj2co1hLwAA4FOo/AAAYDYMe7lE8gMAgNmQ/LjEsBcAAPApVH4AADAZy383T843M5IfAADMhmEvl0h+AAAwGZa6u8acHwAA4FOo/AAAYDYMe7lE8gMAgBmZPIHxBMNeAADAp1D5AQDAZJjw7BrJDwAAZsOcH5cY9gIAAD6Fyg8AACbDsJdrJD8AAJgNw14uMewFAAB8CpUfAABMhmEv10h+AAAwG4a9XCL5AQDAbEh+XGLODwAA8ClUfgAAMBnm/LhG8gMAgNkw7OUSw14AAMCnUPkBAMBkLIYhi1Hx8o0n59YEJD8AAJgNw14uMewFAAB8CpUfAABMhtVerpH8AABgNgx7ucSwFwAA8ClUfgAAMBmGvVyj8gMAgNkYXtg8MH36dFksFo0ePdqxr7CwUCNHjlSdOnVUq1YtDRw4UMeOHXM678CBA7rxxhsVFhamevXq6ZFHHlFpaalnwZwHyQ8AACZTVvnxZKuoL774Qi+++KI6dOjgtH/MmDF677339M9//lNr167VkSNHdNtttzmO22w23XjjjSouLtbGjRu1ePFiLVq0SJMmTap4MBdA8gMAALzi1KlTSk5O1ksvvaTatWs79ufn5+vll1/W7Nmzdf3116tz58569dVXtXHjRn3++eeSpI8//ljffvutXn/9dXXq1El9+/bV1KlTNW/ePBUXF3s1TpIfAADMxkvDXgUFBU5bUVGRy8uOHDlSN954oxITE532b926VSUlJU77W7Vqpcsuu0yZmZmSpMzMTLVv314xMTGONklJSSooKNCOHTsq+IM4P5IfAABMyBtDXvHx8YqMjHRsaWlpF7zem2++qS+//PK8bXJychQUFKSoqCin/TExMcrJyXG0+W3iU3a87Jg3sdoLAACc18GDB2W1Wh2fg4ODL9ju4YcfVkZGhkJCQi5WeBVG5QcAALMxDM83SVar1Wm7UPKzdetWHT9+XFdccYUCAgIUEBCgtWvXKj09XQEBAYqJiVFxcbHy8vKczjt27JhiY2MlSbGxsees/ir7XNbGW0h+AAAwmYu92qtXr17avn27srKyHFuXLl2UnJzs+O/AwECtWbPGcc6uXbt04MABJSQkSJISEhK0fft2HT9+3NEmIyNDVqtVbdq08crPpQzDXgAAwCMRERFq166d077w8HDVqVPHsX/48OEaO3asoqOjZbVaNWrUKCUkJOhPf/qTJKl3795q06aN7r77bs2cOVM5OTl64oknNHLkyAtWnCqK5AcAALOphu/2eu655+Tn56eBAweqqKhISUlJeuGFFxzH/f39tWrVKj3wwANKSEhQeHi4hgwZotTUVK/HQvIDAIDJWOxnN0/O99R//vMfp88hISGaN2+e5s2bd8FzGjZsqA8++MDzi/8Bkh/4tMWbvlVsfMk5+1cuqqN5f22gmf/aq45Xn3Y69v6SOkp/vMHFChEot0F37NTV1xxWg8tOqrjIX9nf1tEr/2ivw4ciHG0CA22674Gv1b3nQQUG2vTlF7Gal3658k78ukKn4+XHdPe9O9SocYEKC/215uOGWvxyO9ntTBOFOZD8/IbFYtG7776rAQMGVHUouEge6ttCfv6/1ncbtSrU9Le+0/r3ohz7Png9Wkue+XWlQdEvfAGgemrX4UetWtlUu3fWlr+/oSHDv9HTM9fr/mG9VVR49s/9iAe/0pVdjyptyp90+nSgHnhom56YnKnxD/eUJDVukqfUaRv05rJWenb6VapzyS9KGf2l/PwMvfxix6q8PbijGg57VSc+9Vc8JydHo0aNUpMmTRQcHKz4+HjdfPPNTrPP4VvycwN04sdAx9Y1sUBH9gfp68xwR5uiX/yc2pw55V+FEQMXNmnCtfrko0Y68EOk9n8Xpdkzr1S9mDNq3vyEJCksvES9++7XSws66qusetq7p7aem9lFbdr9rJatf5Ykde95UPu/i9Qbr7XR0SO19M3XdfXKS+11U/99Cg09t0qK6qkq3+1VE/hM5ef7779Xt27dFBUVpWeeeUbt27dXSUmJPvroI40cOVI7d+6slOsWFxcrKCioUvqGdwUE2nX9wBN658W6kiyO/T1vO6HrB57QieOB+jzDqmVzYqj+oEYIDz+brJw8efZvUPPmJxQYaChraz1Hm0MHrTp+LEyt2/ysXdl1FBhoV3GJ8+93cZG/goPtatbihLZ/VU+oAX7zrJ4Kn29iPvMX/MEHH5TFYtHmzZs1cOBAtWjRQm3bttXYsWMdL1WTpJ9++km33nqrwsLC1Lx5c61cudJxbNGiRec8mnvFihWyWH79opw8ebI6deqkhQsXqnHjxo4nXVosFi1cuPCCfaPqXd2nQLWsNn38drRj37/fra2ZKZfp0dub6s259dRr4Ak9OvdAFUYJlI/FYuj+kVnasb2Ofvg+UpJUO7pQJcV+On3a+R9kJ04Eq3Z0oSRp6xcxat3mZ13X84D8/AzVueQX3Xl3tiQp+r9tgJrOJ5Kf3NxcrV69WiNHjlR4ePg5x3+b0EyZMkWDBg3S119/rX79+ik5OVm5ubluXW/v3r1avny53nnnHWVlZVWo76KionNeKIfKlXTHz/ri31blHgt07PtwaR1tXWvV9ztD9e93a+uZh+N1Tb981W/o+uV+QFV78KFtatioQNOf6urWedu2xuqVf3RQyugv9X+r39FLi1bri01n57wZhuUPzkZ1wbCXaz6R/Ozdu1eGYahVq1Z/2Hbo0KG644471KxZM02bNk2nTp3S5s2b3bpecXGxlixZossvv1wdOnSoUN9paWlOL5OLj493Kwa4p96lxbr82lNavSzaZbudX4ZJkuIakfyg+npg1DZd9aejenzcdfr5pzDH/hO5IQoMsis8vNipfe3aRTqR++tqr3f/1UL/07+/htzRT4Nvu0Wfb4yTJB09eu4/HlFNeemt7mblE8mP4cbY5W+TlfDwcFmtVqdHbZdHw4YNVbduXY/6njBhgvLz8x3bwYMH3YoB7uk9OFd5PwVo0ydWl+2atjtb9s89HuiyHVA1DD0wapsSrjmsCeO761iOc7KyZ09tlZRY1OmKX//uXNrgpOrFnFH2t3V+15dFuT+HqrjYX9ddf1DHj4Vq357aF+EegMrnExOemzdvLovFUq5JzYGBzl9qFotFdvvZpz35+fmdk0iVlJy7+uF8Q2t/1PfvBQcHe/1x3jg/i8VQ7//N1Sf/rC277deyfv2GRep5a542r4nQyRMBatzmF90/+Yi+zgzX/uzQKowYOL8HH9qmHr0OKnXi1frlTKBq1z6brJ8+HajiYn+dOR2ojz9srPse+FonTwbpzOlA/WXUNn27I1q7sn9NfgYO2qWtX8TKbpe6XXtY/zN4p6ZP/ZPsdoa9agpPh67MPuzlE8lPdHS0kpKSNG/ePD300EPnJCd5eXnnTGQ+n7p16+rkyZM6ffq0o4/fzulBzXR591OKaVCij950/pdvaYlFl197Urf++UeFhNn145FAffZBpN6YE1NFkQKu3dT/O0nSzOfWOu2fPbOLPvmokSTpHy90lGFY9LcnMxUYaNfWLTF64fkrnNp3uSpH/5u8U4GBNu3fF6Wpk67Wls31L8o9wEtY7eWSTyQ/kjRv3jx169ZNV111lVJTU9WhQweVlpYqIyND8+fPV3Z29h/20bVrV4WFhemvf/2rHnroIW3atEmLFi2q/OBRqb5cG6GkuHMf3vbjkSA9MrBZFUQEVEy/Xrf/YZuSEn+9kH65Xki//IJtJoy/zpthAdWOT8z5kaQmTZroyy+/VM+ePTVu3Di1a9dON9xwg9asWaP58+eXq4/o6Gi9/vrr+uCDD9S+fXu98cYbmjx5cuUGDgCAm1jt5ZrFcGc2MKpMQUGBIiMj1UP9FWBhsi3Myb9186oOAag0pbYirdk1W/n5+bJaXS+uqKiy74qEPqkKCAz54xMuoLSkUJmrJ1VqrFXJZyo/AAAAkg/N+QEAwFew2ss1kh8AAMzGbpzdPDnfxEh+AAAwG0+f0mzu3Ic5PwAAwLdQ+QEAwGQs8nDOj9ciqZ5IfgAAMBue8OwSw14AAMCnUPkBAMBkWOruGskPAABmw2ovlxj2AgAAPoXKDwAAJmMxDFk8mLTsybk1AckPAABmY//v5sn5JsawFwAA8ClUfgAAMBmGvVwj+QEAwGxY7eUSyQ8AAGbDE55dYs4PAADwKVR+AAAwGZ7w7BrJDwAAZsOwl0sMewEAAJ9C5QcAAJOx2M9unpxvZiQ/AACYDcNeLjHsBQAAfAqVHwAAzIaHHLpE8gMAgMnwegvXGPYCAAA+hcoPAABmw4Rnl0h+AAAwG0OSJ8vVzZ37kPwAAGA2zPlxjTk/AADAp1D5AQDAbAx5OOfHa5FUSyQ/AACYDROeXWLYCwAA+BQqPwAAmI1dksXD802M5AcAAJNhtZdrDHsBAACfQuUHAACzYcKzSyQ/AACYDcmPSwx7AQAAn0LlBwAAs6Hy4xKVHwAAzMbuhc0NaWlpuvLKKxUREaF69eppwIAB2rVrl1ObwsJCjRw5UnXq1FGtWrU0cOBAHTt2zKnNgQMHdOONNyosLEz16tXTI488otLSUnfv/g+R/AAAYDJlS9092dyxdu1ajRw5Up9//rkyMjJUUlKi3r176/Tp0442Y8aM0Xvvvad//vOfWrt2rY4cOaLbbrvNcdxms+nGG29UcXGxNm7cqMWLF2vRokWaNGmS134uZSyGYfLalkkUFBQoMjJSPdRfAZbAqg4HqBT+rZtXdQhApSm1FWnNrtnKz8+X1WqtlGuUfVckthirAP/gCvdTaivSJ7srHuuPP/6oevXqae3aterevbvy8/NVt25dLVu2TLfffrskaefOnWrdurUyMzP1pz/9SR9++KFuuukmHTlyRDExMZKkBQsW6LHHHtOPP/6ooKCgCt/P71H5AQDAbMrm/Hiy6Wwy9dutqKioXJfPz8+XJEVHR0uStm7dqpKSEiUmJjratGrVSpdddpkyMzMlSZmZmWrfvr0j8ZGkpKQkFRQUaMeOHV75sZQh+QEAwGzshuebpPj4eEVGRjq2tLS0P7603a7Ro0erW7duateunSQpJydHQUFBioqKcmobExOjnJwcR5vfJj5lx8uOeROrvQAAwHkdPHjQadgrOPiPh9JGjhypb775Rp999lllhuYRkh8AAMzGS0vdrVarW3N+UlJStGrVKq1bt04NGjRw7I+NjVVxcbHy8vKcqj/Hjh1TbGyso83mzZud+itbDVbWxlsY9gIAwHQ8ne/jXuJkGIZSUlL07rvv6tNPP1Xjxo2djnfu3FmBgYFas2aNY9+uXbt04MABJSQkSJISEhK0fft2HT9+3NEmIyNDVqtVbdq0qfiP4jyo/AAAAI+MHDlSy5Yt0//93/8pIiLCMUcnMjJSoaGhioyM1PDhwzV27FhFR0fLarVq1KhRSkhI0J/+9CdJUu/evdWmTRvdfffdmjlzpnJycvTEE09o5MiR5RpucwfJDwAAZnORn/A8f/58SVKPHj2c9r/66qsaOnSoJOm5556Tn5+fBg4cqKKiIiUlJemFF15wtPX399eqVav0wAMPKCEhQeHh4RoyZIhSU1Mrfh8XQPIDAIDZ2N0fujr3/PIrzyMDQ0JCNG/ePM2bN++CbRo2bKgPPvjArWtXBHN+AACAT6HyAwCA2Rj2s5sn55sYyQ8AAGbDW91dIvkBAMBsLvKcn5qGOT8AAMCnUPkBAMBsGPZyieQHAACzMeRh8uO1SKolhr0AAIBPofIDAIDZMOzlEskPAABmY7dL8uBZPXZzP+eHYS8AAOBTqPwAAGA2DHu5RPIDAIDZkPy4xLAXAADwKVR+AAAwG15v4RLJDwAAJmMYdhkevJndk3NrApIfAADMxjA8q94w5wcAAMA8qPwAAGA2hodzfkxe+SH5AQDAbOx2yeLBvB2Tz/lh2AsAAPgUKj8AAJgNw14ukfwAAGAyht0uw4NhL7MvdWfYCwAA+BQqPwAAmA3DXi6R/AAAYDZ2Q7KQ/FwIw14AAMCnUPkBAMBsDEOSJ8/5MXflh+QHAACTMeyGDA+GvQySHwAAUKMYdnlW+WGpOwAAgGlQ+QEAwGQY9nKN5AcAALNh2Mslkp8aoiwLL1WJR8+tAqozw1ZU1SEAlab0v7/fF6Oq4ul3RalKvBdMNUTyU0OcPHlSkvSZPqjiSIBKtKuqAwAq38mTJxUZGVkpfQcFBSk2Nlaf5Xj+XREbG6ugoCAvRFX9WAyzD+yZhN1u15EjRxQRESGLxVLV4fiEgoICxcfH6+DBg7JarVUdDuB1/I5fXIZh6OTJk4qLi5OfX+WtNyosLFRxcbHH/QQFBSkkJMQLEVU/VH5qCD8/PzVo0KCqw/BJVquVLwaYGr/jF09lVXx+KyQkxLRJi7ew1B0AAPgUkh8AAOBTSH6ACwgODtaTTz6p4ODgqg4FqBT8jsNXMeEZAAD4FCo/AADAp5D8AAAAn0LyAwAAfArJD1BOixYtUlRUVFWHAZSLxWLRihUrqjoMoFoi+UG1NXToUFksFk2fPt1p/4oVK9x+ynWjRo00Z84cL0YHVK2cnByNGjVKTZo0UXBwsOLj43XzzTdrzZo1VR0aUO2R/KBaCwkJ0YwZM3TixImqDqXSeOMx9PAt33//vTp37qxPP/1UzzzzjLZv367Vq1erZ8+eGjlyZKVdl99VmAXJD6q1xMRExcbGKi0tzWW75cuXq23btgoODlajRo307LPPOo716NFDP/zwg8aMGSOLxeKyapSXl6f7779fMTExCgkJUbt27bRq1SqnNh999JFat26tWrVqqU+fPjp69KjTtUaPHu3UfsCAARo6dKjjc6NGjTR16lTdc889slqtGjFihGNIzVXfQJkHH3xQFotFmzdv1sCBA9WiRQu1bdtWY8eO1eeff+5o99NPP+nWW29VWFiYmjdvrpUrVzqOnW8Y9/dV1cmTJ6tTp05auHChGjdu7HhlgsVi0cKFCy/YN1DdkfygWvP399e0adM0d+5cHTp06Lxttm7dqkGDBmnw4MHavn27Jk+erIkTJ2rRokWSpHfeeUcNGjRQamqqjh49esGEwm63q2/fvtqwYYNef/11ffvtt5o+fbr8/f0dbc6cOaNZs2bptdde07p163TgwAGNHz/e7fuaNWuWOnbsqG3btmnixIle7Rvmlpubq9WrV2vkyJEKDw8/5/hvE5opU6Zo0KBB+vrrr9WvXz8lJycrNzfXrevt3btXy5cv1zvvvKOsrCyv9g1UFV5simrv1ltvVadOnfTkk0/q5ZdfPuf47Nmz1atXL0cS0aJFC3377bd65plnNHToUEVHR8vf318RERGKjY294HU++eQTbd68WdnZ2WrRooUkqUmTJk5tSkpKtGDBAjVt2lSSlJKSotTUVLfv6frrr9e4ceMcn9evX++1vmFue/fulWEYatWq1R+2HTp0qO644w5J0rRp05Senq7NmzerT58+5b5ecXGxlixZorp163q9b6CqUPlBjTBjxgwtXrxY2dnZ5xzLzs5Wt27dnPZ169ZNe/bskc1mK/c1srKy1KBBA0ficz5hYWGO5ESS6tevr+PHj5f7GmW6dOlSaX3D3Nx5KH+HDh0c/x0eHi6r1er271TDhg3PSXy81TdQVUh+UCN0795dSUlJmjBhQqVdIzQ09A/bBAYGOn22WCxOX0Z+fn7nfDmVlJSc08/5hiv+qG9Akpo3by6LxaKdO3f+Ydvz/U7Z7XZJnv2u/lHfQHVH8oMaY/r06XrvvfeUmZnptL9169basGGD074NGzaoRYsWjvk6QUFBf1gF6tChgw4dOqTdu3dXOMa6des6zSmy2Wz65ptvKtwf8HvR0dFKSkrSvHnzdPr06XOO5+XllaufunXr6uTJk059/HZOD2BmJD+oMdq3b6/k5GSlp6c77R83bpzWrFmjqVOnavfu3Vq8eLH+/ve/O00WbtSokdatW6fDhw/rp59+Om//1113nbp3766BAwcqIyND+/fv14cffqjVq1eXO8brr79e77//vt5//33t3LlTDzzwQLm/jIDymjdvnmw2m6666iotX75ce/bsUXZ2ttLT05WQkFCuPrp27aqwsDD99a9/1b59+7Rs2TLHIgHA7Eh+UKOkpqaeU1q/4oor9Pbbb+vNN99Uu3btNGnSJKWmpjotL09NTdX333+vpk2bnnf+Qpnly5fryiuv1B133KE2bdro0UcfdWve0LBhwzRkyBDdc889uu6669SkSRP17NnT7fsEXGnSpIm+/PJL9ezZU+PGjVO7du10ww03aM2aNZo/f365+oiOjtbrr7+uDz74QO3bt9cbb7yhyZMnV27gQDVhMZhUAAAAfAiVHwAA4FNIfgAAgE8h+QEAAD6F5AcAAPgUkh8AAOBTSH4AAIBPIfkBAAA+heQHQLkNHTpUAwYMcHzu0aOHRo8efdHj+M9//iOLxeLy6dkWi0UrVqwod5+TJ09Wp06dPIrr+++/l8Vi4TURQDVH8gPUcEOHDpXFYpHFYlFQUJCaNWum1NRUlZaWVvq133nnHU2dOrVcbcuTsADAxRBQ1QEA8FyfPn306quvqqioSB988IFGjhypwMBATZgw4Zy2xcXFCgoK8sp1o6OjvdIPAFxMVH4AEwgODlZsbKwaNmyoBx54QImJiVq5cqWkX4eqnn76acXFxally5aSpIMHD2rQoEGKiopSdHS0+vfvr++//97Rp81m09ixYxUVFaU6dero0Ucf1e/fhvP7Ya+ioiI99thjio+PV3BwsJo1a6aXX35Z33//veMdZ7Vr15bFYnG8e81utystLU2NGzdWaGioOnbsqH/9619O1/nggw/UokULhYaGqmfPnk5xltdjjz2mFi1aKCwsTE2aNNHEiRNVUlJyTrsXX3xR8fHxCgsL06BBg5Sfn+90fOHChWrdurVCQkLUqlUrvfDCC27HAqBqkfwAJhQaGqri4mLH5zVr1mjXrl3KyMjQqlWrVFJSoqSkJEVERGj9+vXasGGDatWqpT59+jjOe/bZZ7Vo0SK98sor+uyzz5Sbm6t3333X5XXvuecevfHGG0pPT1d2drZefPFF1apVS/Hx8Vq+fLkkadeuXTp69Kief/55SVJaWpqWLFmiBQsWaMeOHRozZozuuusurV27VtLZJO22227TzTffrKysLP35z3/W448/7vbPJCIiQosWLdK3336r559/Xi+99JKee+45pzZ79+7V22+/rffee0+rV6/Wtm3b9OCDDzqOL126VJMmTdLTTz+t7OxsTZs2TRMnTtTixYvdjgdAFTIA1GhDhgwx+vfvbxiGYdjtdiMjI8MIDg42xo8f7zgeExNjFBUVOc557bXXjJYtWxp2u92xr6ioyAgNDTU++ugjwzAMo379+sbMmTMdx0tKSowGDRo4rmUYhnHdddcZDz/8sGEYhrFr1y5DkpGRkXHeOP/9738bkowTJ0449hUWFhphYWHGxo0bndoOHz7cuOOOOwzDMIwJEyYYbdq0cTr+2GOPndPX70ky3n333Qsef+aZZ4zOnTs7Pj/55JOGv7+/cejQIce+Dz/80PDz8zOOHj1qGIZhNG3a1Fi2bJlTP1OnTjUSEhIMwzCM/fv3G5KMbdu2XfC6AKoec34AE1i1apVq1aqlkpIS2e123XnnnZo8ebLjePv27Z3m+Xz11Vfau3evIiIinPopLCzUvn37lJ+fr6NHj6pr166OYwEBAerSpcs5Q19lsrKy5O/vr+uuu67cce/du1dnzpzRDTfc4LS/uLhYl19+uSQpOzvbKQ5JSkhIKPc1yrz11ltKT0/Xvn37dOrUKZWWlspqtTq1ueyyy3TppZc6Xcdut2vXrl2KiIjQvn37NHz4cN13332ONqWlpYqMjHQ7HgBVh+QHMIGePXtq/vz5CgoKUlxcnAICnP+vHR4e7vT51KlT6ty5s5YuXXpOX3Xr1q1QDKGhoW6fc+rUKUnS+++/75R0SGfnMXlLZmamkpOTNWXKFCUlJSkyMlJvvvmmnn32Wbdjfemll85Jxvz9/b0WK4DKR/IDmEB4eLiaNWtW7vZXXHGF3nrrLdWrV++c6keZ+vXra9OmTerevbuksxWOrVu36oorrjhv+/bt28tut2vt2rVKTEw853hZ5clmszn2tWnTRsHBwTpw4MAFK0atW7d2TN4u8/nnn//xTf7Gxo0b1bBhQ/3tb39z7Pvhhx/OaXfgwAEdOXJEcXFxjuv4+fmpZcuWiomJUVxcnL777jslJye7dX0A1QsTngEflJycrEsuuUT9+/fX+vXrtX//fv3nP//RQw89pEOHDkmSHn74YU2fPl0rVqzQzp079eCDD7p8Rk+jRo00ZMgQDRs2TCtWrHD0+fbbb0uSGjZsKIvFolWrVunHH3/UqVOnFBERofHjx2vMmDFavHix9u3bpy+//FJz5851TCL+y1/+oj179uiRRx7Rrl27tGzZMi1atMit+23evLkOHDigN998U/v27VN6evp5J2+HhIRoyJAh+uqrr7R+/Xo99NBDGjRokGJjYyVJU6ZMUVpamtLT07V7925t375dr776qmbPnu1WPACqFskP4IPCwsK0bt06XXbZZbrtttvUunVrDR8+XIWFhY5K0Lhx43T33XdryJAhSkhIUEREhG699VaX/c6fP1+33367HnzwQbVq1Ur33XefTp8+LUm69NJLNWXKFD3++OOKiYlRSkqKJGnq1KmaOHGi0tLS1Lp1a/Xp00fvv/++GjduLOnsPJzly5drxYoV6tixoxYsWKBp06a5db+33HKLxowZo5SUFHXq1EkbN27UxIkTz2nXrFkz3XbbberXr5969+6tDh06OC1l//Of/6yFCxfq1VdfVfv27XXddddp0aJFjlgB1AwW40KzFwEAAEyIyg8AAPApJD8AAMCnkPwAAACfQvIDAAB8CskPAADwKSQ/AADAp5D8AAAAn0LyAwAAfArJDwAA8CkkPwAAwKeQ/AAAAJ9C8gMAAHzK/wM9MsG7bpdoGAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall da validação (%):  73.59154929577466\n",
            "Acurácia da validação (%):  84.19182948490231\n",
            "SCORE do modelo (%):  87.80397871929486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizou-se o \"Recall\" como métrica principal de avaliação desta predição pelo fato deste indicador ter uma maior efetividade no estudo dos falsos negativos. A aparição de falsos negativos é bastante prejudicial nesta ocasião, dado que o erro na previsão da não saída de clientes pode ocasionar prejuízos financeiros significativos para a instituição. O melhor valor de Recall obtido foi com um threshould de 0.4, apresentando um score de validação de modelo equivalente aos demais e uma satisfatória acuracidade."
      ],
      "metadata": {
        "id": "9b474p_0hoAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONSTRUINDO A RNA (BALANCEAMENTO NEAR MISS)**"
      ],
      "metadata": {
        "id": "gzCueO6us0mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Seleção do número de neurônios da camada de processamento:\n",
        "\n"
      ],
      "metadata": {
        "id": "4QDGSOg0dFND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Return_Recall_nm(x_test_nm, y_test):\n",
        "    y_pred_nm = ann_nm.predict(x_test_nm)\n",
        "    y_pred_nm = (y_pred_nm > 0.5)\n",
        "\n",
        "    score_nm1 = recall_score(y_test, y_pred_nm)*100\n",
        "    score_nm2 = accuracy_score(y_test, y_pred_nm)*100\n",
        "\n",
        "    ann_nm_2 = KerasClassifier(model=ann_nm, epochs=10, batch_size=64, verbose=0)\n",
        "    # Como o cross_val_score é incompatível com o Sequential, ele foi encapsulado no KerasClassifier.\n",
        "\n",
        "    score_model_nm = cross_val_score(ann_nm_2, x_test_nm, y_test, cv=5, scoring='accuracy')\n",
        "\n",
        "    list_scoresm_nm.append (score_model_nm)\n",
        "    list_ReturnRecall_nm.append (score_nm1)\n",
        "    list_ReturnAccuracy_nm.append (score_nm2)\n",
        "\n",
        "    return print(f\"Recall e Acurácia (NEAR MISS) com a validação (%):{score_nm1} e {score_nm2}. Scores do modelo: {score_model_nm}\")"
      ],
      "metadata": {
        "id": "hxiIJM7btNu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_ReturnRecall_nm = []\n",
        "list_ReturnAccuracy_nm = []\n",
        "list_scoresm_nm = []\n",
        "\n",
        "list_neurons_nm = [2,4,6,8]\n",
        "\n",
        "for i in list_neurons_nm:\n",
        "    ann_nm = Sequential()\n",
        "\n",
        "    ann_nm.add (tf.keras.layers.Dense (units=i, activation='relu', kernel_initializer = 'he_normal'))\n",
        "    ann_nm.add (tf.keras.layers.Dense (units=1, activation='sigmoid', kernel_initializer = 'he_normal'))\n",
        "\n",
        "    optimize = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "    ann_nm.compile(optimizer=optimize, loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
        "\n",
        "    ann_nm.fit(x_train_nm, y_train_nm, batch_size=32, epochs=50)\n",
        "\n",
        "    Return_Recall_nm(x_test_nm, y_test)"
      ],
      "metadata": {
        "id": "LFQnNAgktNu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9ee73b-6400-4ad6-bd91-fb5c28de38e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7804 - recall_12: 0.4525\n",
            "Epoch 2/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6354 - recall_12: 0.5972\n",
            "Epoch 3/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5759 - recall_12: 0.7226\n",
            "Epoch 4/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5727 - recall_12: 0.7515\n",
            "Epoch 5/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5574 - recall_12: 0.7321\n",
            "Epoch 6/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5647 - recall_12: 0.7391\n",
            "Epoch 7/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5668 - recall_12: 0.7231\n",
            "Epoch 8/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5607 - recall_12: 0.7250\n",
            "Epoch 9/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5322 - recall_12: 0.7487\n",
            "Epoch 10/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5556 - recall_12: 0.7302\n",
            "Epoch 11/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5408 - recall_12: 0.7341\n",
            "Epoch 12/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5378 - recall_12: 0.7216\n",
            "Epoch 13/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5319 - recall_12: 0.7294\n",
            "Epoch 14/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5464 - recall_12: 0.7214\n",
            "Epoch 15/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5434 - recall_12: 0.6983\n",
            "Epoch 16/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5539 - recall_12: 0.7059\n",
            "Epoch 17/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5331 - recall_12: 0.7367\n",
            "Epoch 18/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5169 - recall_12: 0.7567\n",
            "Epoch 19/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5395 - recall_12: 0.7115\n",
            "Epoch 20/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5094 - recall_12: 0.7477\n",
            "Epoch 21/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5387 - recall_12: 0.7458\n",
            "Epoch 22/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5339 - recall_12: 0.6962\n",
            "Epoch 23/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5191 - recall_12: 0.7070\n",
            "Epoch 24/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5281 - recall_12: 0.7379\n",
            "Epoch 25/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5389 - recall_12: 0.7338\n",
            "Epoch 26/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - recall_12: 0.6789\n",
            "Epoch 27/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5407 - recall_12: 0.7080\n",
            "Epoch 28/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5312 - recall_12: 0.7202\n",
            "Epoch 29/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5283 - recall_12: 0.7289\n",
            "Epoch 30/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5230 - recall_12: 0.7462\n",
            "Epoch 31/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5058 - recall_12: 0.7306\n",
            "Epoch 32/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5420 - recall_12: 0.7022\n",
            "Epoch 33/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5516 - recall_12: 0.7049\n",
            "Epoch 34/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5317 - recall_12: 0.7384\n",
            "Epoch 35/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5277 - recall_12: 0.7264\n",
            "Epoch 36/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5403 - recall_12: 0.7217\n",
            "Epoch 37/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5505 - recall_12: 0.7075\n",
            "Epoch 38/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5464 - recall_12: 0.7088\n",
            "Epoch 39/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5313 - recall_12: 0.7266\n",
            "Epoch 40/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5430 - recall_12: 0.7210\n",
            "Epoch 41/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5338 - recall_12: 0.6941\n",
            "Epoch 42/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5322 - recall_12: 0.7292\n",
            "Epoch 43/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5404 - recall_12: 0.6863\n",
            "Epoch 44/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5317 - recall_12: 0.7278\n",
            "Epoch 45/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5242 - recall_12: 0.7463\n",
            "Epoch 46/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5292 - recall_12: 0.7107\n",
            "Epoch 47/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5304 - recall_12: 0.7046\n",
            "Epoch 48/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5230 - recall_12: 0.7378\n",
            "Epoch 49/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5353 - recall_12: 0.7429\n",
            "Epoch 50/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5295 - recall_12: 0.7309\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Recall e Acurácia (NEAR MISS) com a validação (%):71.12676056338029 e 50.08880994671403. Scores do modelo: [0.86094675 0.8816568  0.86686391 0.84319527 0.8694362 ]\n",
            "Epoch 1/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8609 - recall_13: 0.5470\n",
            "Epoch 2/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6055 - recall_13: 0.6760\n",
            "Epoch 3/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5655 - recall_13: 0.7018\n",
            "Epoch 4/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5387 - recall_13: 0.7394\n",
            "Epoch 5/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5493 - recall_13: 0.7022\n",
            "Epoch 6/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5230 - recall_13: 0.7361\n",
            "Epoch 7/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5272 - recall_13: 0.6836\n",
            "Epoch 8/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5295 - recall_13: 0.7130\n",
            "Epoch 9/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5164 - recall_13: 0.7146\n",
            "Epoch 10/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5247 - recall_13: 0.7179\n",
            "Epoch 11/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5144 - recall_13: 0.6986\n",
            "Epoch 12/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5274 - recall_13: 0.7101\n",
            "Epoch 13/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4791 - recall_13: 0.7316\n",
            "Epoch 14/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4915 - recall_13: 0.7314\n",
            "Epoch 15/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5082 - recall_13: 0.7344\n",
            "Epoch 16/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4856 - recall_13: 0.7291\n",
            "Epoch 17/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4742 - recall_13: 0.7338\n",
            "Epoch 18/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4849 - recall_13: 0.7564\n",
            "Epoch 19/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4971 - recall_13: 0.7288\n",
            "Epoch 20/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4765 - recall_13: 0.7322\n",
            "Epoch 21/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5023 - recall_13: 0.7154\n",
            "Epoch 22/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4796 - recall_13: 0.7271\n",
            "Epoch 23/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5031 - recall_13: 0.7081\n",
            "Epoch 24/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4751 - recall_13: 0.7450\n",
            "Epoch 25/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4822 - recall_13: 0.7521\n",
            "Epoch 26/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4833 - recall_13: 0.7159\n",
            "Epoch 27/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4902 - recall_13: 0.7434\n",
            "Epoch 28/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4917 - recall_13: 0.7339\n",
            "Epoch 29/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5036 - recall_13: 0.7360\n",
            "Epoch 30/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4913 - recall_13: 0.7374\n",
            "Epoch 31/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4583 - recall_13: 0.7562\n",
            "Epoch 32/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4877 - recall_13: 0.7169\n",
            "Epoch 33/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4738 - recall_13: 0.7132\n",
            "Epoch 34/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5047 - recall_13: 0.7182\n",
            "Epoch 35/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5030 - recall_13: 0.7330\n",
            "Epoch 36/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4982 - recall_13: 0.7121\n",
            "Epoch 37/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4782 - recall_13: 0.7581\n",
            "Epoch 38/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5156 - recall_13: 0.6961\n",
            "Epoch 39/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5288 - recall_13: 0.6609\n",
            "Epoch 40/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4956 - recall_13: 0.7135\n",
            "Epoch 41/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4829 - recall_13: 0.7119\n",
            "Epoch 42/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4814 - recall_13: 0.7172\n",
            "Epoch 43/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4805 - recall_13: 0.7371\n",
            "Epoch 44/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5026 - recall_13: 0.7030\n",
            "Epoch 45/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5050 - recall_13: 0.7204\n",
            "Epoch 46/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5016 - recall_13: 0.6901\n",
            "Epoch 47/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4912 - recall_13: 0.6996\n",
            "Epoch 48/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4717 - recall_13: 0.7130\n",
            "Epoch 49/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4703 - recall_13: 0.7407\n",
            "Epoch 50/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4888 - recall_13: 0.6896\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Recall e Acurácia (NEAR MISS) com a validação (%):75.35211267605634 e 47.246891651865006. Scores do modelo: [0.86094675 0.88461538 0.87869822 0.82544379 0.8694362 ]\n",
            "Epoch 1/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7381 - recall_14: 0.8447\n",
            "Epoch 2/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5600 - recall_14: 0.6878\n",
            "Epoch 3/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5619 - recall_14: 0.6771\n",
            "Epoch 4/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5179 - recall_14: 0.7150\n",
            "Epoch 5/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5135 - recall_14: 0.7259\n",
            "Epoch 6/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5037 - recall_14: 0.7276\n",
            "Epoch 7/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5038 - recall_14: 0.7270\n",
            "Epoch 8/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4636 - recall_14: 0.7473\n",
            "Epoch 9/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4695 - recall_14: 0.7601\n",
            "Epoch 10/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4815 - recall_14: 0.7413\n",
            "Epoch 11/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5067 - recall_14: 0.7182\n",
            "Epoch 12/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4904 - recall_14: 0.7137\n",
            "Epoch 13/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5085 - recall_14: 0.7081\n",
            "Epoch 14/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4636 - recall_14: 0.7631\n",
            "Epoch 15/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4595 - recall_14: 0.7619\n",
            "Epoch 16/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4549 - recall_14: 0.7593\n",
            "Epoch 17/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4796 - recall_14: 0.7204\n",
            "Epoch 18/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4625 - recall_14: 0.7279\n",
            "Epoch 19/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4600 - recall_14: 0.7555\n",
            "Epoch 20/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4599 - recall_14: 0.7396\n",
            "Epoch 21/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4706 - recall_14: 0.7572\n",
            "Epoch 22/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4778 - recall_14: 0.7109\n",
            "Epoch 23/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4563 - recall_14: 0.7307\n",
            "Epoch 24/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4709 - recall_14: 0.7340\n",
            "Epoch 25/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4609 - recall_14: 0.7128\n",
            "Epoch 26/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4591 - recall_14: 0.7748\n",
            "Epoch 27/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4766 - recall_14: 0.7358\n",
            "Epoch 28/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4407 - recall_14: 0.7369\n",
            "Epoch 29/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5076 - recall_14: 0.7280\n",
            "Epoch 30/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4446 - recall_14: 0.7569\n",
            "Epoch 31/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4580 - recall_14: 0.7353\n",
            "Epoch 32/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4470 - recall_14: 0.7526\n",
            "Epoch 33/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4350 - recall_14: 0.7738\n",
            "Epoch 34/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4477 - recall_14: 0.7460\n",
            "Epoch 35/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4728 - recall_14: 0.7703\n",
            "Epoch 36/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4709 - recall_14: 0.7418\n",
            "Epoch 37/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4524 - recall_14: 0.7527\n",
            "Epoch 38/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4663 - recall_14: 0.7409\n",
            "Epoch 39/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4400 - recall_14: 0.7536\n",
            "Epoch 40/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4494 - recall_14: 0.7311\n",
            "Epoch 41/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4262 - recall_14: 0.7572\n",
            "Epoch 42/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4672 - recall_14: 0.7243\n",
            "Epoch 43/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4532 - recall_14: 0.7712\n",
            "Epoch 44/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4515 - recall_14: 0.7363\n",
            "Epoch 45/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4377 - recall_14: 0.7552\n",
            "Epoch 46/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4352 - recall_14: 0.7314\n",
            "Epoch 47/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4356 - recall_14: 0.7660\n",
            "Epoch 48/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4268 - recall_14: 0.7468\n",
            "Epoch 49/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4662 - recall_14: 0.7367\n",
            "Epoch 50/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4585 - recall_14: 0.7250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Recall e Acurácia (NEAR MISS) com a validação (%):77.8169014084507 e 49.55595026642984. Scores do modelo: [0.89349112 0.89940828 0.89053254 0.86094675 0.86646884]\n",
            "Epoch 1/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.6457 - recall_15: 0.5597\n",
            "Epoch 2/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5471 - recall_15: 0.7512\n",
            "Epoch 3/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5224 - recall_15: 0.7285\n",
            "Epoch 4/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5046 - recall_15: 0.7007\n",
            "Epoch 5/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4983 - recall_15: 0.7468\n",
            "Epoch 6/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4819 - recall_15: 0.7535\n",
            "Epoch 7/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4800 - recall_15: 0.7469\n",
            "Epoch 8/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4718 - recall_15: 0.7590\n",
            "Epoch 9/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4654 - recall_15: 0.7414\n",
            "Epoch 10/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5003 - recall_15: 0.6825\n",
            "Epoch 11/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4630 - recall_15: 0.7410\n",
            "Epoch 12/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4741 - recall_15: 0.7501\n",
            "Epoch 13/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4780 - recall_15: 0.7623\n",
            "Epoch 14/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4678 - recall_15: 0.7348\n",
            "Epoch 15/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4608 - recall_15: 0.7514 \n",
            "Epoch 16/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4717 - recall_15: 0.7452\n",
            "Epoch 17/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4801 - recall_15: 0.7461\n",
            "Epoch 18/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4569 - recall_15: 0.7237\n",
            "Epoch 19/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4631 - recall_15: 0.7083\n",
            "Epoch 20/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4603 - recall_15: 0.7553\n",
            "Epoch 21/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4651 - recall_15: 0.7408\n",
            "Epoch 22/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4546 - recall_15: 0.7635\n",
            "Epoch 23/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4526 - recall_15: 0.7170\n",
            "Epoch 24/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4492 - recall_15: 0.7650\n",
            "Epoch 25/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4426 - recall_15: 0.7424\n",
            "Epoch 26/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4604 - recall_15: 0.7351\n",
            "Epoch 27/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4478 - recall_15: 0.7599\n",
            "Epoch 28/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.4524 - recall_15: 0.7515\n",
            "Epoch 29/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.4822 - recall_15: 0.7038\n",
            "Epoch 30/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4353 - recall_15: 0.7440\n",
            "Epoch 31/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4512 - recall_15: 0.7722\n",
            "Epoch 32/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4282 - recall_15: 0.7717\n",
            "Epoch 33/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4358 - recall_15: 0.7633\n",
            "Epoch 34/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4502 - recall_15: 0.7400\n",
            "Epoch 35/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4402 - recall_15: 0.7367\n",
            "Epoch 36/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4513 - recall_15: 0.7473\n",
            "Epoch 37/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4643 - recall_15: 0.7281\n",
            "Epoch 38/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4562 - recall_15: 0.7433\n",
            "Epoch 39/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4648 - recall_15: 0.7255\n",
            "Epoch 40/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4426 - recall_15: 0.7364\n",
            "Epoch 41/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4283 - recall_15: 0.7732\n",
            "Epoch 42/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4438 - recall_15: 0.7378\n",
            "Epoch 43/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4417 - recall_15: 0.7434\n",
            "Epoch 44/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4373 - recall_15: 0.7830\n",
            "Epoch 45/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4550 - recall_15: 0.7648\n",
            "Epoch 46/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4424 - recall_15: 0.7349\n",
            "Epoch 47/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4558 - recall_15: 0.7164\n",
            "Epoch 48/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4564 - recall_15: 0.7504\n",
            "Epoch 49/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4522 - recall_15: 0.7695\n",
            "Epoch 50/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4419 - recall_15: 0.7367\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Recall e Acurácia (NEAR MISS) com a validação (%):75.70422535211267 e 48.016577856719955. Scores do modelo: [0.86982249 0.88757396 0.8816568  0.86094675 0.87537092]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Recall, Acurácia e Score da validação cruzada do modelo para cada quantidade de neurônios na camada intermediária:\n",
        "\n"
      ],
      "metadata": {
        "id": "7q4hDyGsdNv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_scoresm_average_nm = []\n",
        "\n",
        "for w in list_scoresm_nm:\n",
        "\n",
        "  average = st.mean(w)\n",
        "\n",
        "  list_scoresm_average_nm.append(average*100)\n",
        "\n",
        "\n",
        "data_df = {'Recall': list_ReturnRecall_nm, 'Accuracy': list_ReturnAccuracy_nm, 'SCORE': list_scoresm_average_nm}\n",
        "\n",
        "df_neurons_nm = pd.DataFrame (data_df, index = list_neurons_nm, columns = ['Recall', 'Accuracy', 'SCORE']).sort_values('Recall',\n",
        "                                                                                                      ascending=False)\n",
        "df_neurons_nm"
      ],
      "metadata": {
        "id": "7rQROR_itNu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "30ed0bca-77b7-434e-caf7-9bf99e863d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Recall   Accuracy      SCORE\n",
              "6  77.816901  49.555950  88.216951\n",
              "8  75.704225  48.016578  87.507418\n",
              "4  75.352113  47.246892  86.382807\n",
              "2  71.126761  50.088810  86.441978"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a7ba3c0-22b3-47a5-a1f3-2158d638d142\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>77.816901</td>\n",
              "      <td>49.555950</td>\n",
              "      <td>88.216951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>75.704225</td>\n",
              "      <td>48.016578</td>\n",
              "      <td>87.507418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>75.352113</td>\n",
              "      <td>47.246892</td>\n",
              "      <td>86.382807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>71.126761</td>\n",
              "      <td>50.088810</td>\n",
              "      <td>86.441978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a7ba3c0-22b3-47a5-a1f3-2158d638d142')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a7ba3c0-22b3-47a5-a1f3-2158d638d142 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a7ba3c0-22b3-47a5-a1f3-2158d638d142');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29dfeb4f-7ee9-454e-b33e-37c98264c92c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29dfeb4f-7ee9-454e-b33e-37c98264c92c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29dfeb4f-7ee9-454e-b33e-37c98264c92c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9f358f5a-101f-4570-91f9-ab87d69b8e19\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_neurons_nm')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9f358f5a-101f-4570-91f9-ab87d69b8e19 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_neurons_nm');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_neurons_nm",
              "summary": "{\n  \"name\": \"df_neurons_nm\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8021916399796503,\n        \"min\": 71.12676056338029,\n        \"max\": 77.8169014084507,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          75.70422535211267,\n          71.12676056338029,\n          77.8169014084507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3212500653890697,\n        \"min\": 47.246891651865006,\n        \"max\": 50.08880994671403,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          48.016577856719955,\n          50.08880994671403,\n          49.55595026642984\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8860709938755453,\n        \"min\": 86.38280687584499,\n        \"max\": 88.21695081909645,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          87.50741839762611,\n          86.44197847347813,\n          88.21695081909645\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list_neurons_nm, list_ReturnRecall_nm, marker = 'o')\n",
        "plt.plot(list_neurons_nm, list_ReturnAccuracy_nm, marker = 's')\n",
        "plt.plot(list_neurons_smt, list_scoresm_average_nm, marker = 'X')\n",
        "plt.xlabel ('Número de neurônios na camada intermediária')\n",
        "plt.ylabel ('Métricas da RNA')\n",
        "plt.legend (['Recall', 'Acurácia', 'SCORE MODEL VALIDATION'])\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Qzog0kdtNu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "8f59c654-3af6-4bef-fada-4c646012f1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que tais indicadores se mantêm equilibrados para as quantidades de neurônios analisados. Entretanto, nota-se uma certa superioridade dessas  métricas para 6 neurônios, valor esse que será adotado para o treino da RNA."
      ],
      "metadata": {
        "id": "msuPh5mZFwK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Treino da RNA:\n",
        "\n"
      ],
      "metadata": {
        "id": "61XAU2tJdWXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann_nm = Sequential()\n",
        "\n",
        "ann_nm.add (tf.keras.layers.Dense (units=8, activation='relu', kernel_initializer = 'he_normal'))\n",
        "ann_nm.add (tf.keras.layers.Dense (units=1, activation='sigmoid', kernel_initializer = 'he_normal'))\n",
        "\n",
        "optimize = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "ann_nm.compile(optimizer=optimize, loss='binary_crossentropy', metrics=[tf.keras.metrics.Recall()])\n",
        "\n",
        "ann_nm.fit(x_train_nm, y_train_nm, batch_size=32, epochs=50)"
      ],
      "metadata": {
        "id": "l_lEOFDxtNu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836335b3-0104-4164-b62e-0d95fc4dea4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.8266 - recall_16: 0.2669\n",
            "Epoch 2/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6086 - recall_16: 0.7257\n",
            "Epoch 3/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5608 - recall_16: 0.7713\n",
            "Epoch 4/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5787 - recall_16: 0.7618\n",
            "Epoch 5/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5413 - recall_16: 0.7922\n",
            "Epoch 6/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5596 - recall_16: 0.7518\n",
            "Epoch 7/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4995 - recall_16: 0.7958\n",
            "Epoch 8/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5015 - recall_16: 0.7906\n",
            "Epoch 9/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4990 - recall_16: 0.7546\n",
            "Epoch 10/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5019 - recall_16: 0.7401\n",
            "Epoch 11/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4762 - recall_16: 0.7467\n",
            "Epoch 12/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4618 - recall_16: 0.7561\n",
            "Epoch 13/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4786 - recall_16: 0.7219\n",
            "Epoch 14/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4599 - recall_16: 0.7612\n",
            "Epoch 15/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4666 - recall_16: 0.7343\n",
            "Epoch 16/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4428 - recall_16: 0.7304\n",
            "Epoch 17/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4500 - recall_16: 0.7414\n",
            "Epoch 18/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4585 - recall_16: 0.7359\n",
            "Epoch 19/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4376 - recall_16: 0.7515\n",
            "Epoch 20/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4637 - recall_16: 0.7668\n",
            "Epoch 21/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4573 - recall_16: 0.7566\n",
            "Epoch 22/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4546 - recall_16: 0.7084\n",
            "Epoch 23/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4480 - recall_16: 0.7559\n",
            "Epoch 24/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4588 - recall_16: 0.7385\n",
            "Epoch 25/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4537 - recall_16: 0.7690\n",
            "Epoch 26/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4287 - recall_16: 0.7634\n",
            "Epoch 27/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4618 - recall_16: 0.8045\n",
            "Epoch 28/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4400 - recall_16: 0.7763\n",
            "Epoch 29/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4530 - recall_16: 0.7524\n",
            "Epoch 30/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4620 - recall_16: 0.7231\n",
            "Epoch 31/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4360 - recall_16: 0.7696\n",
            "Epoch 32/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4295 - recall_16: 0.7695\n",
            "Epoch 33/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4490 - recall_16: 0.7195\n",
            "Epoch 34/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4470 - recall_16: 0.7506\n",
            "Epoch 35/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4686 - recall_16: 0.7057\n",
            "Epoch 36/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4524 - recall_16: 0.7657\n",
            "Epoch 37/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4592 - recall_16: 0.7577\n",
            "Epoch 38/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4518 - recall_16: 0.7375\n",
            "Epoch 39/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4532 - recall_16: 0.7647\n",
            "Epoch 40/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4211 - recall_16: 0.7699\n",
            "Epoch 41/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4290 - recall_16: 0.7548\n",
            "Epoch 42/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4562 - recall_16: 0.7547\n",
            "Epoch 43/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4479 - recall_16: 0.7863\n",
            "Epoch 44/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4466 - recall_16: 0.7360\n",
            "Epoch 45/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4507 - recall_16: 0.7441\n",
            "Epoch 46/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4619 - recall_16: 0.7086\n",
            "Epoch 47/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4438 - recall_16: 0.7455\n",
            "Epoch 48/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4292 - recall_16: 0.7689\n",
            "Epoch 49/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4512 - recall_16: 0.7507\n",
            "Epoch 50/50\n",
            "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4189 - recall_16: 0.7706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f88825d8670>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Predição da RNA e resultados:\n",
        "\n"
      ],
      "metadata": {
        "id": "amArMmyxdeRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a predição da rede, será adotado 3 valores de thresholds e avaliado qual o melhor desempenho dentre eles."
      ],
      "metadata": {
        "id": "g5eH9-XGGUZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = [0.4, 0.5, 0.6]\n",
        "\n",
        "for i in thresholds:\n",
        "\n",
        "  y_pred_nm = ann_nm.predict(x_test_nm)\n",
        "  y_pred_nm = (y_pred_nm > i)\n",
        "\n",
        "  pred_array_nm = 1 * y_pred_nm.reshape(len(y_pred_nm), 1)\n",
        "  test_array_nm = y_test.values.reshape(len(y_test), 1)\n",
        "\n",
        "  ann_nm_2 = KerasClassifier(model=ann_nm, epochs=50, batch_size=64, verbose=0)\n",
        "  # Como o cross_val_score é incompatível com o Sequential, ele foi encapsulado no KerasClassifier.\n",
        "\n",
        "  score_model_nm = cross_val_score(ann_nm_2, x_test_nm, y_test, cv=5, scoring='accuracy')\n",
        "  score_model_nm = st.mean(score_model_nm)\n",
        "\n",
        "  cm_nm = confusion_matrix(test_array_nm, pred_array_nm)\n",
        "\n",
        "  cm_display_nm = ConfusionMatrixDisplay(confusion_matrix = cm_nm, display_labels = [\"Not churn\", \"Churn\"])\n",
        "\n",
        "  cm_display_nm.plot()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Recall da validação (%): \", ((recall_score(y_test, y_pred_nm)*100)))\n",
        "  print(\"Acurácia da validação (%): \", ((accuracy_score(y_test, y_pred_nm)*100)))\n",
        "  print(\"SCORE do modelo (%): \", (score_model_nm*100))"
      ],
      "metadata": {
        "id": "kDW_2-pKtNu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e614ca36-71c1-4359-da7f-c9a331f83ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall da validação (%):  82.3943661971831\n",
            "Acurácia da validação (%):  44.40497335701599\n",
            "SCORE do modelo (%):  87.98149351219426\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGwCAYAAAC6ty9tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABE0ElEQVR4nO3deXhU5fn/8c9kXychSBIiIexLBERRIUVBFgnIz4KkpdAoQVFbDCiLqLSCEBQQFxQboQolUEWqRfkKIhiwAkIARbEIiIBggiRQjUkImG3m/P6IGR0CmGGykJP367rOVeec5zznHgvJ7f0sx2IYhiEAAAAT8KjrAAAAAKoLiQ0AADANEhsAAGAaJDYAAMA0SGwAAIBpkNgAAADTILEBAACm4VXXAaBq7Ha7Tpw4oeDgYFkslroOBwDgIsMwdPr0aUVFRcnDo+bqCkVFRSopKXG7Hx8fH/n5+VVDRLWLxKaeOHHihKKjo+s6DACAm7KystSsWbMa6buoqEgtY4KUc8rmdl+RkZE6evRovUtuSGzqieDgYEnSbatHyjvQp46jAWrGkpitdR0CUGMKCu2KufaY4+d5TSgpKVHOKZu+2d1C1uBLrwoVnLYrptsxlZSUkNigZlQMP3kH+pDYwLTc+UEM1Be1MZ0gKNiioOBLf45d9XfKA4kNAAAmYzPssrnxJkibYa++YGoZiQ0AACZjlyG7Lj2zcefeukbdFwAAmAYVGwAATMYuu9wZTHLv7rpFYgMAgMnYDEM249KHk9y5t64xFAUAAEyDig0AACbTkCcPk9gAAGAydhmyNdDEhqEoAABgGlRsAAAwGYaiAACAabAqCgAAwASo2AAAYDL2nw537q+vSGwAADAZm5uroty5t66R2AAAYDI2Q26+3bv6YqltzLEBAACmQcUGAACTYY4NAAAwDbssssni1v31FUNRAADANKjYAABgMnaj/HDn/vqKxAYAAJOxuTkU5c69dY2hKAAAYBpUbAAAMJmGXLEhsQEAwGTshkV2w41VUW7cW9cYigIAAKZBxQYAAJNhKAoAAJiGTR6yuTEoY6vGWGobiQ0AACZjuDnHxmCODQAAQN2jYgMAgMkwxwYAAJiGzfCQzXBjjk09fqUCQ1EAAMA0qNgAAGAydllkd6N2YVf9LdmQ2AAAYDINeY4NQ1EAAMA0qNgAAGAy7k8eZigKAABcJsrn2LjxEkyGogAAAOoeFRsAAEzG7ua7olgVBQAALhvMsQEAAKZhl0eD3ceGOTYAAMA0qNgAAGAyNsMim+HGBn1u3FvXqNgAAGAytp8mD7tzuKJFixayWCyVjuTkZElSUVGRkpOT1bhxYwUFBSkhIUEnT5506iMzM1ODBw9WQECAwsPDNWXKFJWVlbn83UlsAACAWz7++GNlZ2c7jvT0dEnS73//e0nSxIkTtWbNGr355pvavHmzTpw4oWHDhjnut9lsGjx4sEpKSrR9+3YtW7ZMaWlpmj59usuxMBQFAIDJ2A0P2d1YFWX/aVVUQUGB03lfX1/5+vpWat+kSROnz3PnzlXr1q3Vu3dv5efna8mSJVqxYoX69u0rSVq6dKk6duyoHTt2qEePHnr//fe1f/9+bdy4UREREeratatmzZqlRx55RDNmzJCPj0+VY6diAwCAyVTXUFR0dLRCQkIcx5w5c3712SUlJXr11Vd19913y2KxaPfu3SotLVX//v0dbTp06KDmzZsrIyNDkpSRkaHOnTsrIiLC0SY+Pl4FBQXat2+fS9+dig0AADivrKwsWa1Wx+fzVWvOtXr1auXl5Wn06NGSpJycHPn4+Cg0NNSpXUREhHJychxtfpnUVFyvuOYKEhsAAEzGLvdWNtl/+l+r1eqU2FTFkiVLNGjQIEVFRV3y893BUBQAACZTsUGfO8el+Oabb7Rx40bdc889jnORkZEqKSlRXl6eU9uTJ08qMjLS0ebcVVIVnyvaVBWJDQAAqBZLly5VeHi4Bg8e7DjXrVs3eXt7a9OmTY5zBw8eVGZmpuLi4iRJcXFx2rt3r06dOuVok56eLqvVqtjYWJdiYCgKAACTcf9dUa7fa7fbtXTpUiUlJcnL6+f0IiQkRGPGjNGkSZMUFhYmq9Wq8ePHKy4uTj169JAkDRgwQLGxsbrzzjs1b9485eTk6LHHHlNycnKV5vX8EokNAAAmY5dFdrkzx8b1ezdu3KjMzEzdfffdla7Nnz9fHh4eSkhIUHFxseLj4/XSSy85rnt6emrt2rUaO3as4uLiFBgYqKSkJKWkpLgcB4kNAAAmUxcVmwEDBsi4wFvB/fz8lJqaqtTU1AveHxMTo3Xr1rn83HMxxwYAAJgGFRsAAEzmUt73dO799RWJDQAAJmM3LLK7s48Nb/cGAACoe1RsAAAwGbubQ1GXukHf5YDEBgAAk3H/7d71N7Gpv5EDAACcg4oNAAAmY5NFNjc26HPn3rpGYgMAgMkwFAUAAGACVGwAADAZm9wbTrJVXyi1jsQGAACTachDUSQ2AACYTF28BPNyUX8jBwAAOAcVGwAATMaQRXY35tgYLPcGAACXC4aiAAAATICKDQAAJmM3LLIblz6c5M69dY3EBgAAk7G5+XZvd+6ta/U3cgAAgHNQsQEAwGQYigIAAKZhl4fsbgzKuHNvXau/kQMAAJyDig0AACZjMyyyuTGc5M69dY3EBgAAk2GODQAAMA3Dzbd7G+w8DAAAUPeo2AAAYDI2WWRz40WW7txb10hsAAAwGbvh3jwZu1GNwdQyhqIAAIBpULFBg2P7n11nX/pRpTtKZRQZ8mzmoaC/BMqrY/lfB8Mw9OPiIhWtKZZx2pB3Fy8FPhQgz2jPn/vItOlM6o8q21smlRrybOOpgHv85d3Nu66+FiBJGnVDrE4e96l0/rak/2ncnG914piPXkmJ0r5dQSotsahbnwIlP/GtGjUpkyR9vj1ID/+uzXn7XrDuoNp3/bFG40f1sLs5edide+saic0vpKWlacKECcrLy6vrUFBD7AV2Ffz5tLyv9VLws0HyCLXIlmWXJfjnkm3Ra8Uq+nexgh4LkEdTD519pUgFkwoV+qpVFt/ydgUPF8qzmYesC4Jk8bXoxzeKVfBwoRq9ESKPxvX3BwLqvwXvHZTd9vOf52Nf+mnqiDa66bZ8FZ310F9Gtlar2B/11JuHJUnL5jXV9KSWemHtIXl4SLHXndHre75w6nPZvKba81GQ2l1NUlNf2GWR3Y15Mu7cW9fq9Cfw6NGjZbFYNHfuXKfzq1evlsXi2r/UFi1a6Pnnn6/G6GBGP75WJI9wDwX9NVDesV7yjPKUT3dveTYrr8YYhqEf3yiSf5KffG7ykVcbLwVNC5T9O7tKtpZKkux5dtmz7PK/w09ebbzkGe2pwD/7S0VS2de2uvx6gEIb2xQWXuY4dm4MUdMWxeoSV6h9uwJ1MstHk5/PVMuORWrZsUhTXvhGhz4P0J6PgiRJ3j6G0/3WRmXK2GDVgD/kysUfy0CdqPP/tPTz89NTTz2lH374oa5DqTElJSV1HQJ+UvpRqbw6eOr0Y4XKHZynvNEFKnqn2HHdfsIu43tD3tf9XMz0CLLIK9ZLZV+Ul+otIRZ5NPdQ8foSGT8aMsoMFf1fsSyNLPJq71npmUBdKS2x6INVjRQ/4ntZLOWfZSlPXip4+xqyeEj7dgWdt4+M90N0+gcvDfhDbm2FjWpQsfOwO0d9VeeJTf/+/RUZGak5c+ZctN2qVat01VVXydfXVy1atNCzzz7ruHbzzTfrm2++0cSJE2WxWC5a7cnLy9Of/vQnRUREyM/PT506ddLatWud2mzYsEEdO3ZUUFCQBg4cqOzsbKdnTZgwwan90KFDNXr0aMfnFi1aaNasWRo1apSsVqvuu+8+paWlKTQ09KJ9o+bZTthVtLpYns08ZZ0fJL/bfXVm/lkVrStPbuy55T/wPcKc/2p4hFlk/94uSbJYLLK+EKyyr2zKvSVPuX3z9OPKIlmfC5KHtc7/SgEO29eHqLDAUwOGlyclHbqdkV+AXUuejFLRWYuKznrolZQo2W0W5Z46/8yEDa83VrebT6tJVGlthg43Vcyxceeor+o8ck9PT82ePVsvvviijh8/ft42u3fv1vDhwzVixAjt3btXM2bM0LRp05SWliZJeuutt9SsWTOlpKQoOzv7gsmC3W7XoEGDtG3bNr366qvav3+/5s6dK0/Pn/8r++zZs3rmmWf0z3/+U1u2bFFmZqYeeughl7/XM888o6uvvlqfffaZpk2b5nLfxcXFKigocDpQDeySVztPBfzZX17tvOQ3xFd+v/VV8eriX7/3J4Zh6MyzZ+XRyCLrS8EKeSVYPr18dPrhQtm/s9dg8IBrNrwepuv7FKhxZHm1MbSxTY/9/Zh2pls1tG0X3d6+s84UeKpN57OynOe3wf9OeGv3h8GKH/l9LUcOXLrLYvLw7bffrq5du+rxxx/XkiVLKl1/7rnn1K9fP0eC0K5dO+3fv19PP/20Ro8erbCwMHl6eio4OFiRkZEXfM7GjRu1a9cuHThwQO3atZMktWrVyqlNaWmpFi1apNatW0uSxo0bp5SUFJe/U9++fTV58mTH561bt7rU95w5czRz5kyXn4uL82jsIc8WzsNFni08Vfxh+XChR1h5tc+ea5fHFT//pLfnGvJqW35f2e4ylW4vVaP1ofIILG8f1N5LP3xcquL3SuR/p19tfBXgok4e99ZnW4M1bfFRp/Pdbj6ttIwDyv/eU55eUlCITSOuvkpNm1dO7t//V5iCG5UpbkB+bYWNamKXm++KYvKw+5566iktW7ZMBw4cqHTtwIED6tmzp9O5nj176tChQ7LZqj5Zc8+ePWrWrJkjqTmfgIAAR+IhSU2bNtWpU6eq/IwK1113nVt9T506Vfn5+Y4jKyvL5RhQmVcXT9kynasqtkybPCPL/yp4RHnI0tii0t1ljuv2M4bK9pfJq9NPy8GLyoerKo14WiSjPu9qBVN5f2VjhV5Rpu79z1/tDWlsU1CITXs+ClLed17qMcC5nWGUJzb9f/eDvNjFoN4xfloVdamHQWLjvl69eik+Pl5Tp06tsWf4+/v/ahtvb+e/wRaLRYbx8y8rDw8Pp89SeZXnXIGBgS73/Uu+vr6yWq1OB9zn/wc/le0r09llP8p23Kbi90tU9E6x/Ib5Sir//8R/uJ9+XFakkq0lKjtiU+GsM/K4wkM+N5X//+fVyUuWYIsKnzijskNl5Xva/O2s7Nl2+fyG3wCoe3b7T0nJ73PleU5dfsPKMB3YHaATx3y0aVUjPfGnFrr9vv8puo1zxWbPR0HKyfTVwD8yDFUfVbzd252jvrpsEhtJmjt3rtasWaOMjAyn8x07dtS2bduczm3btk3t2rVzzI/x8fH51epNly5ddPz4cX311VeXHGOTJk2c5vDYbDZ98cUXF7kDlxOvjl4KnhOoko0lyruzQD+m/ajABwPkG+/raOOX6Cu/BF8Vzjur/HsKpB8NWZ8Ncuxh4xHqIeuzQTJ+NFTwQKHyxxSo7L9lCp4bJK+2l8XoLhq4z7YE69S3PoofUXkl0/Ejvpp5d0vd27uDXpsfoZEPnNR9009Uarf+9caKva5QzdtWff4ZGrZvv/1Wd9xxhxo3bix/f3917txZn3zyieO6YRiaPn26mjZtKn9/f/Xv31+HDh1y6iM3N1eJiYmyWq0KDQ3VmDFjVFhY6FIcl9VP4c6dOysxMVELFixwOj958mRdf/31mjVrlv7whz8oIyNDf/vb3/TSSy852rRo0UJbtmzRiBEj5OvrqyuuuKJS/71791avXr2UkJCg5557Tm3atNGXX34pi8WigQMHVinGvn37atKkSXr33XfVunVrPffcc2zoV8/49PSRT8/KO7NWsFgsCrjXXwH3XrjC59XRS9b5wTURHuC2bjef1oYTe857bcxfszXmr7++GnPqS99Uc1SoTbW98/APP/ygnj17qk+fPnrvvffUpEkTHTp0SI0aNXK0mTdvnhYsWKBly5apZcuWmjZtmuLj47V//375+ZXPTUxMTFR2drbS09NVWlqqu+66S/fdd59WrFhR5Vguq4qNJKWkpMhud54Dce211+qNN97QypUr1alTJ02fPl0pKSlOS6xTUlJ07NgxtW7dWk2aNLlg/6tWrdL111+vkSNHKjY2Vg8//LBL83TuvvtuJSUladSoUerdu7datWqlPn36uPw9AQCoKbU9FPXUU08pOjpaS5cu1Q033KCWLVtqwIABjnmlhmHo+eef12OPPaYhQ4aoS5cuWr58uU6cOKHVq1dLKp9Pu379ei1evFjdu3fXjTfeqBdffFErV67UiROVq4oXYjEuNMkDl5WCggKFhIRoWHqSvAMvXG0A6rMVLf9T1yEANabgtF2N2n2t/Pz8Gps3WfG7Ysj7d7v1u6L0TIn+b8A/lJWV5RSrr6+vfH19K7WPjY1VfHy8jh8/rs2bN+vKK6/U/fffr3vvvVeS9PXXX6t169b67LPP1LVrV8d9vXv3VteuXfXCCy/oH//4hyZPnuy0YW9ZWZn8/Pz05ptv6vbbb69S7JddxQYAALjHnRVRv3zPVHR0tEJCQhzHhTbT/frrr7Vw4UK1bdtWGzZs0NixY/XAAw9o2bJlkqScnBxJUkREhNN9ERERjms5OTkKDw93uu7l5aWwsDBHm6q4rObYAAAA97m7sqni3vNVbM7b3m7Xddddp9mzZ0uSrrnmGn3xxRdatGiRkpKSLjmOS0HFBgAAnNe5245cKLFp2rSpYmNjnc517NhRmZmZkuTYPPfkyZNObU6ePOm4FhkZWWlvt7KyMuXm5l50891zkdgAAGAytT15uGfPnjp48KDTua+++koxMTGSpJYtWyoyMlKbNm1yXC8oKNDOnTsVFxcnSYqLi1NeXp52797taPPBBx/Ibrere/fuVY6FoSgAAEymuoaiqmrixIn6zW9+o9mzZ2v48OHatWuXXn75Zb388suSyrfRmDBhgp544gm1bdvWsdw7KipKQ4cOlVRe4Rk4cKDuvfdeLVq0SKWlpRo3bpxGjBihqKioKsdCYgMAANxy/fXX6+2339bUqVOVkpKili1b6vnnn1diYqKjzcMPP6wzZ87ovvvuU15enm688UatX7/esYeNJL322msaN26c+vXrJw8PDyUkJFTa2+7XsNy7nmC5NxoClnvDzGpzufct6/7k9nLv9Fv/XqOx1hQqNgAAmIwh997QXZ8rHiQ2AACYTG3PsbmcsCoKAACYBhUbAABMpiFXbEhsAAAwmYac2DAUBQAATIOKDQAAJtOQKzYkNgAAmIxhWGS4kZy4c29dYygKAACYBhUbAABMxi6LWxv0uXNvXSOxAQDAZBryHBuGogAAgGlQsQEAwGQa8uRhEhsAAEymIQ9FkdgAAGAyDbliwxwbAABgGlRsAAAwGcPNoaj6XLEhsQEAwGQMSYbh3v31FUNRAADANKjYAABgMnZZZGHnYQAAYAasigIAADABKjYAAJiM3bDIwgZ9AADADAzDzVVR9XhZFENRAADANKjYAABgMg158jCJDQAAJkNiAwAATKMhTx5mjg0AADANKjYAAJhMQ14VRWIDAIDJlCc27syxqcZgahlDUQAAwDSo2AAAYDKsigIAAKZh/HS4c399xVAUAAAwDSo2AACYDENRAADAPBrwWBSJDQAAZuNmxUb1uGLDHBsAAGAaVGwAADCZhrzzMBUbAABMpmLysDuHK2bMmCGLxeJ0dOjQwXG9qKhIycnJaty4sYKCgpSQkKCTJ0869ZGZmanBgwcrICBA4eHhmjJlisrKylz+7lRsAACA26666ipt3LjR8dnL6+cUY+LEiXr33Xf15ptvKiQkROPGjdOwYcO0bds2SZLNZtPgwYMVGRmp7du3Kzs7W6NGjZK3t7dmz57tUhwkNgAAmI1hcW8C8E/3FhQUOJ329fWVr6/veW/x8vJSZGRkpfP5+flasmSJVqxYob59+0qSli5dqo4dO2rHjh3q0aOH3n//fe3fv18bN25URESEunbtqlmzZumRRx7RjBkz5OPjU+XQGYoCAMBkKubYuHNIUnR0tEJCQhzHnDlzLvjMQ4cOKSoqSq1atVJiYqIyMzMlSbt371Zpaan69+/vaNuhQwc1b95cGRkZkqSMjAx17txZERERjjbx8fEqKCjQvn37XPruVGwAAMB5ZWVlyWq1Oj5fqFrTvXt3paWlqX379srOztbMmTN100036YsvvlBOTo58fHwUGhrqdE9ERIRycnIkSTk5OU5JTcX1imuuILEBAMBsqmmDPqvV6pTYXMigQYMc/9ylSxd1795dMTExeuONN+Tv7+9GIK5jKAoAAJOp7VVR5woNDVW7du10+PBhRUZGqqSkRHl5eU5tTp486ZiTExkZWWmVVMXn883buZgqVWzeeeedKnf429/+1qUAAACAuRQWFurIkSO688471a1bN3l7e2vTpk1KSEiQJB08eFCZmZmKi4uTJMXFxenJJ5/UqVOnFB4eLklKT0+X1WpVbGysS8+uUmIzdOjQKnVmsVhks9lcCgAAANSAWtxk76GHHtJtt92mmJgYnThxQo8//rg8PT01cuRIhYSEaMyYMZo0aZLCwsJktVo1fvx4xcXFqUePHpKkAQMGKDY2VnfeeafmzZunnJwcPfbYY0pOTr7gvJ4LqVJiY7fbXf+WAACgTtT2272PHz+ukSNH6vvvv1eTJk104403aseOHWrSpIkkaf78+fLw8FBCQoKKi4sVHx+vl156yXG/p6en1q5dq7FjxyouLk6BgYFKSkpSSkqKy7G7NXm4qKhIfn5+7nQBAACqWy2/3XvlypUXve7n56fU1FSlpqZesE1MTIzWrVvn2oPPw+XJwzabTbNmzdKVV16poKAgff3115KkadOmacmSJW4HBAAAcKlcTmyefPJJpaWlad68eU47AXbq1EmLFy+u1uAAAMClsFTDUT+5nNgsX75cL7/8shITE+Xp6ek4f/XVV+vLL7+s1uAAAMAlMKrhqKdcTmy+/fZbtWnTptJ5u92u0tLSagkKAADgUric2MTGxmrr1q2Vzv/73//WNddcUy1BAQAANzTgio3Lq6KmT5+upKQkffvtt7Lb7Xrrrbd08OBBLV++XGvXrq2JGAEAgCuq6e3e9ZHLFZshQ4ZozZo12rhxowIDAzV9+nQdOHBAa9as0S233FITMQIAAFTJJe1jc9NNNyk9Pb26YwEAANXAMMoPd+6vry55g75PPvlEBw4ckFQ+76Zbt27VFhQAAHBDLW/QdzlxObGp2DZ527ZtCg0NlSTl5eXpN7/5jVauXKlmzZpVd4wAAABV4vIcm3vuuUelpaU6cOCAcnNzlZubqwMHDshut+uee+6piRgBAIArKiYPu3PUUy5XbDZv3qzt27erffv2jnPt27fXiy++qJtuuqlagwMAAK6zGOWHO/fXVy4nNtHR0efdiM9msykqKqpaggIAAG5owHNsXB6KevrppzV+/Hh98sknjnOffPKJHnzwQT3zzDPVGhwAAIArqlSxadSokSyWn8fbzpw5o+7du8vLq/z2srIyeXl56e6779bQoUNrJFAAAFBFDXiDviolNs8//3wNhwEAAKpNAx6KqlJik5SUVNNxAAAAuO2SN+iTpKKiIpWUlDids1qtbgUEAADc1IArNi5PHj5z5ozGjRun8PBwBQYGqlGjRk4HAACoYw347d4uJzYPP/ywPvjgAy1cuFC+vr5avHixZs6cqaioKC1fvrwmYgQAAKgSl4ei1qxZo+XLl+vmm2/WXXfdpZtuuklt2rRRTEyMXnvtNSUmJtZEnAAAoKoa8Koolys2ubm5atWqlaTy+TS5ubmSpBtvvFFbtmyp3ugAAIDLKnYedueor1xObFq1aqWjR49Kkjp06KA33nhDUnklp+KlmAAAAHXB5cTmrrvu0ueffy5JevTRR5Wamio/Pz9NnDhRU6ZMqfYAAQCAixrw5GGX59hMnDjR8c/9+/fXl19+qd27d6tNmzbq0qVLtQYHAADgCrf2sZGkmJgYxcTEVEcsAACgGljk5tu9qy2S2lelxGbBggVV7vCBBx645GAAAADcUaXEZv78+VXqzGKxkNjUsNxb8uRl8a7rMIAa0a/fmLoOAagxZWVFkmbWzsMa8HLvKiU2FaugAABAPcArFQAAAOo/tycPAwCAy0wDrtiQ2AAAYDLu7h7coHYeBgAAuFxRsQEAwGwa8FDUJVVstm7dqjvuuENxcXH69ttvJUn//Oc/9dFHH1VrcAAA4BI04FcquJzYrFq1SvHx8fL399dnn32m4uJiSVJ+fr5mz55d7QECAABUlcuJzRNPPKFFixbplVdekbf3zxvF9ezZU59++mm1BgcAAFxXMXnYnaO+cnmOzcGDB9WrV69K50NCQpSXl1cdMQEAAHc04J2HXa7YREZG6vDhw5XOf/TRR2rVqlW1BAUAANzAHJuqu/fee/Xggw9q586dslgsOnHihF577TU99NBDGjt2bE3ECAAAUCUuJzaPPvqo/vjHP6pfv34qLCxUr169dM899+hPf/qTxo8fXxMxAgAAF9T1HJu5c+fKYrFowoQJjnNFRUVKTk5W48aNFRQUpISEBJ08edLpvszMTA0ePFgBAQEKDw/XlClTVFZW5tKzXZ5jY7FY9Ne//lVTpkzR4cOHVVhYqNjYWAUFBbnaFQAAqAl1uI/Nxx9/rL///e/q0qWL0/mJEyfq3Xff1ZtvvqmQkBCNGzdOw4YN07Zt2yRJNptNgwcPVmRkpLZv367s7GyNGjVK3t7eLq26vuSdh318fBQbG6sbbriBpAYAABMqKChwOiq2eLmQwsJCJSYm6pVXXlGjRo0c5/Pz87VkyRI999xz6tu3r7p166alS5dq+/bt2rFjhyTp/fff1/79+/Xqq6+qa9euGjRokGbNmqXU1FSVlJRUOWaXE5s+ffqob9++FzwAAEAdc3cY6qeKTXR0tEJCQhzHnDlzLvrY5ORkDR48WP3793c6v3v3bpWWljqd79Chg5o3b66MjAxJUkZGhjp37qyIiAhHm/j4eBUUFGjfvn1V/uouD0V17drV6XNpaan27NmjL774QklJSa52BwAAqls1DUVlZWXJarU6Tvv6+l7wlpUrV+rTTz/Vxx9/XOlaTk6OfHx8FBoa6nQ+IiJCOTk5jja/TGoqrldcqyqXE5v58+ef9/yMGTNUWFjoancAAOAyZbVanRKbC8nKytKDDz6o9PR0+fn51UJkF1Ztb/e+44479I9//KO6ugMAAJeqlvex2b17t06dOqVrr71WXl5e8vLy0ubNm7VgwQJ5eXkpIiJCJSUllTbyPXnypCIjIyWV75N37iqpis8Vbaqi2hKbjIyMOs/SAABA7S/37tevn/bu3as9e/Y4juuuu06JiYmOf/b29tamTZsc9xw8eFCZmZmKi4uTJMXFxWnv3r06deqUo016erqsVqtiY2OrHIvLQ1HDhg1z+mwYhrKzs/XJJ59o2rRprnYHAADqueDgYHXq1MnpXGBgoBo3buw4P2bMGE2aNElhYWGyWq0aP3684uLi1KNHD0nSgAEDFBsbqzvvvFPz5s1TTk6OHnvsMSUnJ190bs+5XE5sQkJCnD57eHioffv2SklJ0YABA1ztDgAANADz58+Xh4eHEhISVFxcrPj4eL300kuO656enlq7dq3Gjh2ruLg4BQYGKikpSSkpKS49x6XExmaz6a677lLnzp2d1qcDAIDLSB1u0Ffhww8/dPrs5+en1NRUpaamXvCemJgYrVu3zq3nujTHxtPTUwMGDOAt3gAAXMbq+pUKdcnlycOdOnXS119/XROxAAAAuMXlxOaJJ57QQw89pLVr1yo7O7vSdssAAOAyUEtLvS83VZ5jk5KSosmTJ+vWW2+VJP32t7+VxWJxXDcMQxaLRTabrfqjBAAAVXcZzLGpK1VObGbOnKk///nP+s9//lOT8QAAAFyyKic2hlGevvXu3bvGggEAAO5zdwJwfZ487NJy718OPQEAgMsUQ1FV065du19NbnJzc90KCAAA4FK5lNjMnDmz0s7DAADg8sJQVBWNGDFC4eHhNRULAACoDg14KKrK+9gwvwYAAFzuXF4VBQAALnMNuGJT5cTGbrfXZBwAAKCaMMcGAACYRwOu2Lj8rigAAIDLFRUbAADMpgFXbEhsAAAwmYY8x4ahKAAAYBpUbAAAMBuGogAAgFkwFAUAAGACVGwAADAbhqIAAIBpNODEhqEoAABgGlRsAAAwGctPhzv311ckNgAAmE0DHooisQEAwGRY7g0AAGACVGwAADAbhqIAAICp1OPkxB0MRQEAANOgYgMAgMk05MnDJDYAAJhNA55jw1AUAAAwDSo2AACYDENRAADAPBiKAgAAqP+o2AAAYDIMRQEAAPNgKAoAAJiGUQ2HCxYuXKguXbrIarXKarUqLi5O7733nuN6UVGRkpOT1bhxYwUFBSkhIUEnT5506iMzM1ODBw9WQECAwsPDNWXKFJWVlbn81UlsAACAW5o1a6a5c+dq9+7d+uSTT9S3b18NGTJE+/btkyRNnDhRa9as0ZtvvqnNmzfrxIkTGjZsmON+m82mwYMHq6SkRNu3b9eyZcuUlpam6dOnuxwLQ1EAAJhMbc+xue2225w+P/nkk1q4cKF27NihZs2aacmSJVqxYoX69u0rSVq6dKk6duyoHTt2qEePHnr//fe1f/9+bdy4UREREeratatmzZqlRx55RDNmzJCPj0+VY6FiAwCA2VTTUFRBQYHTUVxc/KuPttlsWrlypc6cOaO4uDjt3r1bpaWl6t+/v6NNhw4d1Lx5c2VkZEiSMjIy1LlzZ0VERDjaxMfHq6CgwFH1qSoSGwAAcF7R0dEKCQlxHHPmzLlg27179yooKEi+vr7685//rLfffluxsbHKycmRj4+PQkNDndpHREQoJydHkpSTk+OU1FRcr7jmCoaiAAAwGYthyGJc+lhUxb1ZWVmyWq2O876+vhe8p3379tqzZ4/y8/P173//W0lJSdq8efMlx3CpSGwAADCbalruXbHKqSp8fHzUpk0bSVK3bt308ccf64UXXtAf/vAHlZSUKC8vz6lqc/LkSUVGRkqSIiMjtWvXLqf+KlZNVbSpKoaiAABAtbPb7SouLla3bt3k7e2tTZs2Oa4dPHhQmZmZiouLkyTFxcVp7969OnXqlKNNenq6rFarYmNjXXouFRsAAEymtldFTZ06VYMGDVLz5s11+vRprVixQh9++KE2bNigkJAQjRkzRpMmTVJYWJisVqvGjx+vuLg49ejRQ5I0YMAAxcbG6s4779S8efOUk5Ojxx57TMnJyRcd/jofEhsAAMymlncePnXqlEaNGqXs7GyFhISoS5cu2rBhg2655RZJ0vz58+Xh4aGEhAQVFxcrPj5eL730kuN+T09PrV27VmPHjlVcXJwCAwOVlJSklJQUl0MnsQEAAG5ZsmTJRa/7+fkpNTVVqampF2wTExOjdevWuR0LiQ0AACbDSzABAIB5NOCXYJLYAABgMg25YsNybwAAYBpUbAAAMBuGogAAgJnU5+EkdzAUBQAATIOKDQAAZmMY5Yc799dTJDYAAJgMq6IAAABMgIoNAABmw6ooAABgFhZ7+eHO/fUVQ1EAAMA0qNigwWscWaoxfz2h6/uclq+/XSeO+erZidE69N8ASdKGE5+f975XZjXVvxeG12aowEWNvO1z3XjdN2reNE/FpV7afyhcL6+8XsdzQhxtBvf5Un3jvlbbFt8r0L9Uv/1Tos6c9XVcv7pDtp7763vn7f/+6bfp4NEmNf49UA0YioIkWSwWvf322xo6dGhdh4JaEhRSpuf+75D+uz1Ij93RSnnfe+rKViUqzPd0tBlxdazTPdf3Pa2Jz2bpo3dDzu0OqFNdOuTonY0d9eXXV8jT064xv9+teY+s192PDlNRsbckydfHpo//e6U+/u+VuvcPuyv1se9QuH43boTTubsSPtU1V53QwaNX1Mr3gPsa8qqoBpXY5OTk6Mknn9S7776rb7/9VuHh4eratasmTJigfv361XV4qAPDk0/puxM+enZic8e5k1m+Tm1++J+30+e4+Hx9vi1IOZnO7YC6NvXpeKfP816+SW+99Lratvheew9GSpLe2nCVpPLKzPmU2Tz1Q36A47Onp12/6Zap1e/HSrLUTOCofuxjY37Hjh1Tz549FRoaqqefflqdO3dWaWmpNmzYoOTkZH355Zc18tySkhL5+PjUSN9wX48BBdr9YbD++vdj6hJ3Rt/leGlt2hV6b0Xj87YPvaJUN/Qr0DMTmp/3OnA5CfQvlSSdPnPpSfhvrsmUNahY67e0ra6wgBrVYCYP33///bJYLNq1a5cSEhLUrl07XXXVVZo0aZJ27NjhaPfdd9/p9ttvV0BAgNq2bat33nnHcS0tLU2hoaFO/a5evVoWy8//FTNjxgx17dpVixcvVsuWLeXn5yepfJhr8eLFF+z7XMXFxSooKHA6UP2aNi/R/xv1vU4c9dVf/thSa5ddobGzvlX/3+eet/0tw3/Qj4We+mgdw1C4vFkshpLv2Km9B8N17HijS+5n0M1f6ZO9V+q7HwKrMTrUtIqhKHeO+qpBJDa5ublav369kpOTFRhY+S/nL5OVmTNnavjw4frvf/+rW2+9VYmJicrNPf8vuQs5fPiwVq1apbfeekt79uy5pL7nzJmjkJAQxxEdHe1SDKgai4d0+At/LZ3bVEe+CNB7rzXWeysaa/Cd35+3ffyIXH3wdqhKixvEXx3UYw8kZahFsx/0RGqfS+7jikZndF3nb/Xeh+2qMTLUCqMajnqqQfx0Pnz4sAzDUIcOHX617ejRozVy5Ei1adNGs2fPVmFhoXbt2uXS80pKSrR8+XJdc8016tKlyyX1PXXqVOXn5zuOrKwsl2JA1eSe8tI3X/k5ncs65KvwK0sqte10Q6Gi2xRr/QWGqYDLxfhRGerRNUuT5wxyq9IysNchFRT6avtnDL2i/mgQc2wMFyZB/TIRCQwMlNVq1alTp1x6XkxMjJo0qbwk0pW+fX195evL5NSatv/jQEW3LnY6d2WrYp36tvK8qPiRufrqc399vd+/tsIDXGRo/KgdurHbN5o0e5By/hfsVl/xvb5S+kdtZLM1iP8GNpWGvCqqQfxpbdu2rSwWS5UmCHt7O6+AsVgsstvLt2D08PColCSVlpZW6uN8w12/1jfqxlsvN1GHa89oxPiTimpRrD63/6Bb78jVO0udl7UGBNnU67Z8rV8RVkeRAr/ugaQM9f/NET25sLfOFnmrUchZNQo5Kx/vMkebRiFn1br597oyonzeXqtmP6h18+8VHOic4F8Tm62o8EKtYxiqfqpYFeXOUU81iIpNWFiY4uPjlZqaqgceeKBS4pGXl1dpUvD5NGnSRKdPn9aZM2ccffxyDg3qn68+D1DKmJa6a2q2EieeVE6WjxZNj9J/3naebNl7SJ5kMfSf1Zc+CROoaUP6l//H2/xzNtib9/JN2rC1fFXTbX2/VNKwPY5rz09bV6mNJA3q/ZW++CpcWdmhNRs0UM0aRGIjSampqerZs6duuOEGpaSkqEuXLiorK1N6eroWLlyoAwcO/Gof3bt3V0BAgP7yl7/ogQce0M6dO5WWllbzwaNG7dxo1c6N1ou2ee+1xnrvNebW4PLW7867f7XN8rev1fK3r/3VdrMX3lwNEaGuMBTVALRq1Uqffvqp+vTpo8mTJ6tTp0665ZZbtGnTJi1cuLBKfYSFhenVV1/VunXr1LlzZ73++uuaMWNGzQYOAICrGvCqKIvhysxa1JmCggKFhIToZg2Rl8X7128A6qGyft3qOgSgxpSVFemjD2cqPz9fVuvFq8SXquJ3RdzAFHl5+/36DRdQVlqkjPXTazTWmtJghqIAAGgoGvJQFIkNAABmYzfKD3fur6dIbAAAMBt358nU37ym4UweBgAA5kfFBgAAk7HIzTk21RZJ7SOxAQDAbNzdPbgeL5hmKAoAAJgGFRsAAEyG5d4AAMA8WBUFAABQ/1GxAQDAZCyGIYsbE4DdubeukdgAAGA29p8Od+6vpxiKAgAApkHFBgAAk2nIQ1FUbAAAMBujGg4XzJkzR9dff72Cg4MVHh6uoUOH6uDBg05tioqKlJycrMaNGysoKEgJCQk6efKkU5vMzEwNHjxYAQEBCg8P15QpU1RWVuZSLCQ2AACYTcXOw+4cLti8ebOSk5O1Y8cOpaenq7S0VAMGDNCZM2ccbSZOnKg1a9bozTff1ObNm3XixAkNGzbMcd1ms2nw4MEqKSnR9u3btWzZMqWlpWn69OkuxcJQFAAAOK+CggKnz76+vvL19a3Ubv369U6f09LSFB4ert27d6tXr17Kz8/XkiVLtGLFCvXt21eStHTpUnXs2FE7duxQjx499P7772v//v3auHGjIiIi1LVrV82aNUuPPPKIZsyYIR8fnyrFTMUGAACTqdh52J1DkqKjoxUSEuI45syZU6Xn5+fnS5LCwsIkSbt371Zpaan69+/vaNOhQwc1b95cGRkZkqSMjAx17txZERERjjbx8fEqKCjQvn37qvzdqdgAAGA21fQSzKysLFmtVsfp81VrzmW32zVhwgT17NlTnTp1kiTl5OTIx8dHoaGhTm0jIiKUk5PjaPPLpKbiesW1qiKxAQAA52W1Wp0Sm6pITk7WF198oY8++qiGoro4hqIAADAZi93941KMGzdOa9eu1X/+8x81a9bMcT4yMlIlJSXKy8tzan/y5ElFRkY62py7Sqric0WbqiCxAQDAbGp5VZRhGBo3bpzefvttffDBB2rZsqXT9W7dusnb21ubNm1ynDt48KAyMzMVFxcnSYqLi9PevXt16tQpR5v09HRZrVbFxsZWORaGogAAgFuSk5O1YsUK/d///Z+Cg4Mdc2JCQkLk7++vkJAQjRkzRpMmTVJYWJisVqvGjx+vuLg49ejRQ5I0YMAAxcbG6s4779S8efOUk5Ojxx57TMnJyVWa21OBxAYAALO5hE32Kt3vgoULF0qSbr75ZqfzS5cu1ejRoyVJ8+fPl4eHhxISElRcXKz4+Hi99NJLjraenp5au3atxo4dq7i4OAUGBiopKUkpKSkuxUJiAwCAydT2KxWMKrT38/NTamqqUlNTL9gmJiZG69atc+nZ52KODQAAMA0qNgAAmE017WNTH5HYAABgNoakS1yy7bi/niKxAQDAZGp7js3lhDk2AADANKjYAABgNobcnGNTbZHUOhIbAADMpgFPHmYoCgAAmAYVGwAAzMYuyeLm/fUUiQ0AACbDqigAAAAToGIDAIDZNODJwyQ2AACYTQNObBiKAgAApkHFBgAAs2nAFRsSGwAAzIbl3gAAwCxY7g0AAGACVGwAADAb5tgAAADTsBuSxY3kxF5/ExuGogAAgGlQsQEAwGwYigIAAObhZmKj+pvYMBQFAABMg4oNAABmw1AUAAAwDbsht4aTWBUFAABQ96jYAABgNoa9/HDn/nqKxAYAALNhjg0AADAN5tgAAADUf1RsAAAwG4aiAACAaRhyM7GptkhqHUNRAADANKjYAABgNgxFAQAA07DbJbmxF429/u5jw1AUAAAwDSo2AACYDUNRAADANBpwYsNQFAAAcNuWLVt02223KSoqShaLRatXr3a6bhiGpk+frqZNm8rf31/9+/fXoUOHnNrk5uYqMTFRVqtVoaGhGjNmjAoLC12Kg8QGAACzsRvuHy46c+aMrr76aqWmpp73+rx587RgwQItWrRIO3fuVGBgoOLj41VUVORok5iYqH379ik9PV1r167Vli1bdN9997kUB0NRAACYjGHYZbjxhu5LuXfQoEEaNGjQBfoz9Pzzz+uxxx7TkCFDJEnLly9XRESEVq9erREjRujAgQNav369Pv74Y1133XWSpBdffFG33nqrnnnmGUVFRVUpDio2AACYjeFmteanOTYFBQVOR3Fx8SWFc/ToUeXk5Kh///6OcyEhIerevbsyMjIkSRkZGQoNDXUkNZLUv39/eXh4aOfOnVV+FokNAAA4r+joaIWEhDiOOXPmXFI/OTk5kqSIiAin8xEREY5rOTk5Cg8Pd7ru5eWlsLAwR5uqYCgKAACzMQy59cKnnyo2WVlZslqtjtO+vr5uBlbzSGwAADAbu12yuLF78E9zbKxWq1Nic6kiIyMlSSdPnlTTpk0d50+ePKmuXbs62pw6dcrpvrKyMuXm5jrurwqGogAAQI1q2bKlIiMjtWnTJse5goIC7dy5U3FxcZKkuLg45eXlaffu3Y42H3zwgex2u7p3717lZ1GxAQDAbKppKMoVhYWFOnz4sOPz0aNHtWfPHoWFhal58+aaMGGCnnjiCbVt21YtW7bUtGnTFBUVpaFDh0qSOnbsqIEDB+ree+/VokWLVFpaqnHjxmnEiBFVXhElkdgAAGA6ht0uw42hqEtZ7v3JJ5+oT58+js+TJk2SJCUlJSktLU0PP/ywzpw5o/vuu095eXm68cYbtX79evn5+Tnuee211zRu3Dj169dPHh4eSkhI0IIFC1yKw2IY9Xjf5AakoKBAISEhullD5GXxrutwgBpR1q9bXYcA1JiysiJ99OFM5efnV8u8lfOp+F3RN2CEvCw+l9xPmVGiD86urNFYawoVGwAAzKYOhqIuFyQ2AACYjd2QLA0zsWFVFAAAMA0qNgAAmI1hSHJnH5v6W7EhsQEAwGQMuyHDjaGo+ryuiMQGAACzMexyr2Ljxr11jDk2AADANKjYAABgMgxFAQAA82jAQ1EkNvVERfZcplK39lwCLmdlZUV1HQJQY8rKiiXVTjXE3d8VZSqtvmBqGa9UqCeOHz+u6Ojoug4DAOCmrKwsNWvWrEb6LioqUsuWLZWTk+N2X5GRkTp69KjTu5zqAxKbesJut+vEiRMKDg6WxWKp63AahIKCAkVHRysrK6vevSsFqAr+jNcuwzB0+vRpRUVFycOj5tbuFBUVqaSkxO1+fHx86l1SIzEUVW94eHjUWIaPi7NarfzQh6nxZ7z2hISE1Pgz/Pz86mVCUl1Y7g0AAEyDxAYAAJgGiQ1wAb6+vnr88cfl6+tb16EANYI/4zAjJg8DAADToGIDAABMg8QGAACYBokNAAAwDRIboIrS0tIUGhpa12EAVWKxWLR69eq6DgOodSQ2uGyNHj1aFotFc+fOdTq/evVql3dfbtGihZ5//vlqjA6oWzk5ORo/frxatWolX19fRUdH67bbbtOmTZvqOjSgTpHY4LLm5+enp556Sj/88ENdh1JjqmPrczQsx44dU7du3fTBBx/o6aef1t69e7V+/Xr16dNHycnJNfZc/qyiPiCxwWWtf//+ioyM1Jw5cy7abtWqVbrqqqvk6+urFi1a6Nlnn3Vcu/nmm/XNN99o4sSJslgsF6325OXl6U9/+pMiIiLk5+enTp06ae3atU5tNmzYoI4dOyooKEgDBw5Udna207MmTJjg1H7o0KEaPXq043OLFi00a9YsjRo1SlarVffdd59jmOtifQMV7r//flksFu3atUsJCQlq166drrrqKk2aNEk7duxwtPvuu+90++23KyAgQG3bttU777zjuHa+odVzq6EzZsxQ165dtXjxYrVs2dKxTb/FYtHixYsv2DdQl0hscFnz9PTU7Nmz9eKLL+r48ePnbbN7924NHz5cI0aM0N69ezVjxgxNmzZNaWlpkqS33npLzZo1U0pKirKzsy+YLNjtdg0aNEjbtm3Tq6++qv3792vu3Lny9PR0tDl79qyeeeYZ/fOf/9SWLVuUmZmphx56yOXv9cwzz+jqq6/WZ599pmnTplVr3zC33NxcrV+/XsnJyQoMDKx0/ZfJysyZMzV8+HD997//1a233qrExETl5ua69LzDhw9r1apVeuutt7Rnz55q7RuoCbwEE5e922+/XV27dtXjjz+uJUuWVLr+3HPPqV+/fo4EoV27dtq/f7+efvppjR49WmFhYfL09FRwcLAiIyMv+JyNGzdq165dOnDggNq1aydJatWqlVOb0tJSLVq0SK1bt5YkjRs3TikpKS5/p759+2ry5MmOz1u3bq22vmFuhw8flmEY6tChw6+2HT16tEaOHClJmj17thYsWKBdu3Zp4MCBVX5eSUmJli9friZNmlR730BNoGKDeuGpp57SsmXLdODAgUrXDhw4oJ49ezqd69mzpw4dOiSbzVblZ+zZs0fNmjVzJDXnExAQ4Eg8JKlp06Y6depUlZ9R4brrrquxvmFurmwW36VLF8c/BwYGymq1uvxnKiYmplJSU119AzWBxAb1Qq9evRQfH6+pU6fW2DP8/f1/tY23t7fTZ4vF4vSLxsPDo9IvntLS0kr9nG8I4df6BiSpbdu2slgs+vLLL3+17fn+TNntdknu/Vn9tb6BukRig3pj7ty5WrNmjTIyMpzOd+zYUdu2bXM6t23bNrVr184xP8bHx+dXqzddunTR8ePH9dVXX11yjE2aNHGaw2Oz2fTFF19ccn/AucLCwhQfH6/U1FSdOXOm0vW8vLwq9dOkSROdPn3aqY9fzqEB6isSG9QbnTt3VmJiohYsWOB0fvLkydq0aZNmzZqlr776SsuWLdPf/vY3p4m3LVq00JYtW/Ttt9/qu+++O2//vXv3Vq9evZSQkKD09HQdPXpU7733ntavX1/lGPv27at3331X7777rr788kuNHTu2yr9ogKpKTU2VzWbTDTfcoFWrVunQoUM6cOCAFixYoLi4uCr10b17dwUEBOgvf/mLjhw5ohUrVjgm3AP1GYkN6pWUlJRK5e5rr71Wb7zxhlauXKlOnTpp+vTpSklJcVpinZKSomPHjql169bnnS9QYdWqVbr++us1cuRIxcbG6uGHH3Zpns7dd9+tpKQkjRo1Sr1791arVq3Up08fl78ncDGtWrXSp59+qj59+mjy5Mnq1KmTbrnlFm3atEkLFy6sUh9hYWF69dVXtW7dOnXu3Fmvv/66ZsyYUbOBA7XAYjCIDwAATIKKDQAAMA0SGwAAYBokNgAAwDRIbAAAgGmQ2AAAANMgsQEAAKZBYgMAAEyDxAYAAJgGiQ2AKhs9erSGDh3q+HzzzTdrwoQJtR7Hhx9+KIvFctHXVVgsFq1evbrKfc6YMUNdu3Z1K65jx47JYrHwziWgDpHYAPXc6NGjZbFYZLFY5OPjozZt2iglJUVlZWU1/uy33npLs2bNqlLbqiQjAOAur7oOAID7Bg4cqKVLl6q4uFjr1q1TcnKyvL29NXXq1EptS0pK5OPjUy3PDQsLq5Z+AKC6ULEBTMDX11eRkZGKiYnR2LFj1b9/f73zzjuSfh4+evLJJxUVFaX27dtLkrKysjR8+HCFhoYqLCxMQ4YM0bFjxxx92mw2TZo0SaGhoWrcuLEefvhhnftquXOHooqLi/XII48oOjpavr6+atOmjZYsWaJjx445XgbaqFEjWSwWx0tK7Xa75syZo5YtW8rf319XX321/v3vfzs9Z926dWrXrp38/f3Vp08fpzir6pFHHlG7du0UEBCgVq1aadq0aSotLa3U7u9//7uio6MVEBCg4cOHKz8/3+n64sWL1bFjR/n5+alDhw566aWXXI4FQM0hsQFMyN/fXyUlJY7PmzZt0sGDB5Wenq61a9eqtLRU8fHxCg4O1tatW7Vt2zYFBQVp4MCBjvueffZZpaWl6R//+Ic++ugj5ebm6u23377oc0eNGqXXX39dCxYs0IEDB/T3v/9dQUFBio6O1qpVqyRJBw8eVHZ2tl544QVJ0pw5c7R8+XItWrRI+/bt08SJE3XHHXdo8+bNksoTsGHDhum2227Tnj17dM899+jRRx91+d9JcHCw0tLStH//fr3wwgt65ZVXNH/+fKc2hw8f1htvvKE1a9Zo/fr1+uyzz3T//fc7rr/22muaPn26nnzySR04cECzZ8/WtGnTtGzZMpfjAVBDDAD1WlJSkjFkyBDDMAzDbrcb6enphq+vr/HQQw85rkdERBjFxcWOe/75z38a7du3N+x2u+NccXGx4e/vb2zYsMEwDMNo2rSpMW/ePMf10tJSo1mzZo5nGYZh9O7d23jwwQcNwzCMgwcPGpKM9PT088b5n//8x5Bk/PDDD45zRUVFRkBAgLF9+3antmPGjDFGjhxpGIZhTJ061YiNjXW6/sgjj1Tq61ySjLfffvuC159++mmjW7dujs+PP/644enpaRw/ftxx7r333jM8PDyM7OxswzAMo3Xr1saKFSuc+pk1a5YRFxdnGIZhHD161JBkfPbZZxd8LoCaxRwbwATWrl2roKAglZaWym63649//KNmzJjhuN65c2eneTWff/65Dh8+rODgYKd+ioqKdOTIEeXn5ys7O1vdu3d3XPPy8tJ1111XaTiqwp49e+Tp6anevXtXOe7Dhw/r7NmzuuWWW5zOl5SU6JprrpEkHThwwCkOSYqLi6vyMyr861//0oIFC3TkyBEVFhaqrKxMVqvVqU3z5s115ZVXOj3Hbrfr4MGDCg4O1pEjRzRmzBjde++9jjZlZWUKCQlxOR4ANYPEBjCBPn36aOHChfLx8VFUVJS8vJz/agcGBjp9LiwsVLdu3fTaa69V6qtJkyaXFIO/v7/L9xQWFkqS3n33XaeEQiqfN1RdMjIylJiYqJkzZyo+Pl4hISFauXKlnn32WZdjfeWVVyolWp6entUWKwD3kNgAJhAYGKg2bdpUuf21116rf/3rXwoPD69UtajQtGlT7dy5U7169ZJUXpnYvXu3rr322vO279y5s+x2uzZv3qz+/ftXul5RMbLZbI5zsbGx8vX1VWZm5gUrPR07dnRMhK6wY8eOX/+Sv7B9+3bFxMTor3/9q+PcN998U6ldZmamTpw4oaioKMdzPDw81L59e0VERCgqKkpff/21EhMTXXo+gNrD5GGgAUpMTNQVV1yhIUOGaOvWrTp69Kg+/PBDPfDAAzp+/Lgk6cEHH9TcuXO1evVqffnll7r//vsvugdNixYtlJSUpLvvvlurV6929PnGG29IkmJiYmSxWLR27Vr973//U2FhoYKDg/XQQw9p4sSJWrZsmY4cOaJPP/1UL774omNC7p///GcdOnRIU6ZM0cGDB7VixQqlpaW59H3btm2rzMxMrVy5UkeOHNGCBQvOOxHaz89PSUlJ+vzzz7V161Y98MADGj58uCIjIyVJM2fO1Jw5c7RgwQJ99dVX2rt3r5YuXarnnnvOpXgA1BwSG6ABCggI0JYtW9S8eXMNGzZMHTt21JgxY1RUVOSo4EyePFl33nmnkpKSFBcXp+DgYN1+++0X7XfhwoX63e9+p/vvv18dOnTQvffeqzNnzkiSrrzySs2cOVOPPvqoIiIiNG7cOEnSrFmzNG3aNM2ZM0cdO3bUwIED9e6776ply5aSyue9rFq1SqtXr9bVV1+tRYsWafbs2S5939/+9reaOHGixo0bp65du2r79u2aNm1apXZt2rTRsGHDdOutt2rAgAHq0qWL03Lue+65R4sXL9bSpUvVuXNn9e7dW2lpaY5YAdQ9i3GhmYAAAAD1DBUbAABgGiQ2AADANEhsAACAaZDYAAAA0yCxAQAApkFiAwAATIPEBgAAmAaJDQAAMA0SGwAAYBokNgAAwDRIbAAAgGn8f3RnqkUNdY0RAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall da validação (%):  76.40845070422534\n",
            "Acurácia da validação (%):  48.84547069271758\n",
            "SCORE do modelo (%):  88.8695942268186\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall da validação (%):  70.07042253521126\n",
            "Acurácia da validação (%):  52.989934872705746\n",
            "SCORE do modelo (%):  88.1000122908363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diferentemente do método de balanceamento anterior, foram obtidas baixas acuracidades para o modelo Near Miss, apesar dos valores de Recall e Score das validações cruzadas serem satisfatório. Tal fato pode ser justificado pela significativa redução do volume de dados após esse tipo de balanceamento, o qual não acarretou em uma aprendizagem de máquina eficiente."
      ],
      "metadata": {
        "id": "8C0t1xCmtNvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUAL O MELHOR BALANCEAMENTO?**"
      ],
      "metadata": {
        "id": "3pXHkCIWFbxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tendo em vista os fatos mencionados, é evidente que o método de balanceamento SMOTE com 8 neurônios na camada intermediária e threshold de 0.4 foi o mais bem avaliado nesse estudo."
      ],
      "metadata": {
        "id": "MDibk2vPFg7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CURVA DE APRENDIZAGEM**"
      ],
      "metadata": {
        "id": "hPeRPk_DpPjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A avaliação das curvas de aprendizagem é de fundamental importância para se identificar a relação entre a quantidade de dados de treino e a eficiência do aprendizado de máquina, sendo crucial no universo da análise de dados. Primeiramente, insere-se o modelo de aprendizado de máquina a ser utilizado:"
      ],
      "metadata": {
        "id": "a2mhU5aFe8fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classif = MLPClassifier(hidden_layer_sizes=(8,), max_iter=10000, activation='relu', random_state=42,\n",
        "                        solver = 'adam', alpha=0.001, learning_rate='adaptive', batch_size = 64, verbose=2)"
      ],
      "metadata": {
        "id": "DjJ3G9F1pS3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_model_curve = cross_val_score(classif, x_best, y, cv=5, scoring='accuracy')\n",
        "score_model_curve = st.mean(score_model_curve)"
      ],
      "metadata": {
        "id": "wuEBCPgeEaN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3bcbe4-02e6-477e-c175-1fd665868a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 6.05234018\n",
            "Iteration 2, loss = 5.01659537\n",
            "Iteration 3, loss = 2.81270492\n",
            "Iteration 4, loss = 0.94022117\n",
            "Iteration 5, loss = 0.38920708\n",
            "Iteration 6, loss = 0.38506521\n",
            "Iteration 7, loss = 0.38329978\n",
            "Iteration 8, loss = 0.37901140\n",
            "Iteration 9, loss = 0.37741450\n",
            "Iteration 10, loss = 0.37404240\n",
            "Iteration 11, loss = 0.37198964\n",
            "Iteration 12, loss = 0.37010335\n",
            "Iteration 13, loss = 0.36779305\n",
            "Iteration 14, loss = 0.36575673\n",
            "Iteration 15, loss = 0.36443293\n",
            "Iteration 16, loss = 0.36219054\n",
            "Iteration 17, loss = 0.36124132\n",
            "Iteration 18, loss = 0.35978568\n",
            "Iteration 19, loss = 0.35839628\n",
            "Iteration 20, loss = 0.35795764\n",
            "Iteration 21, loss = 0.35727381\n",
            "Iteration 22, loss = 0.35542774\n",
            "Iteration 23, loss = 0.35444334\n",
            "Iteration 24, loss = 0.35344395\n",
            "Iteration 25, loss = 0.35269451\n",
            "Iteration 26, loss = 0.35209823\n",
            "Iteration 27, loss = 0.35067481\n",
            "Iteration 28, loss = 0.35038386\n",
            "Iteration 29, loss = 0.35040552\n",
            "Iteration 30, loss = 0.34847091\n",
            "Iteration 31, loss = 0.34942218\n",
            "Iteration 32, loss = 0.34767874\n",
            "Iteration 33, loss = 0.34767575\n",
            "Iteration 34, loss = 0.34767682\n",
            "Iteration 35, loss = 0.34542991\n",
            "Iteration 36, loss = 0.34568039\n",
            "Iteration 37, loss = 0.34375710\n",
            "Iteration 38, loss = 0.34605391\n",
            "Iteration 39, loss = 0.34321402\n",
            "Iteration 40, loss = 0.34252366\n",
            "Iteration 41, loss = 0.34200399\n",
            "Iteration 42, loss = 0.34231534\n",
            "Iteration 43, loss = 0.34151849\n",
            "Iteration 44, loss = 0.34080320\n",
            "Iteration 45, loss = 0.34213623\n",
            "Iteration 46, loss = 0.34068424\n",
            "Iteration 47, loss = 0.33925241\n",
            "Iteration 48, loss = 0.33995949\n",
            "Iteration 49, loss = 0.33870915\n",
            "Iteration 50, loss = 0.33944339\n",
            "Iteration 51, loss = 0.33760622\n",
            "Iteration 52, loss = 0.33742154\n",
            "Iteration 53, loss = 0.33730825\n",
            "Iteration 54, loss = 0.33907722\n",
            "Iteration 55, loss = 0.33617772\n",
            "Iteration 56, loss = 0.33840523\n",
            "Iteration 57, loss = 0.33638549\n",
            "Iteration 58, loss = 0.33583526\n",
            "Iteration 59, loss = 0.33584648\n",
            "Iteration 60, loss = 0.33505924\n",
            "Iteration 61, loss = 0.33505880\n",
            "Iteration 62, loss = 0.33426422\n",
            "Iteration 63, loss = 0.33605592\n",
            "Iteration 64, loss = 0.33656484\n",
            "Iteration 65, loss = 0.33481691\n",
            "Iteration 66, loss = 0.33541137\n",
            "Iteration 67, loss = 0.33391549\n",
            "Iteration 68, loss = 0.33412849\n",
            "Iteration 69, loss = 0.33697269\n",
            "Iteration 70, loss = 0.33448992\n",
            "Iteration 71, loss = 0.33440179\n",
            "Iteration 72, loss = 0.33521156\n",
            "Iteration 73, loss = 0.33345263\n",
            "Iteration 74, loss = 0.33399608\n",
            "Iteration 75, loss = 0.33208402\n",
            "Iteration 76, loss = 0.33266191\n",
            "Iteration 77, loss = 0.33350659\n",
            "Iteration 78, loss = 0.33222052\n",
            "Iteration 79, loss = 0.33191269\n",
            "Iteration 80, loss = 0.33271887\n",
            "Iteration 81, loss = 0.33456666\n",
            "Iteration 82, loss = 0.33440812\n",
            "Iteration 83, loss = 0.33214561\n",
            "Iteration 84, loss = 0.33201617\n",
            "Iteration 85, loss = 0.33212677\n",
            "Iteration 86, loss = 0.33264614\n",
            "Iteration 87, loss = 0.33246864\n",
            "Iteration 88, loss = 0.33372878\n",
            "Iteration 89, loss = 0.33544757\n",
            "Iteration 90, loss = 0.33526489\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.05628864\n",
            "Iteration 2, loss = 5.05179635\n",
            "Iteration 3, loss = 2.87503639\n",
            "Iteration 4, loss = 0.99222917\n",
            "Iteration 5, loss = 0.38939153\n",
            "Iteration 6, loss = 0.38437705\n",
            "Iteration 7, loss = 0.38153343\n",
            "Iteration 8, loss = 0.37739120\n",
            "Iteration 9, loss = 0.37581227\n",
            "Iteration 10, loss = 0.37233270\n",
            "Iteration 11, loss = 0.36982859\n",
            "Iteration 12, loss = 0.36752397\n",
            "Iteration 13, loss = 0.36695690\n",
            "Iteration 14, loss = 0.36556545\n",
            "Iteration 15, loss = 0.36442633\n",
            "Iteration 16, loss = 0.36166671\n",
            "Iteration 17, loss = 0.36130190\n",
            "Iteration 18, loss = 0.35925477\n",
            "Iteration 19, loss = 0.35783084\n",
            "Iteration 20, loss = 0.35651606\n",
            "Iteration 21, loss = 0.35536405\n",
            "Iteration 22, loss = 0.35463938\n",
            "Iteration 23, loss = 0.35470790\n",
            "Iteration 24, loss = 0.35304269\n",
            "Iteration 25, loss = 0.35284882\n",
            "Iteration 26, loss = 0.35228332\n",
            "Iteration 27, loss = 0.35132824\n",
            "Iteration 28, loss = 0.34987778\n",
            "Iteration 29, loss = 0.34999834\n",
            "Iteration 30, loss = 0.34825556\n",
            "Iteration 31, loss = 0.34856897\n",
            "Iteration 32, loss = 0.34692902\n",
            "Iteration 33, loss = 0.34627606\n",
            "Iteration 34, loss = 0.34568940\n",
            "Iteration 35, loss = 0.34530365\n",
            "Iteration 36, loss = 0.34484368\n",
            "Iteration 37, loss = 0.34360803\n",
            "Iteration 38, loss = 0.34364426\n",
            "Iteration 39, loss = 0.34322937\n",
            "Iteration 40, loss = 0.34274486\n",
            "Iteration 41, loss = 0.34235023\n",
            "Iteration 42, loss = 0.34292511\n",
            "Iteration 43, loss = 0.34160054\n",
            "Iteration 44, loss = 0.34101955\n",
            "Iteration 45, loss = 0.34219848\n",
            "Iteration 46, loss = 0.34150990\n",
            "Iteration 47, loss = 0.33884417\n",
            "Iteration 48, loss = 0.33881709\n",
            "Iteration 49, loss = 0.33879041\n",
            "Iteration 50, loss = 0.33867340\n",
            "Iteration 51, loss = 0.33740787\n",
            "Iteration 52, loss = 0.33722022\n",
            "Iteration 53, loss = 0.33736750\n",
            "Iteration 54, loss = 0.33785843\n",
            "Iteration 55, loss = 0.33658164\n",
            "Iteration 56, loss = 0.33810545\n",
            "Iteration 57, loss = 0.33616583\n",
            "Iteration 58, loss = 0.33728226\n",
            "Iteration 59, loss = 0.33569132\n",
            "Iteration 60, loss = 0.33489336\n",
            "Iteration 61, loss = 0.33532362\n",
            "Iteration 62, loss = 0.33562514\n",
            "Iteration 63, loss = 0.33496857\n",
            "Iteration 64, loss = 0.33624647\n",
            "Iteration 65, loss = 0.33464686\n",
            "Iteration 66, loss = 0.33405612\n",
            "Iteration 67, loss = 0.33491460\n",
            "Iteration 68, loss = 0.33432629\n",
            "Iteration 69, loss = 0.33878407\n",
            "Iteration 70, loss = 0.33448128\n",
            "Iteration 71, loss = 0.33450597\n",
            "Iteration 72, loss = 0.33677129\n",
            "Iteration 73, loss = 0.33369822\n",
            "Iteration 74, loss = 0.33326939\n",
            "Iteration 75, loss = 0.33391033\n",
            "Iteration 76, loss = 0.33217630\n",
            "Iteration 77, loss = 0.33473721\n",
            "Iteration 78, loss = 0.33348442\n",
            "Iteration 79, loss = 0.33119753\n",
            "Iteration 80, loss = 0.33393315\n",
            "Iteration 81, loss = 0.33328121\n",
            "Iteration 82, loss = 0.33332642\n",
            "Iteration 83, loss = 0.33183012\n",
            "Iteration 84, loss = 0.33226124\n",
            "Iteration 85, loss = 0.33327354\n",
            "Iteration 86, loss = 0.33265477\n",
            "Iteration 87, loss = 0.33282399\n",
            "Iteration 88, loss = 0.33377636\n",
            "Iteration 89, loss = 0.33626191\n",
            "Iteration 90, loss = 0.33439656\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.03385495\n",
            "Iteration 2, loss = 4.88517956\n",
            "Iteration 3, loss = 2.71457061\n",
            "Iteration 4, loss = 0.90772909\n",
            "Iteration 5, loss = 0.39328847\n",
            "Iteration 6, loss = 0.38859862\n",
            "Iteration 7, loss = 0.38600221\n",
            "Iteration 8, loss = 0.38240531\n",
            "Iteration 9, loss = 0.37981255\n",
            "Iteration 10, loss = 0.37733168\n",
            "Iteration 11, loss = 0.37572943\n",
            "Iteration 12, loss = 0.37167483\n",
            "Iteration 13, loss = 0.37093950\n",
            "Iteration 14, loss = 0.36962815\n",
            "Iteration 15, loss = 0.36842997\n",
            "Iteration 16, loss = 0.36579676\n",
            "Iteration 17, loss = 0.36438199\n",
            "Iteration 18, loss = 0.36269165\n",
            "Iteration 19, loss = 0.36192821\n",
            "Iteration 20, loss = 0.36017573\n",
            "Iteration 21, loss = 0.35914286\n",
            "Iteration 22, loss = 0.35796911\n",
            "Iteration 23, loss = 0.35916634\n",
            "Iteration 24, loss = 0.35653639\n",
            "Iteration 25, loss = 0.35695681\n",
            "Iteration 26, loss = 0.35599052\n",
            "Iteration 27, loss = 0.35472841\n",
            "Iteration 28, loss = 0.35342290\n",
            "Iteration 29, loss = 0.35318673\n",
            "Iteration 30, loss = 0.35113416\n",
            "Iteration 31, loss = 0.35090017\n",
            "Iteration 32, loss = 0.34978008\n",
            "Iteration 33, loss = 0.34950776\n",
            "Iteration 34, loss = 0.34888563\n",
            "Iteration 35, loss = 0.34815321\n",
            "Iteration 36, loss = 0.34756999\n",
            "Iteration 37, loss = 0.34680504\n",
            "Iteration 38, loss = 0.34685693\n",
            "Iteration 39, loss = 0.34572877\n",
            "Iteration 40, loss = 0.34541316\n",
            "Iteration 41, loss = 0.34498337\n",
            "Iteration 42, loss = 0.34513101\n",
            "Iteration 43, loss = 0.34403438\n",
            "Iteration 44, loss = 0.34329751\n",
            "Iteration 45, loss = 0.34241174\n",
            "Iteration 46, loss = 0.34318751\n",
            "Iteration 47, loss = 0.34261685\n",
            "Iteration 48, loss = 0.34169966\n",
            "Iteration 49, loss = 0.34170582\n",
            "Iteration 50, loss = 0.34040603\n",
            "Iteration 51, loss = 0.34087149\n",
            "Iteration 52, loss = 0.33980860\n",
            "Iteration 53, loss = 0.33992592\n",
            "Iteration 54, loss = 0.33886654\n",
            "Iteration 55, loss = 0.33863836\n",
            "Iteration 56, loss = 0.33842268\n",
            "Iteration 57, loss = 0.33939203\n",
            "Iteration 58, loss = 0.33774476\n",
            "Iteration 59, loss = 0.33805381\n",
            "Iteration 60, loss = 0.33741545\n",
            "Iteration 61, loss = 0.33937427\n",
            "Iteration 62, loss = 0.33757783\n",
            "Iteration 63, loss = 0.33640721\n",
            "Iteration 64, loss = 0.34063123\n",
            "Iteration 65, loss = 0.33858521\n",
            "Iteration 66, loss = 0.33684139\n",
            "Iteration 67, loss = 0.33785138\n",
            "Iteration 68, loss = 0.33540139\n",
            "Iteration 69, loss = 0.33826329\n",
            "Iteration 70, loss = 0.33494468\n",
            "Iteration 71, loss = 0.33720295\n",
            "Iteration 72, loss = 0.33657028\n",
            "Iteration 73, loss = 0.33541707\n",
            "Iteration 74, loss = 0.33584723\n",
            "Iteration 75, loss = 0.33604640\n",
            "Iteration 76, loss = 0.33430628\n",
            "Iteration 77, loss = 0.33445733\n",
            "Iteration 78, loss = 0.33340693\n",
            "Iteration 79, loss = 0.33323622\n",
            "Iteration 80, loss = 0.33596986\n",
            "Iteration 81, loss = 0.33462704\n",
            "Iteration 82, loss = 0.33373294\n",
            "Iteration 83, loss = 0.33315860\n",
            "Iteration 84, loss = 0.33386687\n",
            "Iteration 85, loss = 0.33408830\n",
            "Iteration 86, loss = 0.33464478\n",
            "Iteration 87, loss = 0.33379489\n",
            "Iteration 88, loss = 0.33672206\n",
            "Iteration 89, loss = 0.33439467\n",
            "Iteration 90, loss = 0.33621430\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.04445453\n",
            "Iteration 2, loss = 4.89666399\n",
            "Iteration 3, loss = 2.74816358\n",
            "Iteration 4, loss = 0.95681695\n",
            "Iteration 5, loss = 0.39610325\n",
            "Iteration 6, loss = 0.39173452\n",
            "Iteration 7, loss = 0.38904226\n",
            "Iteration 8, loss = 0.38567200\n",
            "Iteration 9, loss = 0.38251966\n",
            "Iteration 10, loss = 0.38023171\n",
            "Iteration 11, loss = 0.37945095\n",
            "Iteration 12, loss = 0.37523882\n",
            "Iteration 13, loss = 0.37444264\n",
            "Iteration 14, loss = 0.37212973\n",
            "Iteration 15, loss = 0.37101468\n",
            "Iteration 16, loss = 0.36953728\n",
            "Iteration 17, loss = 0.36774239\n",
            "Iteration 18, loss = 0.36582929\n",
            "Iteration 19, loss = 0.36476778\n",
            "Iteration 20, loss = 0.36365070\n",
            "Iteration 21, loss = 0.36256549\n",
            "Iteration 22, loss = 0.36221163\n",
            "Iteration 23, loss = 0.36172509\n",
            "Iteration 24, loss = 0.36075388\n",
            "Iteration 25, loss = 0.36074994\n",
            "Iteration 26, loss = 0.35780038\n",
            "Iteration 27, loss = 0.35985644\n",
            "Iteration 28, loss = 0.35651100\n",
            "Iteration 29, loss = 0.35653883\n",
            "Iteration 30, loss = 0.35417944\n",
            "Iteration 31, loss = 0.35334569\n",
            "Iteration 32, loss = 0.35408145\n",
            "Iteration 33, loss = 0.35331408\n",
            "Iteration 34, loss = 0.35243700\n",
            "Iteration 35, loss = 0.35136551\n",
            "Iteration 36, loss = 0.35097126\n",
            "Iteration 37, loss = 0.35074472\n",
            "Iteration 38, loss = 0.34882001\n",
            "Iteration 39, loss = 0.34869033\n",
            "Iteration 40, loss = 0.34882840\n",
            "Iteration 41, loss = 0.34785881\n",
            "Iteration 42, loss = 0.34837813\n",
            "Iteration 43, loss = 0.34882649\n",
            "Iteration 44, loss = 0.34741783\n",
            "Iteration 45, loss = 0.34645743\n",
            "Iteration 46, loss = 0.34632948\n",
            "Iteration 47, loss = 0.34588632\n",
            "Iteration 48, loss = 0.34647223\n",
            "Iteration 49, loss = 0.34623906\n",
            "Iteration 50, loss = 0.34418147\n",
            "Iteration 51, loss = 0.34410984\n",
            "Iteration 52, loss = 0.34586288\n",
            "Iteration 53, loss = 0.34329601\n",
            "Iteration 54, loss = 0.34345482\n",
            "Iteration 55, loss = 0.34398453\n",
            "Iteration 56, loss = 0.34242913\n",
            "Iteration 57, loss = 0.34412890\n",
            "Iteration 58, loss = 0.34123196\n",
            "Iteration 59, loss = 0.34179709\n",
            "Iteration 60, loss = 0.34092095\n",
            "Iteration 61, loss = 0.34205086\n",
            "Iteration 62, loss = 0.34106654\n",
            "Iteration 63, loss = 0.33986839\n",
            "Iteration 64, loss = 0.34309583\n",
            "Iteration 65, loss = 0.34163345\n",
            "Iteration 66, loss = 0.34010713\n",
            "Iteration 67, loss = 0.33962151\n",
            "Iteration 68, loss = 0.33984315\n",
            "Iteration 69, loss = 0.34210092\n",
            "Iteration 70, loss = 0.33897587\n",
            "Iteration 71, loss = 0.34058176\n",
            "Iteration 72, loss = 0.34001709\n",
            "Iteration 73, loss = 0.33867246\n",
            "Iteration 74, loss = 0.34065347\n",
            "Iteration 75, loss = 0.33921098\n",
            "Iteration 76, loss = 0.33910073\n",
            "Iteration 77, loss = 0.33828966\n",
            "Iteration 78, loss = 0.33893151\n",
            "Iteration 79, loss = 0.33739610\n",
            "Iteration 80, loss = 0.33915636\n",
            "Iteration 81, loss = 0.33943249\n",
            "Iteration 82, loss = 0.33857411\n",
            "Iteration 83, loss = 0.33841766\n",
            "Iteration 84, loss = 0.33950395\n",
            "Iteration 85, loss = 0.33746696\n",
            "Iteration 86, loss = 0.33809770\n",
            "Iteration 87, loss = 0.33741633\n",
            "Iteration 88, loss = 0.34089797\n",
            "Iteration 89, loss = 0.33841241\n",
            "Iteration 90, loss = 0.33789620\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.04355142\n",
            "Iteration 2, loss = 4.90464632\n",
            "Iteration 3, loss = 2.74652088\n",
            "Iteration 4, loss = 0.96377370\n",
            "Iteration 5, loss = 0.39352300\n",
            "Iteration 6, loss = 0.39012973\n",
            "Iteration 7, loss = 0.38793364\n",
            "Iteration 8, loss = 0.38375766\n",
            "Iteration 9, loss = 0.38124784\n",
            "Iteration 10, loss = 0.37836156\n",
            "Iteration 11, loss = 0.37729542\n",
            "Iteration 12, loss = 0.37456870\n",
            "Iteration 13, loss = 0.37218707\n",
            "Iteration 14, loss = 0.37203590\n",
            "Iteration 15, loss = 0.36954731\n",
            "Iteration 16, loss = 0.36766557\n",
            "Iteration 17, loss = 0.36612837\n",
            "Iteration 18, loss = 0.36558249\n",
            "Iteration 19, loss = 0.36456528\n",
            "Iteration 20, loss = 0.36267341\n",
            "Iteration 21, loss = 0.36159405\n",
            "Iteration 22, loss = 0.36155553\n",
            "Iteration 23, loss = 0.36069075\n",
            "Iteration 24, loss = 0.35845692\n",
            "Iteration 25, loss = 0.35892063\n",
            "Iteration 26, loss = 0.35635956\n",
            "Iteration 27, loss = 0.35709529\n",
            "Iteration 28, loss = 0.35605717\n",
            "Iteration 29, loss = 0.35414802\n",
            "Iteration 30, loss = 0.35317317\n",
            "Iteration 31, loss = 0.35282778\n",
            "Iteration 32, loss = 0.35295379\n",
            "Iteration 33, loss = 0.35172202\n",
            "Iteration 34, loss = 0.35113215\n",
            "Iteration 35, loss = 0.35040518\n",
            "Iteration 36, loss = 0.34949601\n",
            "Iteration 37, loss = 0.34921177\n",
            "Iteration 38, loss = 0.34875039\n",
            "Iteration 39, loss = 0.34843054\n",
            "Iteration 40, loss = 0.34924941\n",
            "Iteration 41, loss = 0.34747671\n",
            "Iteration 42, loss = 0.34606153\n",
            "Iteration 43, loss = 0.34813148\n",
            "Iteration 44, loss = 0.34624871\n",
            "Iteration 45, loss = 0.34560293\n",
            "Iteration 46, loss = 0.34436138\n",
            "Iteration 47, loss = 0.34426644\n",
            "Iteration 48, loss = 0.34461584\n",
            "Iteration 49, loss = 0.34388327\n",
            "Iteration 50, loss = 0.34288024\n",
            "Iteration 51, loss = 0.34250636\n",
            "Iteration 52, loss = 0.34439876\n",
            "Iteration 53, loss = 0.34332569\n",
            "Iteration 54, loss = 0.34288484\n",
            "Iteration 55, loss = 0.34264705\n",
            "Iteration 56, loss = 0.34044288\n",
            "Iteration 57, loss = 0.34071976\n",
            "Iteration 58, loss = 0.34007702\n",
            "Iteration 59, loss = 0.34023116\n",
            "Iteration 60, loss = 0.34189066\n",
            "Iteration 61, loss = 0.34027868\n",
            "Iteration 62, loss = 0.33952024\n",
            "Iteration 63, loss = 0.33931526\n",
            "Iteration 64, loss = 0.34117482\n",
            "Iteration 65, loss = 0.33957770\n",
            "Iteration 66, loss = 0.33825485\n",
            "Iteration 67, loss = 0.34036385\n",
            "Iteration 68, loss = 0.33944718\n",
            "Iteration 69, loss = 0.34074991\n",
            "Iteration 70, loss = 0.33792060\n",
            "Iteration 71, loss = 0.33789385\n",
            "Iteration 72, loss = 0.33846354\n",
            "Iteration 73, loss = 0.33848770\n",
            "Iteration 74, loss = 0.34137216\n",
            "Iteration 75, loss = 0.33917058\n",
            "Iteration 76, loss = 0.33785921\n",
            "Iteration 77, loss = 0.33830820\n",
            "Iteration 78, loss = 0.33716541\n",
            "Iteration 79, loss = 0.33650829\n",
            "Iteration 80, loss = 0.33676605\n",
            "Iteration 81, loss = 0.33785714\n",
            "Iteration 82, loss = 0.33760806\n",
            "Iteration 83, loss = 0.33900161\n",
            "Iteration 84, loss = 0.33839996\n",
            "Iteration 85, loss = 0.33710256\n",
            "Iteration 86, loss = 0.33667798\n",
            "Iteration 87, loss = 0.33642059\n",
            "Iteration 88, loss = 0.33801168\n",
            "Iteration 89, loss = 0.33626603\n",
            "Iteration 90, loss = 0.33790944\n",
            "Iteration 91, loss = 0.33916316\n",
            "Iteration 92, loss = 0.33612980\n",
            "Iteration 93, loss = 0.33602117\n",
            "Iteration 94, loss = 0.33630214\n",
            "Iteration 95, loss = 0.33707596\n",
            "Iteration 96, loss = 0.33654885\n",
            "Iteration 97, loss = 0.33549457\n",
            "Iteration 98, loss = 0.33584175\n",
            "Iteration 99, loss = 0.33621958\n",
            "Iteration 100, loss = 0.33627367\n",
            "Iteration 101, loss = 0.33747053\n",
            "Iteration 102, loss = 0.33756847\n",
            "Iteration 103, loss = 0.33644108\n",
            "Iteration 104, loss = 0.33549607\n",
            "Iteration 105, loss = 0.33545579\n",
            "Iteration 106, loss = 0.33772824\n",
            "Iteration 107, loss = 0.33710562\n",
            "Iteration 108, loss = 0.33817560\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SCORE do modelo da curva de aprendizado (%): \", (score_model_curve*100))"
      ],
      "metadata": {
        "id": "BFQ50_YCFuRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f678daaa-d43c-41fe-e25f-2aef5a33402c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCORE do modelo da curva de aprendizado (%):  86.53641207815275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se um score satisfatório para a validação cruzada do modelo."
      ],
      "metadata": {
        "id": "ntFBW833JACl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, a curva de aprendizado é implementada da seguinte forma:"
      ],
      "metadata": {
        "id": "cL1XvZMaf8Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sizes_abs, train_scores, test_scores = learning_curve(classif, x_best, y, train_sizes=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.97, 0.99],\n",
        "                                                            scoring = 'accuracy', cv=5)"
      ],
      "metadata": {
        "id": "JyjmAmDJpbve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f262407-9997-4c66-eb8a-4661f8382c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "Iteration 52, loss = 0.35129220\n",
            "Iteration 53, loss = 0.35283993\n",
            "Iteration 54, loss = 0.35211881\n",
            "Iteration 55, loss = 0.35075031\n",
            "Iteration 56, loss = 0.35234167\n",
            "Iteration 57, loss = 0.34904733\n",
            "Iteration 58, loss = 0.34910829\n",
            "Iteration 59, loss = 0.35012694\n",
            "Iteration 60, loss = 0.34932103\n",
            "Iteration 61, loss = 0.34832987\n",
            "Iteration 62, loss = 0.34855398\n",
            "Iteration 63, loss = 0.34750777\n",
            "Iteration 64, loss = 0.34743419\n",
            "Iteration 65, loss = 0.34741799\n",
            "Iteration 66, loss = 0.34585355\n",
            "Iteration 67, loss = 0.34526662\n",
            "Iteration 68, loss = 0.34612185\n",
            "Iteration 69, loss = 0.34730542\n",
            "Iteration 70, loss = 0.34618149\n",
            "Iteration 71, loss = 0.34519630\n",
            "Iteration 72, loss = 0.34478095\n",
            "Iteration 73, loss = 0.34367272\n",
            "Iteration 74, loss = 0.34376383\n",
            "Iteration 75, loss = 0.34351856\n",
            "Iteration 76, loss = 0.34346536\n",
            "Iteration 77, loss = 0.34423366\n",
            "Iteration 78, loss = 0.34157912\n",
            "Iteration 79, loss = 0.34314859\n",
            "Iteration 80, loss = 0.34338568\n",
            "Iteration 81, loss = 0.34183406\n",
            "Iteration 82, loss = 0.34302703\n",
            "Iteration 83, loss = 0.34412987\n",
            "Iteration 84, loss = 0.34321524\n",
            "Iteration 85, loss = 0.34148265\n",
            "Iteration 86, loss = 0.34096587\n",
            "Iteration 87, loss = 0.34237877\n",
            "Iteration 88, loss = 0.34052758\n",
            "Iteration 89, loss = 0.34081497\n",
            "Iteration 90, loss = 0.34139459\n",
            "Iteration 91, loss = 0.34057349\n",
            "Iteration 92, loss = 0.34091368\n",
            "Iteration 93, loss = 0.34079406\n",
            "Iteration 94, loss = 0.34056824\n",
            "Iteration 95, loss = 0.34017752\n",
            "Iteration 96, loss = 0.33986660\n",
            "Iteration 97, loss = 0.33941492\n",
            "Iteration 98, loss = 0.34115697\n",
            "Iteration 99, loss = 0.33990672\n",
            "Iteration 100, loss = 0.34129139\n",
            "Iteration 101, loss = 0.34105262\n",
            "Iteration 102, loss = 0.34052757\n",
            "Iteration 103, loss = 0.34038802\n",
            "Iteration 104, loss = 0.33986494\n",
            "Iteration 105, loss = 0.34209736\n",
            "Iteration 106, loss = 0.34088732\n",
            "Iteration 107, loss = 0.34138641\n",
            "Iteration 108, loss = 0.33831275\n",
            "Iteration 109, loss = 0.33870795\n",
            "Iteration 110, loss = 0.33936199\n",
            "Iteration 111, loss = 0.34163468\n",
            "Iteration 112, loss = 0.33934234\n",
            "Iteration 113, loss = 0.33980915\n",
            "Iteration 114, loss = 0.33996304\n",
            "Iteration 115, loss = 0.33863654\n",
            "Iteration 116, loss = 0.33796493\n",
            "Iteration 117, loss = 0.33795685\n",
            "Iteration 118, loss = 0.33906546\n",
            "Iteration 119, loss = 0.33819801\n",
            "Iteration 120, loss = 0.34005701\n",
            "Iteration 121, loss = 0.33824500\n",
            "Iteration 122, loss = 0.34052295\n",
            "Iteration 123, loss = 0.33987536\n",
            "Iteration 124, loss = 0.33917560\n",
            "Iteration 125, loss = 0.33945175\n",
            "Iteration 126, loss = 0.34198124\n",
            "Iteration 127, loss = 0.33888030\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.09159096\n",
            "Iteration 2, loss = 5.65597015\n",
            "Iteration 3, loss = 4.00424709\n",
            "Iteration 4, loss = 2.28100802\n",
            "Iteration 5, loss = 0.86341306\n",
            "Iteration 6, loss = 0.38963822\n",
            "Iteration 7, loss = 0.38598214\n",
            "Iteration 8, loss = 0.38393900\n",
            "Iteration 9, loss = 0.38032628\n",
            "Iteration 10, loss = 0.36914741\n",
            "Iteration 11, loss = 0.36599802\n",
            "Iteration 12, loss = 0.36257931\n",
            "Iteration 13, loss = 0.36158967\n",
            "Iteration 14, loss = 0.35819114\n",
            "Iteration 15, loss = 0.35775247\n",
            "Iteration 16, loss = 0.35568407\n",
            "Iteration 17, loss = 0.35465666\n",
            "Iteration 18, loss = 0.35314463\n",
            "Iteration 19, loss = 0.35194294\n",
            "Iteration 20, loss = 0.35072765\n",
            "Iteration 21, loss = 0.34896472\n",
            "Iteration 22, loss = 0.34928265\n",
            "Iteration 23, loss = 0.34843253\n",
            "Iteration 24, loss = 0.34724610\n",
            "Iteration 25, loss = 0.34615731\n",
            "Iteration 26, loss = 0.34606084\n",
            "Iteration 27, loss = 0.34404370\n",
            "Iteration 28, loss = 0.34266401\n",
            "Iteration 29, loss = 0.34122618\n",
            "Iteration 30, loss = 0.34367684\n",
            "Iteration 31, loss = 0.34270100\n",
            "Iteration 32, loss = 0.34155607\n",
            "Iteration 33, loss = 0.34014496\n",
            "Iteration 34, loss = 0.34244286\n",
            "Iteration 35, loss = 0.34389577\n",
            "Iteration 36, loss = 0.34100132\n",
            "Iteration 37, loss = 0.33901827\n",
            "Iteration 38, loss = 0.33822333\n",
            "Iteration 39, loss = 0.33895114\n",
            "Iteration 40, loss = 0.33879603\n",
            "Iteration 41, loss = 0.33827068\n",
            "Iteration 42, loss = 0.33547352\n",
            "Iteration 43, loss = 0.33530087\n",
            "Iteration 44, loss = 0.33770966\n",
            "Iteration 45, loss = 0.33441589\n",
            "Iteration 46, loss = 0.33877981\n",
            "Iteration 47, loss = 0.33395098\n",
            "Iteration 48, loss = 0.33557743\n",
            "Iteration 49, loss = 0.33347566\n",
            "Iteration 50, loss = 0.33680259\n",
            "Iteration 51, loss = 0.33435129\n",
            "Iteration 52, loss = 0.33500045\n",
            "Iteration 53, loss = 0.33311285\n",
            "Iteration 54, loss = 0.33190905\n",
            "Iteration 55, loss = 0.33406443\n",
            "Iteration 56, loss = 0.33379965\n",
            "Iteration 57, loss = 0.33178506\n",
            "Iteration 58, loss = 0.33648995\n",
            "Iteration 59, loss = 0.33164542\n",
            "Iteration 60, loss = 0.33243958\n",
            "Iteration 61, loss = 0.33482276\n",
            "Iteration 62, loss = 0.33411128\n",
            "Iteration 63, loss = 0.33545668\n",
            "Iteration 64, loss = 0.33317507\n",
            "Iteration 65, loss = 0.33259324\n",
            "Iteration 66, loss = 0.33257100\n",
            "Iteration 67, loss = 0.33191327\n",
            "Iteration 68, loss = 0.33438352\n",
            "Iteration 69, loss = 0.33600448\n",
            "Iteration 70, loss = 0.33379406\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.15145191\n",
            "Iteration 2, loss = 5.41860201\n",
            "Iteration 3, loss = 3.44369200\n",
            "Iteration 4, loss = 1.58840350\n",
            "Iteration 5, loss = 0.45511452\n",
            "Iteration 6, loss = 0.39105891\n",
            "Iteration 7, loss = 0.38805042\n",
            "Iteration 8, loss = 0.38506688\n",
            "Iteration 9, loss = 0.38153898\n",
            "Iteration 10, loss = 0.37413844\n",
            "Iteration 11, loss = 0.36728259\n",
            "Iteration 12, loss = 0.36500608\n",
            "Iteration 13, loss = 0.36452862\n",
            "Iteration 14, loss = 0.36071620\n",
            "Iteration 15, loss = 0.35978891\n",
            "Iteration 16, loss = 0.35868497\n",
            "Iteration 17, loss = 0.35704678\n",
            "Iteration 18, loss = 0.35378841\n",
            "Iteration 19, loss = 0.35715224\n",
            "Iteration 20, loss = 0.35312188\n",
            "Iteration 21, loss = 0.35152768\n",
            "Iteration 22, loss = 0.35216693\n",
            "Iteration 23, loss = 0.34941792\n",
            "Iteration 24, loss = 0.34876948\n",
            "Iteration 25, loss = 0.34916535\n",
            "Iteration 26, loss = 0.34760873\n",
            "Iteration 27, loss = 0.34688423\n",
            "Iteration 28, loss = 0.34484218\n",
            "Iteration 29, loss = 0.34495102\n",
            "Iteration 30, loss = 0.34437342\n",
            "Iteration 31, loss = 0.34383680\n",
            "Iteration 32, loss = 0.34380967\n",
            "Iteration 33, loss = 0.34296684\n",
            "Iteration 34, loss = 0.34203013\n",
            "Iteration 35, loss = 0.34348784\n",
            "Iteration 36, loss = 0.34145470\n",
            "Iteration 37, loss = 0.33969209\n",
            "Iteration 38, loss = 0.33989261\n",
            "Iteration 39, loss = 0.33888692\n",
            "Iteration 40, loss = 0.33838176\n",
            "Iteration 41, loss = 0.33778534\n",
            "Iteration 42, loss = 0.34039585\n",
            "Iteration 43, loss = 0.33685715\n",
            "Iteration 44, loss = 0.33767819\n",
            "Iteration 45, loss = 0.33777601\n",
            "Iteration 46, loss = 0.34280978\n",
            "Iteration 47, loss = 0.33676335\n",
            "Iteration 48, loss = 0.33795757\n",
            "Iteration 49, loss = 0.33585939\n",
            "Iteration 50, loss = 0.33629060\n",
            "Iteration 51, loss = 0.33728494\n",
            "Iteration 52, loss = 0.33660033\n",
            "Iteration 53, loss = 0.33699287\n",
            "Iteration 54, loss = 0.33562549\n",
            "Iteration 55, loss = 0.33541196\n",
            "Iteration 56, loss = 0.33469035\n",
            "Iteration 57, loss = 0.33540500\n",
            "Iteration 58, loss = 0.33674217\n",
            "Iteration 59, loss = 0.33574522\n",
            "Iteration 60, loss = 0.33876282\n",
            "Iteration 61, loss = 0.33567503\n",
            "Iteration 62, loss = 0.33462478\n",
            "Iteration 63, loss = 0.33418618\n",
            "Iteration 64, loss = 0.33521381\n",
            "Iteration 65, loss = 0.33627300\n",
            "Iteration 66, loss = 0.33495415\n",
            "Iteration 67, loss = 0.33467977\n",
            "Iteration 68, loss = 0.33495317\n",
            "Iteration 69, loss = 0.33686041\n",
            "Iteration 70, loss = 0.33779549\n",
            "Iteration 71, loss = 0.33541507\n",
            "Iteration 72, loss = 0.33374493\n",
            "Iteration 73, loss = 0.33636905\n",
            "Iteration 74, loss = 0.33571379\n",
            "Iteration 75, loss = 0.33430292\n",
            "Iteration 76, loss = 0.33502612\n",
            "Iteration 77, loss = 0.33487862\n",
            "Iteration 78, loss = 0.33765316\n",
            "Iteration 79, loss = 0.33442365\n",
            "Iteration 80, loss = 0.33424703\n",
            "Iteration 81, loss = 0.33630998\n",
            "Iteration 82, loss = 0.33376011\n",
            "Iteration 83, loss = 0.33855615\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.08784577\n",
            "Iteration 2, loss = 5.17158667\n",
            "Iteration 3, loss = 3.08623053\n",
            "Iteration 4, loss = 1.22891045\n",
            "Iteration 5, loss = 0.39978602\n",
            "Iteration 6, loss = 0.38835602\n",
            "Iteration 7, loss = 0.38539426\n",
            "Iteration 8, loss = 0.38187097\n",
            "Iteration 9, loss = 0.37803100\n",
            "Iteration 10, loss = 0.37605417\n",
            "Iteration 11, loss = 0.37363765\n",
            "Iteration 12, loss = 0.37136806\n",
            "Iteration 13, loss = 0.37034244\n",
            "Iteration 14, loss = 0.36738202\n",
            "Iteration 15, loss = 0.36564043\n",
            "Iteration 16, loss = 0.36390968\n",
            "Iteration 17, loss = 0.36375633\n",
            "Iteration 18, loss = 0.36186383\n",
            "Iteration 19, loss = 0.36041500\n",
            "Iteration 20, loss = 0.36015274\n",
            "Iteration 21, loss = 0.35921289\n",
            "Iteration 22, loss = 0.35762326\n",
            "Iteration 23, loss = 0.35634562\n",
            "Iteration 24, loss = 0.35595355\n",
            "Iteration 25, loss = 0.35586412\n",
            "Iteration 26, loss = 0.35493915\n",
            "Iteration 27, loss = 0.35294261\n",
            "Iteration 28, loss = 0.35347978\n",
            "Iteration 29, loss = 0.35268289\n",
            "Iteration 30, loss = 0.35191778\n",
            "Iteration 31, loss = 0.35219838\n",
            "Iteration 32, loss = 0.35083380\n",
            "Iteration 33, loss = 0.34899729\n",
            "Iteration 34, loss = 0.34907230\n",
            "Iteration 35, loss = 0.34791741\n",
            "Iteration 36, loss = 0.34805438\n",
            "Iteration 37, loss = 0.34822823\n",
            "Iteration 38, loss = 0.34784383\n",
            "Iteration 39, loss = 0.34544542\n",
            "Iteration 40, loss = 0.34582260\n",
            "Iteration 41, loss = 0.34565669\n",
            "Iteration 42, loss = 0.34333588\n",
            "Iteration 43, loss = 0.34527194\n",
            "Iteration 44, loss = 0.34397067\n",
            "Iteration 45, loss = 0.34228877\n",
            "Iteration 46, loss = 0.34402197\n",
            "Iteration 47, loss = 0.34143694\n",
            "Iteration 48, loss = 0.34210174\n",
            "Iteration 49, loss = 0.34175068\n",
            "Iteration 50, loss = 0.34484660\n",
            "Iteration 51, loss = 0.34052929\n",
            "Iteration 52, loss = 0.33865339\n",
            "Iteration 53, loss = 0.34116637\n",
            "Iteration 54, loss = 0.33933581\n",
            "Iteration 55, loss = 0.33972805\n",
            "Iteration 56, loss = 0.33982054\n",
            "Iteration 57, loss = 0.33709546\n",
            "Iteration 58, loss = 0.33776769\n",
            "Iteration 59, loss = 0.33758656\n",
            "Iteration 60, loss = 0.33841318\n",
            "Iteration 61, loss = 0.33739147\n",
            "Iteration 62, loss = 0.33784490\n",
            "Iteration 63, loss = 0.33609236\n",
            "Iteration 64, loss = 0.33667289\n",
            "Iteration 65, loss = 0.33702219\n",
            "Iteration 66, loss = 0.33492139\n",
            "Iteration 67, loss = 0.33828070\n",
            "Iteration 68, loss = 0.33476424\n",
            "Iteration 69, loss = 0.33550068\n",
            "Iteration 70, loss = 0.33458451\n",
            "Iteration 71, loss = 0.33612198\n",
            "Iteration 72, loss = 0.33440939\n",
            "Iteration 73, loss = 0.33684330\n",
            "Iteration 74, loss = 0.33286413\n",
            "Iteration 75, loss = 0.33625186\n",
            "Iteration 76, loss = 0.33522801\n",
            "Iteration 77, loss = 0.33495347\n",
            "Iteration 78, loss = 0.33370682\n",
            "Iteration 79, loss = 0.33341511\n",
            "Iteration 80, loss = 0.33435152\n",
            "Iteration 81, loss = 0.33680857\n",
            "Iteration 82, loss = 0.33305789\n",
            "Iteration 83, loss = 0.33385541\n",
            "Iteration 84, loss = 0.33280156\n",
            "Iteration 85, loss = 0.33288445\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.11310944\n",
            "Iteration 2, loss = 5.17905817\n",
            "Iteration 3, loss = 3.03693503\n",
            "Iteration 4, loss = 1.12313524\n",
            "Iteration 5, loss = 0.39211494\n",
            "Iteration 6, loss = 0.38703399\n",
            "Iteration 7, loss = 0.38377182\n",
            "Iteration 8, loss = 0.37743502\n",
            "Iteration 9, loss = 0.36896268\n",
            "Iteration 10, loss = 0.36432248\n",
            "Iteration 11, loss = 0.36202752\n",
            "Iteration 12, loss = 0.35943770\n",
            "Iteration 13, loss = 0.35694439\n",
            "Iteration 14, loss = 0.35591653\n",
            "Iteration 15, loss = 0.35301317\n",
            "Iteration 16, loss = 0.35227467\n",
            "Iteration 17, loss = 0.35123772\n",
            "Iteration 18, loss = 0.34988929\n",
            "Iteration 19, loss = 0.34871961\n",
            "Iteration 20, loss = 0.34744968\n",
            "Iteration 21, loss = 0.34754214\n",
            "Iteration 22, loss = 0.34608553\n",
            "Iteration 23, loss = 0.34314490\n",
            "Iteration 24, loss = 0.34345289\n",
            "Iteration 25, loss = 0.34649177\n",
            "Iteration 26, loss = 0.34092048\n",
            "Iteration 27, loss = 0.34145087\n",
            "Iteration 28, loss = 0.34222559\n",
            "Iteration 29, loss = 0.34077000\n",
            "Iteration 30, loss = 0.34031658\n",
            "Iteration 31, loss = 0.34304577\n",
            "Iteration 32, loss = 0.33972466\n",
            "Iteration 33, loss = 0.33641474\n",
            "Iteration 34, loss = 0.33797458\n",
            "Iteration 35, loss = 0.33665422\n",
            "Iteration 36, loss = 0.33622538\n",
            "Iteration 37, loss = 0.33519000\n",
            "Iteration 38, loss = 0.33553053\n",
            "Iteration 39, loss = 0.33544183\n",
            "Iteration 40, loss = 0.33545385\n",
            "Iteration 41, loss = 0.33551391\n",
            "Iteration 42, loss = 0.33479979\n",
            "Iteration 43, loss = 0.33563188\n",
            "Iteration 44, loss = 0.33439991\n",
            "Iteration 45, loss = 0.33504761\n",
            "Iteration 46, loss = 0.33524534\n",
            "Iteration 47, loss = 0.33361903\n",
            "Iteration 48, loss = 0.33287243\n",
            "Iteration 49, loss = 0.33458924\n",
            "Iteration 50, loss = 0.33397464\n",
            "Iteration 51, loss = 0.33948574\n",
            "Iteration 52, loss = 0.33295656\n",
            "Iteration 53, loss = 0.33729103\n",
            "Iteration 54, loss = 0.33250635\n",
            "Iteration 55, loss = 0.33375051\n",
            "Iteration 56, loss = 0.33569776\n",
            "Iteration 57, loss = 0.33224917\n",
            "Iteration 58, loss = 0.33265196\n",
            "Iteration 59, loss = 0.33298462\n",
            "Iteration 60, loss = 0.33367220\n",
            "Iteration 61, loss = 0.33152292\n",
            "Iteration 62, loss = 0.33095842\n",
            "Iteration 63, loss = 0.33321008\n",
            "Iteration 64, loss = 0.33330404\n",
            "Iteration 65, loss = 0.33293436\n",
            "Iteration 66, loss = 0.33309699\n",
            "Iteration 67, loss = 0.33418375\n",
            "Iteration 68, loss = 0.33424988\n",
            "Iteration 69, loss = 0.33421411\n",
            "Iteration 70, loss = 0.33214046\n",
            "Iteration 71, loss = 0.33511428\n",
            "Iteration 72, loss = 0.33141129\n",
            "Iteration 73, loss = 0.33522876\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.07653995\n",
            "Iteration 2, loss = 5.10421014\n",
            "Iteration 3, loss = 2.90154673\n",
            "Iteration 4, loss = 1.01340078\n",
            "Iteration 5, loss = 0.38746687\n",
            "Iteration 6, loss = 0.38338544\n",
            "Iteration 7, loss = 0.38031657\n",
            "Iteration 8, loss = 0.37343903\n",
            "Iteration 9, loss = 0.36643722\n",
            "Iteration 10, loss = 0.36275785\n",
            "Iteration 11, loss = 0.36100006\n",
            "Iteration 12, loss = 0.35709384\n",
            "Iteration 13, loss = 0.35645483\n",
            "Iteration 14, loss = 0.35426718\n",
            "Iteration 15, loss = 0.35265076\n",
            "Iteration 16, loss = 0.35081665\n",
            "Iteration 17, loss = 0.34946588\n",
            "Iteration 18, loss = 0.34819870\n",
            "Iteration 19, loss = 0.34657005\n",
            "Iteration 20, loss = 0.34705857\n",
            "Iteration 21, loss = 0.34456550\n",
            "Iteration 22, loss = 0.34406804\n",
            "Iteration 23, loss = 0.34294306\n",
            "Iteration 24, loss = 0.34266340\n",
            "Iteration 25, loss = 0.34141569\n",
            "Iteration 26, loss = 0.34366147\n",
            "Iteration 27, loss = 0.33979192\n",
            "Iteration 28, loss = 0.33886895\n",
            "Iteration 29, loss = 0.33753911\n",
            "Iteration 30, loss = 0.33766933\n",
            "Iteration 31, loss = 0.33923464\n",
            "Iteration 32, loss = 0.33642865\n",
            "Iteration 33, loss = 0.33567096\n",
            "Iteration 34, loss = 0.33793767\n",
            "Iteration 35, loss = 0.33502251\n",
            "Iteration 36, loss = 0.34420883\n",
            "Iteration 37, loss = 0.33406318\n",
            "Iteration 38, loss = 0.33296742\n",
            "Iteration 39, loss = 0.33299339\n",
            "Iteration 40, loss = 0.33321618\n",
            "Iteration 41, loss = 0.33609154\n",
            "Iteration 42, loss = 0.33242875\n",
            "Iteration 43, loss = 0.33306593\n",
            "Iteration 44, loss = 0.33232752\n",
            "Iteration 45, loss = 0.33475815\n",
            "Iteration 46, loss = 0.33276392\n",
            "Iteration 47, loss = 0.33153910\n",
            "Iteration 48, loss = 0.33682634\n",
            "Iteration 49, loss = 0.33487659\n",
            "Iteration 50, loss = 0.33326678\n",
            "Iteration 51, loss = 0.33303633\n",
            "Iteration 52, loss = 0.33125308\n",
            "Iteration 53, loss = 0.33217388\n",
            "Iteration 54, loss = 0.33256784\n",
            "Iteration 55, loss = 0.33188801\n",
            "Iteration 56, loss = 0.33287029\n",
            "Iteration 57, loss = 0.33102640\n",
            "Iteration 58, loss = 0.33506786\n",
            "Iteration 59, loss = 0.33282691\n",
            "Iteration 60, loss = 0.33079942\n",
            "Iteration 61, loss = 0.33204155\n",
            "Iteration 62, loss = 0.33051180\n",
            "Iteration 63, loss = 0.33093560\n",
            "Iteration 64, loss = 0.33240990\n",
            "Iteration 65, loss = 0.33144947\n",
            "Iteration 66, loss = 0.33520700\n",
            "Iteration 67, loss = 0.33189305\n",
            "Iteration 68, loss = 0.33128764\n",
            "Iteration 69, loss = 0.33137964\n",
            "Iteration 70, loss = 0.33286181\n",
            "Iteration 71, loss = 0.33334948\n",
            "Iteration 72, loss = 0.33288076\n",
            "Iteration 73, loss = 0.33232334\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 7.12871227\n",
            "Iteration 2, loss = 7.12871084\n",
            "Iteration 3, loss = 7.12870984\n",
            "Iteration 4, loss = 7.12870887\n",
            "Iteration 5, loss = 7.12870795\n",
            "Iteration 6, loss = 7.12870710\n",
            "Iteration 7, loss = 7.12326389\n",
            "Iteration 8, loss = 7.11366449\n",
            "Iteration 9, loss = 7.08524052\n",
            "Iteration 10, loss = 6.99997215\n",
            "Iteration 11, loss = 6.82840886\n",
            "Iteration 12, loss = 6.63423915\n",
            "Iteration 13, loss = 6.40248963\n",
            "Iteration 14, loss = 6.18902270\n",
            "Iteration 15, loss = 5.95555111\n",
            "Iteration 16, loss = 5.70170004\n",
            "Iteration 17, loss = 5.43992137\n",
            "Iteration 18, loss = 5.20353722\n",
            "Iteration 19, loss = 4.90711011\n",
            "Iteration 20, loss = 4.62354722\n",
            "Iteration 21, loss = 4.36421015\n",
            "Iteration 22, loss = 4.10945002\n",
            "Iteration 23, loss = 3.88284634\n",
            "Iteration 24, loss = 3.67157006\n",
            "Iteration 25, loss = 3.46670020\n",
            "Iteration 26, loss = 3.26515925\n",
            "Iteration 27, loss = 3.06672200\n",
            "Iteration 28, loss = 2.86751272\n",
            "Iteration 29, loss = 2.65983611\n",
            "Iteration 30, loss = 2.43277249\n",
            "Iteration 31, loss = 2.24936322\n",
            "Iteration 32, loss = 2.05645192\n",
            "Iteration 33, loss = 1.87519165\n",
            "Iteration 34, loss = 1.66219379\n",
            "Iteration 35, loss = 1.42937371\n",
            "Iteration 36, loss = 1.21158903\n",
            "Iteration 37, loss = 1.03048222\n",
            "Iteration 38, loss = 0.86800187\n",
            "Iteration 39, loss = 0.72808006\n",
            "Iteration 40, loss = 0.60686738\n",
            "Iteration 41, loss = 0.50085192\n",
            "Iteration 42, loss = 0.43852106\n",
            "Iteration 43, loss = 0.41636091\n",
            "Iteration 44, loss = 0.41370314\n",
            "Iteration 45, loss = 0.41422365\n",
            "Iteration 46, loss = 0.41451525\n",
            "Iteration 47, loss = 0.41305881\n",
            "Iteration 48, loss = 0.41156806\n",
            "Iteration 49, loss = 0.41262791\n",
            "Iteration 50, loss = 0.41128049\n",
            "Iteration 51, loss = 0.41231135\n",
            "Iteration 52, loss = 0.41568337\n",
            "Iteration 53, loss = 0.41752627\n",
            "Iteration 54, loss = 0.41368167\n",
            "Iteration 55, loss = 0.41031644\n",
            "Iteration 56, loss = 0.41100702\n",
            "Iteration 57, loss = 0.41162943\n",
            "Iteration 58, loss = 0.41106364\n",
            "Iteration 59, loss = 0.41048469\n",
            "Iteration 60, loss = 0.40919025\n",
            "Iteration 61, loss = 0.40944030\n",
            "Iteration 62, loss = 0.40913917\n",
            "Iteration 63, loss = 0.40855511\n",
            "Iteration 64, loss = 0.40745280\n",
            "Iteration 65, loss = 0.40725656\n",
            "Iteration 66, loss = 0.40702935\n",
            "Iteration 67, loss = 0.40707261\n",
            "Iteration 68, loss = 0.40665097\n",
            "Iteration 69, loss = 0.40650843\n",
            "Iteration 70, loss = 0.40713841\n",
            "Iteration 71, loss = 0.40997868\n",
            "Iteration 72, loss = 0.40986378\n",
            "Iteration 73, loss = 0.40625678\n",
            "Iteration 74, loss = 0.40550245\n",
            "Iteration 75, loss = 0.40588079\n",
            "Iteration 76, loss = 0.40456398\n",
            "Iteration 77, loss = 0.40542413\n",
            "Iteration 78, loss = 0.40387889\n",
            "Iteration 79, loss = 0.40478233\n",
            "Iteration 80, loss = 0.40442680\n",
            "Iteration 81, loss = 0.40630176\n",
            "Iteration 82, loss = 0.40431827\n",
            "Iteration 83, loss = 0.40408979\n",
            "Iteration 84, loss = 0.40417521\n",
            "Iteration 85, loss = 0.40262899\n",
            "Iteration 86, loss = 0.40133824\n",
            "Iteration 87, loss = 0.40619612\n",
            "Iteration 88, loss = 0.40826907\n",
            "Iteration 89, loss = 0.40604399\n",
            "Iteration 90, loss = 0.40403006\n",
            "Iteration 91, loss = 0.40302739\n",
            "Iteration 92, loss = 0.40190401\n",
            "Iteration 93, loss = 0.40091299\n",
            "Iteration 94, loss = 0.40069091\n",
            "Iteration 95, loss = 0.39994617\n",
            "Iteration 96, loss = 0.39858024\n",
            "Iteration 97, loss = 0.39893025\n",
            "Iteration 98, loss = 0.40053014\n",
            "Iteration 99, loss = 0.39956487\n",
            "Iteration 100, loss = 0.39847690\n",
            "Iteration 101, loss = 0.39827341\n",
            "Iteration 102, loss = 0.40337979\n",
            "Iteration 103, loss = 0.40932385\n",
            "Iteration 104, loss = 0.40422460\n",
            "Iteration 105, loss = 0.39708892\n",
            "Iteration 106, loss = 0.39714801\n",
            "Iteration 107, loss = 0.39693382\n",
            "Iteration 108, loss = 0.39790630\n",
            "Iteration 109, loss = 0.39765917\n",
            "Iteration 110, loss = 0.39797444\n",
            "Iteration 111, loss = 0.39761938\n",
            "Iteration 112, loss = 0.39742277\n",
            "Iteration 113, loss = 0.39709786\n",
            "Iteration 114, loss = 0.39733830\n",
            "Iteration 115, loss = 0.39702180\n",
            "Iteration 116, loss = 0.39567857\n",
            "Iteration 117, loss = 0.39515490\n",
            "Iteration 118, loss = 0.39567486\n",
            "Iteration 119, loss = 0.39501245\n",
            "Iteration 120, loss = 0.39604059\n",
            "Iteration 121, loss = 0.39538544\n",
            "Iteration 122, loss = 0.39627794\n",
            "Iteration 123, loss = 0.39843097\n",
            "Iteration 124, loss = 0.39458984\n",
            "Iteration 125, loss = 0.39467048\n",
            "Iteration 126, loss = 0.39537428\n",
            "Iteration 127, loss = 0.39538237\n",
            "Iteration 128, loss = 0.39342931\n",
            "Iteration 129, loss = 0.39320360\n",
            "Iteration 130, loss = 0.39353775\n",
            "Iteration 131, loss = 0.39386720\n",
            "Iteration 132, loss = 0.39544931\n",
            "Iteration 133, loss = 0.39694526\n",
            "Iteration 134, loss = 0.39642286\n",
            "Iteration 135, loss = 0.39571575\n",
            "Iteration 136, loss = 0.39566995\n",
            "Iteration 137, loss = 0.39450027\n",
            "Iteration 138, loss = 0.39271671\n",
            "Iteration 139, loss = 0.39363567\n",
            "Iteration 140, loss = 0.39214012\n",
            "Iteration 141, loss = 0.39386617\n",
            "Iteration 142, loss = 0.39057489\n",
            "Iteration 143, loss = 0.39342736\n",
            "Iteration 144, loss = 0.39229663\n",
            "Iteration 145, loss = 0.39165375\n",
            "Iteration 146, loss = 0.39196404\n",
            "Iteration 147, loss = 0.39156994\n",
            "Iteration 148, loss = 0.39185634\n",
            "Iteration 149, loss = 0.39042741\n",
            "Iteration 150, loss = 0.39047749\n",
            "Iteration 151, loss = 0.39065773\n",
            "Iteration 152, loss = 0.38979801\n",
            "Iteration 153, loss = 0.39035610\n",
            "Iteration 154, loss = 0.39083206\n",
            "Iteration 155, loss = 0.39271657\n",
            "Iteration 156, loss = 0.38762988\n",
            "Iteration 157, loss = 0.39062057\n",
            "Iteration 158, loss = 0.39034548\n",
            "Iteration 159, loss = 0.38799530\n",
            "Iteration 160, loss = 0.38872389\n",
            "Iteration 161, loss = 0.39020709\n",
            "Iteration 162, loss = 0.39590603\n",
            "Iteration 163, loss = 0.39203399\n",
            "Iteration 164, loss = 0.39248236\n",
            "Iteration 165, loss = 0.39671613\n",
            "Iteration 166, loss = 0.39377784\n",
            "Iteration 167, loss = 0.38975269\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.88841557\n",
            "Iteration 2, loss = 6.88841299\n",
            "Iteration 3, loss = 6.88590458\n",
            "Iteration 4, loss = 6.87140796\n",
            "Iteration 5, loss = 6.69285463\n",
            "Iteration 6, loss = 6.30240000\n",
            "Iteration 7, loss = 5.83356034\n",
            "Iteration 8, loss = 5.32590150\n",
            "Iteration 9, loss = 4.79425849\n",
            "Iteration 10, loss = 4.27262644\n",
            "Iteration 11, loss = 3.76717927\n",
            "Iteration 12, loss = 3.29727189\n",
            "Iteration 13, loss = 2.83471411\n",
            "Iteration 14, loss = 2.42576721\n",
            "Iteration 15, loss = 2.02818363\n",
            "Iteration 16, loss = 1.64410634\n",
            "Iteration 17, loss = 1.27330443\n",
            "Iteration 18, loss = 0.91752736\n",
            "Iteration 19, loss = 0.61458840\n",
            "Iteration 20, loss = 0.44861847\n",
            "Iteration 21, loss = 0.43188421\n",
            "Iteration 22, loss = 0.43051718\n",
            "Iteration 23, loss = 0.43109445\n",
            "Iteration 24, loss = 0.42796550\n",
            "Iteration 25, loss = 0.42606025\n",
            "Iteration 26, loss = 0.42519725\n",
            "Iteration 27, loss = 0.42487784\n",
            "Iteration 28, loss = 0.42608287\n",
            "Iteration 29, loss = 0.42377914\n",
            "Iteration 30, loss = 0.42359999\n",
            "Iteration 31, loss = 0.42579266\n",
            "Iteration 32, loss = 0.42642845\n",
            "Iteration 33, loss = 0.42192923\n",
            "Iteration 34, loss = 0.42166754\n",
            "Iteration 35, loss = 0.41985692\n",
            "Iteration 36, loss = 0.41980653\n",
            "Iteration 37, loss = 0.41912417\n",
            "Iteration 38, loss = 0.41858041\n",
            "Iteration 39, loss = 0.41848925\n",
            "Iteration 40, loss = 0.41820831\n",
            "Iteration 41, loss = 0.41747357\n",
            "Iteration 42, loss = 0.41650998\n",
            "Iteration 43, loss = 0.41589364\n",
            "Iteration 44, loss = 0.41663739\n",
            "Iteration 45, loss = 0.41532824\n",
            "Iteration 46, loss = 0.41459672\n",
            "Iteration 47, loss = 0.41399724\n",
            "Iteration 48, loss = 0.41358999\n",
            "Iteration 49, loss = 0.41649552\n",
            "Iteration 50, loss = 0.41212059\n",
            "Iteration 51, loss = 0.41430124\n",
            "Iteration 52, loss = 0.41188774\n",
            "Iteration 53, loss = 0.41037284\n",
            "Iteration 54, loss = 0.41254508\n",
            "Iteration 55, loss = 0.41071802\n",
            "Iteration 56, loss = 0.41081769\n",
            "Iteration 57, loss = 0.41303598\n",
            "Iteration 58, loss = 0.41076042\n",
            "Iteration 59, loss = 0.40908790\n",
            "Iteration 60, loss = 0.40884713\n",
            "Iteration 61, loss = 0.40885915\n",
            "Iteration 62, loss = 0.40807583\n",
            "Iteration 63, loss = 0.40746826\n",
            "Iteration 64, loss = 0.40784650\n",
            "Iteration 65, loss = 0.40681604\n",
            "Iteration 66, loss = 0.40642529\n",
            "Iteration 67, loss = 0.40590356\n",
            "Iteration 68, loss = 0.40598873\n",
            "Iteration 69, loss = 0.40509396\n",
            "Iteration 70, loss = 0.40730725\n",
            "Iteration 71, loss = 0.40461315\n",
            "Iteration 72, loss = 0.40447111\n",
            "Iteration 73, loss = 0.40366540\n",
            "Iteration 74, loss = 0.40611768\n",
            "Iteration 75, loss = 0.40763359\n",
            "Iteration 76, loss = 0.40351927\n",
            "Iteration 77, loss = 0.40260919\n",
            "Iteration 78, loss = 0.40209491\n",
            "Iteration 79, loss = 0.40147143\n",
            "Iteration 80, loss = 0.40076799\n",
            "Iteration 81, loss = 0.40550526\n",
            "Iteration 82, loss = 0.40043574\n",
            "Iteration 83, loss = 0.39985327\n",
            "Iteration 84, loss = 0.40474788\n",
            "Iteration 85, loss = 0.40002239\n",
            "Iteration 86, loss = 0.39865565\n",
            "Iteration 87, loss = 0.39913902\n",
            "Iteration 88, loss = 0.39848621\n",
            "Iteration 89, loss = 0.39861231\n",
            "Iteration 90, loss = 0.39738206\n",
            "Iteration 91, loss = 0.39819313\n",
            "Iteration 92, loss = 0.39869431\n",
            "Iteration 93, loss = 0.39671090\n",
            "Iteration 94, loss = 0.39806494\n",
            "Iteration 95, loss = 0.39664781\n",
            "Iteration 96, loss = 0.39728316\n",
            "Iteration 97, loss = 0.39654073\n",
            "Iteration 98, loss = 0.39730214\n",
            "Iteration 99, loss = 0.39563344\n",
            "Iteration 100, loss = 0.39522642\n",
            "Iteration 101, loss = 0.39504194\n",
            "Iteration 102, loss = 0.39399844\n",
            "Iteration 103, loss = 0.39410640\n",
            "Iteration 104, loss = 0.39402297\n",
            "Iteration 105, loss = 0.39476692\n",
            "Iteration 106, loss = 0.39378251\n",
            "Iteration 107, loss = 0.39278388\n",
            "Iteration 108, loss = 0.39633373\n",
            "Iteration 109, loss = 0.39213954\n",
            "Iteration 110, loss = 0.39438791\n",
            "Iteration 111, loss = 0.39395294\n",
            "Iteration 112, loss = 0.39218867\n",
            "Iteration 113, loss = 0.39145335\n",
            "Iteration 114, loss = 0.39178432\n",
            "Iteration 115, loss = 0.39554411\n",
            "Iteration 116, loss = 0.39043291\n",
            "Iteration 117, loss = 0.39148855\n",
            "Iteration 118, loss = 0.39087955\n",
            "Iteration 119, loss = 0.39357477\n",
            "Iteration 120, loss = 0.39169458\n",
            "Iteration 121, loss = 0.39159179\n",
            "Iteration 122, loss = 0.38988586\n",
            "Iteration 123, loss = 0.38940125\n",
            "Iteration 124, loss = 0.38932009\n",
            "Iteration 125, loss = 0.38949155\n",
            "Iteration 126, loss = 0.38887263\n",
            "Iteration 127, loss = 0.38926921\n",
            "Iteration 128, loss = 0.38901051\n",
            "Iteration 129, loss = 0.39074775\n",
            "Iteration 130, loss = 0.38868705\n",
            "Iteration 131, loss = 0.38940099\n",
            "Iteration 132, loss = 0.38788378\n",
            "Iteration 133, loss = 0.38908563\n",
            "Iteration 134, loss = 0.38690754\n",
            "Iteration 135, loss = 0.38697162\n",
            "Iteration 136, loss = 0.38990769\n",
            "Iteration 137, loss = 0.39280119\n",
            "Iteration 138, loss = 0.39021450\n",
            "Iteration 139, loss = 0.38793700\n",
            "Iteration 140, loss = 0.39306321\n",
            "Iteration 141, loss = 0.38622359\n",
            "Iteration 142, loss = 0.38902204\n",
            "Iteration 143, loss = 0.38743874\n",
            "Iteration 144, loss = 0.38769719\n",
            "Iteration 145, loss = 0.38883753\n",
            "Iteration 146, loss = 0.38753171\n",
            "Iteration 147, loss = 0.38610580\n",
            "Iteration 148, loss = 0.38692537\n",
            "Iteration 149, loss = 0.38447314\n",
            "Iteration 150, loss = 0.38758978\n",
            "Iteration 151, loss = 0.38914216\n",
            "Iteration 152, loss = 0.38915681\n",
            "Iteration 153, loss = 0.38953872\n",
            "Iteration 154, loss = 0.38440939\n",
            "Iteration 155, loss = 0.38703313\n",
            "Iteration 156, loss = 0.38384453\n",
            "Iteration 157, loss = 0.38390918\n",
            "Iteration 158, loss = 0.38346736\n",
            "Iteration 159, loss = 0.38455374\n",
            "Iteration 160, loss = 0.38757367\n",
            "Iteration 161, loss = 0.38670003\n",
            "Iteration 162, loss = 0.38482421\n",
            "Iteration 163, loss = 0.38438066\n",
            "Iteration 164, loss = 0.38355825\n",
            "Iteration 165, loss = 0.38804175\n",
            "Iteration 166, loss = 0.38256213\n",
            "Iteration 167, loss = 0.38392714\n",
            "Iteration 168, loss = 0.38592754\n",
            "Iteration 169, loss = 0.38224906\n",
            "Iteration 170, loss = 0.38232458\n",
            "Iteration 171, loss = 0.38370611\n",
            "Iteration 172, loss = 0.38505964\n",
            "Iteration 173, loss = 0.38333426\n",
            "Iteration 174, loss = 0.38224712\n",
            "Iteration 175, loss = 0.38217530\n",
            "Iteration 176, loss = 0.39391597\n",
            "Iteration 177, loss = 0.38969316\n",
            "Iteration 178, loss = 0.38402904\n",
            "Iteration 179, loss = 0.38407692\n",
            "Iteration 180, loss = 0.39048847\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.37650962\n",
            "Iteration 2, loss = 6.37460461\n",
            "Iteration 3, loss = 6.32679594\n",
            "Iteration 4, loss = 5.92811639\n",
            "Iteration 5, loss = 5.30490966\n",
            "Iteration 6, loss = 4.61306721\n",
            "Iteration 7, loss = 3.92598686\n",
            "Iteration 8, loss = 3.29140923\n",
            "Iteration 9, loss = 2.67424447\n",
            "Iteration 10, loss = 2.09449039\n",
            "Iteration 11, loss = 1.54866118\n",
            "Iteration 12, loss = 1.01400260\n",
            "Iteration 13, loss = 0.58389157\n",
            "Iteration 14, loss = 0.41891242\n",
            "Iteration 15, loss = 0.40911573\n",
            "Iteration 16, loss = 0.40776618\n",
            "Iteration 17, loss = 0.40643129\n",
            "Iteration 18, loss = 0.40648356\n",
            "Iteration 19, loss = 0.40743940\n",
            "Iteration 20, loss = 0.40495034\n",
            "Iteration 21, loss = 0.40376984\n",
            "Iteration 22, loss = 0.40296235\n",
            "Iteration 23, loss = 0.40153679\n",
            "Iteration 24, loss = 0.40049780\n",
            "Iteration 25, loss = 0.40000737\n",
            "Iteration 26, loss = 0.39855980\n",
            "Iteration 27, loss = 0.39797752\n",
            "Iteration 28, loss = 0.39622774\n",
            "Iteration 29, loss = 0.39679382\n",
            "Iteration 30, loss = 0.39559501\n",
            "Iteration 31, loss = 0.39523484\n",
            "Iteration 32, loss = 0.39345231\n",
            "Iteration 33, loss = 0.39290780\n",
            "Iteration 34, loss = 0.39236696\n",
            "Iteration 35, loss = 0.39273773\n",
            "Iteration 36, loss = 0.39101039\n",
            "Iteration 37, loss = 0.39121177\n",
            "Iteration 38, loss = 0.39001838\n",
            "Iteration 39, loss = 0.38929849\n",
            "Iteration 40, loss = 0.38837547\n",
            "Iteration 41, loss = 0.38934197\n",
            "Iteration 42, loss = 0.38836631\n",
            "Iteration 43, loss = 0.38789092\n",
            "Iteration 44, loss = 0.38591491\n",
            "Iteration 45, loss = 0.38566486\n",
            "Iteration 46, loss = 0.38585822\n",
            "Iteration 47, loss = 0.38451378\n",
            "Iteration 48, loss = 0.38482283\n",
            "Iteration 49, loss = 0.38355496\n",
            "Iteration 50, loss = 0.38353965\n",
            "Iteration 51, loss = 0.38273613\n",
            "Iteration 52, loss = 0.38343661\n",
            "Iteration 53, loss = 0.38584350\n",
            "Iteration 54, loss = 0.38379468\n",
            "Iteration 55, loss = 0.38174325\n",
            "Iteration 56, loss = 0.38092883\n",
            "Iteration 57, loss = 0.38007554\n",
            "Iteration 58, loss = 0.37978973\n",
            "Iteration 59, loss = 0.37941844\n",
            "Iteration 60, loss = 0.38261379\n",
            "Iteration 61, loss = 0.38072581\n",
            "Iteration 62, loss = 0.37945365\n",
            "Iteration 63, loss = 0.37736865\n",
            "Iteration 64, loss = 0.37827065\n",
            "Iteration 65, loss = 0.37735031\n",
            "Iteration 66, loss = 0.37771741\n",
            "Iteration 67, loss = 0.37697124\n",
            "Iteration 68, loss = 0.37562851\n",
            "Iteration 69, loss = 0.37495570\n",
            "Iteration 70, loss = 0.37553384\n",
            "Iteration 71, loss = 0.37428178\n",
            "Iteration 72, loss = 0.37473865\n",
            "Iteration 73, loss = 0.37444509\n",
            "Iteration 74, loss = 0.37248273\n",
            "Iteration 75, loss = 0.37359084\n",
            "Iteration 76, loss = 0.37283504\n",
            "Iteration 77, loss = 0.37175260\n",
            "Iteration 78, loss = 0.37227226\n",
            "Iteration 79, loss = 0.37563532\n",
            "Iteration 80, loss = 0.37628531\n",
            "Iteration 81, loss = 0.37267160\n",
            "Iteration 82, loss = 0.37167191\n",
            "Iteration 83, loss = 0.37044586\n",
            "Iteration 84, loss = 0.37106079\n",
            "Iteration 85, loss = 0.37008737\n",
            "Iteration 86, loss = 0.37178660\n",
            "Iteration 87, loss = 0.36950053\n",
            "Iteration 88, loss = 0.37000429\n",
            "Iteration 89, loss = 0.37002825\n",
            "Iteration 90, loss = 0.36915426\n",
            "Iteration 91, loss = 0.37138916\n",
            "Iteration 92, loss = 0.37001261\n",
            "Iteration 93, loss = 0.36946653\n",
            "Iteration 94, loss = 0.36964929\n",
            "Iteration 95, loss = 0.36799287\n",
            "Iteration 96, loss = 0.36793468\n",
            "Iteration 97, loss = 0.36771439\n",
            "Iteration 98, loss = 0.36750946\n",
            "Iteration 99, loss = 0.36682998\n",
            "Iteration 100, loss = 0.36622164\n",
            "Iteration 101, loss = 0.36762336\n",
            "Iteration 102, loss = 0.36801260\n",
            "Iteration 103, loss = 0.36642067\n",
            "Iteration 104, loss = 0.36638068\n",
            "Iteration 105, loss = 0.36529510\n",
            "Iteration 106, loss = 0.36527116\n",
            "Iteration 107, loss = 0.37174271\n",
            "Iteration 108, loss = 0.36592916\n",
            "Iteration 109, loss = 0.36528426\n",
            "Iteration 110, loss = 0.36554148\n",
            "Iteration 111, loss = 0.36463885\n",
            "Iteration 112, loss = 0.36532912\n",
            "Iteration 113, loss = 0.36473681\n",
            "Iteration 114, loss = 0.36558612\n",
            "Iteration 115, loss = 0.36694847\n",
            "Iteration 116, loss = 0.36775970\n",
            "Iteration 117, loss = 0.36438401\n",
            "Iteration 118, loss = 0.36359023\n",
            "Iteration 119, loss = 0.36393367\n",
            "Iteration 120, loss = 0.36462195\n",
            "Iteration 121, loss = 0.36407387\n",
            "Iteration 122, loss = 0.36234182\n",
            "Iteration 123, loss = 0.36474798\n",
            "Iteration 124, loss = 0.36290823\n",
            "Iteration 125, loss = 0.36381231\n",
            "Iteration 126, loss = 0.36253101\n",
            "Iteration 127, loss = 0.36106937\n",
            "Iteration 128, loss = 0.36200814\n",
            "Iteration 129, loss = 0.36181105\n",
            "Iteration 130, loss = 0.36289251\n",
            "Iteration 131, loss = 0.36770900\n",
            "Iteration 132, loss = 0.36146143\n",
            "Iteration 133, loss = 0.36190905\n",
            "Iteration 134, loss = 0.36139139\n",
            "Iteration 135, loss = 0.36094096\n",
            "Iteration 136, loss = 0.36203546\n",
            "Iteration 137, loss = 0.36257842\n",
            "Iteration 138, loss = 0.36133458\n",
            "Iteration 139, loss = 0.35987200\n",
            "Iteration 140, loss = 0.36308841\n",
            "Iteration 141, loss = 0.36050178\n",
            "Iteration 142, loss = 0.36204110\n",
            "Iteration 143, loss = 0.35891102\n",
            "Iteration 144, loss = 0.35948819\n",
            "Iteration 145, loss = 0.35902029\n",
            "Iteration 146, loss = 0.35906957\n",
            "Iteration 147, loss = 0.35977171\n",
            "Iteration 148, loss = 0.36185070\n",
            "Iteration 149, loss = 0.36122386\n",
            "Iteration 150, loss = 0.35867582\n",
            "Iteration 151, loss = 0.35890993\n",
            "Iteration 152, loss = 0.36399829\n",
            "Iteration 153, loss = 0.36038207\n",
            "Iteration 154, loss = 0.36371779\n",
            "Iteration 155, loss = 0.35987489\n",
            "Iteration 156, loss = 0.35769604\n",
            "Iteration 157, loss = 0.35821825\n",
            "Iteration 158, loss = 0.35890248\n",
            "Iteration 159, loss = 0.35759455\n",
            "Iteration 160, loss = 0.35977708\n",
            "Iteration 161, loss = 0.35802106\n",
            "Iteration 162, loss = 0.35821495\n",
            "Iteration 163, loss = 0.36052558\n",
            "Iteration 164, loss = 0.35953093\n",
            "Iteration 165, loss = 0.35944236\n",
            "Iteration 166, loss = 0.36168586\n",
            "Iteration 167, loss = 0.35658557\n",
            "Iteration 168, loss = 0.35827662\n",
            "Iteration 169, loss = 0.35863738\n",
            "Iteration 170, loss = 0.35727476\n",
            "Iteration 171, loss = 0.35699474\n",
            "Iteration 172, loss = 0.35702226\n",
            "Iteration 173, loss = 0.35778789\n",
            "Iteration 174, loss = 0.35882566\n",
            "Iteration 175, loss = 0.35607465\n",
            "Iteration 176, loss = 0.35668373\n",
            "Iteration 177, loss = 0.35530223\n",
            "Iteration 178, loss = 0.36025295\n",
            "Iteration 179, loss = 0.36154479\n",
            "Iteration 180, loss = 0.35821730\n",
            "Iteration 181, loss = 0.35972414\n",
            "Iteration 182, loss = 0.35961570\n",
            "Iteration 183, loss = 0.35947180\n",
            "Iteration 184, loss = 0.35754688\n",
            "Iteration 185, loss = 0.35565449\n",
            "Iteration 186, loss = 0.35934017\n",
            "Iteration 187, loss = 0.35605533\n",
            "Iteration 188, loss = 0.35849679\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.16420017\n",
            "Iteration 2, loss = 6.15598127\n",
            "Iteration 3, loss = 5.85551546\n",
            "Iteration 4, loss = 5.03693623\n",
            "Iteration 5, loss = 4.12375440\n",
            "Iteration 6, loss = 3.24011338\n",
            "Iteration 7, loss = 2.45595300\n",
            "Iteration 8, loss = 1.72396518\n",
            "Iteration 9, loss = 1.07079916\n",
            "Iteration 10, loss = 0.53747614\n",
            "Iteration 11, loss = 0.39960290\n",
            "Iteration 12, loss = 0.39436386\n",
            "Iteration 13, loss = 0.39395601\n",
            "Iteration 14, loss = 0.39273769\n",
            "Iteration 15, loss = 0.39107435\n",
            "Iteration 16, loss = 0.39026525\n",
            "Iteration 17, loss = 0.38884590\n",
            "Iteration 18, loss = 0.38790502\n",
            "Iteration 19, loss = 0.38880573\n",
            "Iteration 20, loss = 0.38616430\n",
            "Iteration 21, loss = 0.38579675\n",
            "Iteration 22, loss = 0.38351588\n",
            "Iteration 23, loss = 0.38264605\n",
            "Iteration 24, loss = 0.38205234\n",
            "Iteration 25, loss = 0.38305036\n",
            "Iteration 26, loss = 0.38022033\n",
            "Iteration 27, loss = 0.37914842\n",
            "Iteration 28, loss = 0.37919635\n",
            "Iteration 29, loss = 0.37910352\n",
            "Iteration 30, loss = 0.37698325\n",
            "Iteration 31, loss = 0.37604524\n",
            "Iteration 32, loss = 0.37511560\n",
            "Iteration 33, loss = 0.37488459\n",
            "Iteration 34, loss = 0.37391448\n",
            "Iteration 35, loss = 0.37301334\n",
            "Iteration 36, loss = 0.37264612\n",
            "Iteration 37, loss = 0.37206826\n",
            "Iteration 38, loss = 0.37140277\n",
            "Iteration 39, loss = 0.37020533\n",
            "Iteration 40, loss = 0.37014967\n",
            "Iteration 41, loss = 0.36967770\n",
            "Iteration 42, loss = 0.36833614\n",
            "Iteration 43, loss = 0.36799979\n",
            "Iteration 44, loss = 0.36746215\n",
            "Iteration 45, loss = 0.36810304\n",
            "Iteration 46, loss = 0.36656249\n",
            "Iteration 47, loss = 0.36638588\n",
            "Iteration 48, loss = 0.36539454\n",
            "Iteration 49, loss = 0.36448429\n",
            "Iteration 50, loss = 0.36496272\n",
            "Iteration 51, loss = 0.36349169\n",
            "Iteration 52, loss = 0.36538537\n",
            "Iteration 53, loss = 0.36255721\n",
            "Iteration 54, loss = 0.36400268\n",
            "Iteration 55, loss = 0.36379390\n",
            "Iteration 56, loss = 0.36096003\n",
            "Iteration 57, loss = 0.36090150\n",
            "Iteration 58, loss = 0.36019379\n",
            "Iteration 59, loss = 0.36021331\n",
            "Iteration 60, loss = 0.36128654\n",
            "Iteration 61, loss = 0.36097220\n",
            "Iteration 62, loss = 0.35992932\n",
            "Iteration 63, loss = 0.36070071\n",
            "Iteration 64, loss = 0.35793058\n",
            "Iteration 65, loss = 0.35845649\n",
            "Iteration 66, loss = 0.35774798\n",
            "Iteration 67, loss = 0.35735253\n",
            "Iteration 68, loss = 0.35795121\n",
            "Iteration 69, loss = 0.35742731\n",
            "Iteration 70, loss = 0.35686666\n",
            "Iteration 71, loss = 0.35662183\n",
            "Iteration 72, loss = 0.35630568\n",
            "Iteration 73, loss = 0.35773439\n",
            "Iteration 74, loss = 0.35562005\n",
            "Iteration 75, loss = 0.35566218\n",
            "Iteration 76, loss = 0.35522714\n",
            "Iteration 77, loss = 0.35455969\n",
            "Iteration 78, loss = 0.35555756\n",
            "Iteration 79, loss = 0.35743352\n",
            "Iteration 80, loss = 0.35590519\n",
            "Iteration 81, loss = 0.35510467\n",
            "Iteration 82, loss = 0.35426146\n",
            "Iteration 83, loss = 0.35541521\n",
            "Iteration 84, loss = 0.35367658\n",
            "Iteration 85, loss = 0.35310757\n",
            "Iteration 86, loss = 0.35608578\n",
            "Iteration 87, loss = 0.35458903\n",
            "Iteration 88, loss = 0.35702779\n",
            "Iteration 89, loss = 0.35236934\n",
            "Iteration 90, loss = 0.35427202\n",
            "Iteration 91, loss = 0.35717514\n",
            "Iteration 92, loss = 0.35242899\n",
            "Iteration 93, loss = 0.35199646\n",
            "Iteration 94, loss = 0.35118703\n",
            "Iteration 95, loss = 0.35335013\n",
            "Iteration 96, loss = 0.35148263\n",
            "Iteration 97, loss = 0.35220611\n",
            "Iteration 98, loss = 0.35035301\n",
            "Iteration 99, loss = 0.34985143\n",
            "Iteration 100, loss = 0.35090806\n",
            "Iteration 101, loss = 0.35002361\n",
            "Iteration 102, loss = 0.35101822\n",
            "Iteration 103, loss = 0.34900561\n",
            "Iteration 104, loss = 0.34952910\n",
            "Iteration 105, loss = 0.35132808\n",
            "Iteration 106, loss = 0.34974480\n",
            "Iteration 107, loss = 0.35114350\n",
            "Iteration 108, loss = 0.35032639\n",
            "Iteration 109, loss = 0.34877586\n",
            "Iteration 110, loss = 0.34861032\n",
            "Iteration 111, loss = 0.34951804\n",
            "Iteration 112, loss = 0.34830846\n",
            "Iteration 113, loss = 0.34937123\n",
            "Iteration 114, loss = 0.35039661\n",
            "Iteration 115, loss = 0.34853567\n",
            "Iteration 116, loss = 0.34857071\n",
            "Iteration 117, loss = 0.34811593\n",
            "Iteration 118, loss = 0.34779063\n",
            "Iteration 119, loss = 0.34872229\n",
            "Iteration 120, loss = 0.34601102\n",
            "Iteration 121, loss = 0.34666823\n",
            "Iteration 122, loss = 0.34593044\n",
            "Iteration 123, loss = 0.34602743\n",
            "Iteration 124, loss = 0.34913105\n",
            "Iteration 125, loss = 0.34990628\n",
            "Iteration 126, loss = 0.34854265\n",
            "Iteration 127, loss = 0.34543778\n",
            "Iteration 128, loss = 0.34700395\n",
            "Iteration 129, loss = 0.34687763\n",
            "Iteration 130, loss = 0.34589812\n",
            "Iteration 131, loss = 0.34538596\n",
            "Iteration 132, loss = 0.35028291\n",
            "Iteration 133, loss = 0.34620124\n",
            "Iteration 134, loss = 0.34603784\n",
            "Iteration 135, loss = 0.34731616\n",
            "Iteration 136, loss = 0.34688992\n",
            "Iteration 137, loss = 0.34584236\n",
            "Iteration 138, loss = 0.34705304\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.08212989\n",
            "Iteration 2, loss = 6.00970944\n",
            "Iteration 3, loss = 5.29820303\n",
            "Iteration 4, loss = 4.21786755\n",
            "Iteration 5, loss = 3.13403627\n",
            "Iteration 6, loss = 2.12910203\n",
            "Iteration 7, loss = 1.24823882\n",
            "Iteration 8, loss = 0.55060826\n",
            "Iteration 9, loss = 0.40260123\n",
            "Iteration 10, loss = 0.40011449\n",
            "Iteration 11, loss = 0.39815678\n",
            "Iteration 12, loss = 0.39748292\n",
            "Iteration 13, loss = 0.39482773\n",
            "Iteration 14, loss = 0.39351910\n",
            "Iteration 15, loss = 0.39252912\n",
            "Iteration 16, loss = 0.39110155\n",
            "Iteration 17, loss = 0.39060349\n",
            "Iteration 18, loss = 0.38891114\n",
            "Iteration 19, loss = 0.38727441\n",
            "Iteration 20, loss = 0.38590400\n",
            "Iteration 21, loss = 0.38585200\n",
            "Iteration 22, loss = 0.38371281\n",
            "Iteration 23, loss = 0.38337542\n",
            "Iteration 24, loss = 0.38168992\n",
            "Iteration 25, loss = 0.38074855\n",
            "Iteration 26, loss = 0.37964512\n",
            "Iteration 27, loss = 0.38111077\n",
            "Iteration 28, loss = 0.37843544\n",
            "Iteration 29, loss = 0.37750308\n",
            "Iteration 30, loss = 0.37687389\n",
            "Iteration 31, loss = 0.37582897\n",
            "Iteration 32, loss = 0.37584613\n",
            "Iteration 33, loss = 0.37373641\n",
            "Iteration 34, loss = 0.37385081\n",
            "Iteration 35, loss = 0.37205715\n",
            "Iteration 36, loss = 0.37109016\n",
            "Iteration 37, loss = 0.37116244\n",
            "Iteration 38, loss = 0.37004674\n",
            "Iteration 39, loss = 0.37066094\n",
            "Iteration 40, loss = 0.36803613\n",
            "Iteration 41, loss = 0.36775581\n",
            "Iteration 42, loss = 0.36681641\n",
            "Iteration 43, loss = 0.36667470\n",
            "Iteration 44, loss = 0.36624477\n",
            "Iteration 45, loss = 0.36687246\n",
            "Iteration 46, loss = 0.36525092\n",
            "Iteration 47, loss = 0.36558426\n",
            "Iteration 48, loss = 0.36686705\n",
            "Iteration 49, loss = 0.36337965\n",
            "Iteration 50, loss = 0.36432148\n",
            "Iteration 51, loss = 0.36261296\n",
            "Iteration 52, loss = 0.36157299\n",
            "Iteration 53, loss = 0.36315792\n",
            "Iteration 54, loss = 0.36203923\n",
            "Iteration 55, loss = 0.36237879\n",
            "Iteration 56, loss = 0.36071005\n",
            "Iteration 57, loss = 0.36013142\n",
            "Iteration 58, loss = 0.35957978\n",
            "Iteration 59, loss = 0.35974098\n",
            "Iteration 60, loss = 0.36213625\n",
            "Iteration 61, loss = 0.35966204\n",
            "Iteration 62, loss = 0.35994109\n",
            "Iteration 63, loss = 0.35962573\n",
            "Iteration 64, loss = 0.35788700\n",
            "Iteration 65, loss = 0.35955123\n",
            "Iteration 66, loss = 0.35938204\n",
            "Iteration 67, loss = 0.35877826\n",
            "Iteration 68, loss = 0.35970661\n",
            "Iteration 69, loss = 0.35811772\n",
            "Iteration 70, loss = 0.35576860\n",
            "Iteration 71, loss = 0.35646785\n",
            "Iteration 72, loss = 0.35724070\n",
            "Iteration 73, loss = 0.35697376\n",
            "Iteration 74, loss = 0.35632848\n",
            "Iteration 75, loss = 0.35592326\n",
            "Iteration 76, loss = 0.35436721\n",
            "Iteration 77, loss = 0.35483243\n",
            "Iteration 78, loss = 0.35915643\n",
            "Iteration 79, loss = 0.35412284\n",
            "Iteration 80, loss = 0.35441347\n",
            "Iteration 81, loss = 0.35320180\n",
            "Iteration 82, loss = 0.35363658\n",
            "Iteration 83, loss = 0.35267673\n",
            "Iteration 84, loss = 0.35423059\n",
            "Iteration 85, loss = 0.35152885\n",
            "Iteration 86, loss = 0.35260168\n",
            "Iteration 87, loss = 0.35317058\n",
            "Iteration 88, loss = 0.35094859\n",
            "Iteration 89, loss = 0.35359018\n",
            "Iteration 90, loss = 0.35158613\n",
            "Iteration 91, loss = 0.35053542\n",
            "Iteration 92, loss = 0.34989569\n",
            "Iteration 93, loss = 0.34983619\n",
            "Iteration 94, loss = 0.34984605\n",
            "Iteration 95, loss = 0.35005256\n",
            "Iteration 96, loss = 0.34852408\n",
            "Iteration 97, loss = 0.35136265\n",
            "Iteration 98, loss = 0.35114219\n",
            "Iteration 99, loss = 0.34954460\n",
            "Iteration 100, loss = 0.34943760\n",
            "Iteration 101, loss = 0.34805199\n",
            "Iteration 102, loss = 0.35011159\n",
            "Iteration 103, loss = 0.34852278\n",
            "Iteration 104, loss = 0.34817558\n",
            "Iteration 105, loss = 0.34884489\n",
            "Iteration 106, loss = 0.34775418\n",
            "Iteration 107, loss = 0.34868643\n",
            "Iteration 108, loss = 0.34779466\n",
            "Iteration 109, loss = 0.34799004\n",
            "Iteration 110, loss = 0.34757864\n",
            "Iteration 111, loss = 0.34780757\n",
            "Iteration 112, loss = 0.34947833\n",
            "Iteration 113, loss = 0.35059011\n",
            "Iteration 114, loss = 0.34652961\n",
            "Iteration 115, loss = 0.34612421\n",
            "Iteration 116, loss = 0.34669842\n",
            "Iteration 117, loss = 0.34624981\n",
            "Iteration 118, loss = 0.35035804\n",
            "Iteration 119, loss = 0.34671196\n",
            "Iteration 120, loss = 0.34651538\n",
            "Iteration 121, loss = 0.34591552\n",
            "Iteration 122, loss = 0.34561382\n",
            "Iteration 123, loss = 0.34635583\n",
            "Iteration 124, loss = 0.34445463\n",
            "Iteration 125, loss = 0.34573968\n",
            "Iteration 126, loss = 0.34787681\n",
            "Iteration 127, loss = 0.34523903\n",
            "Iteration 128, loss = 0.34608680\n",
            "Iteration 129, loss = 0.34399289\n",
            "Iteration 130, loss = 0.34637657\n",
            "Iteration 131, loss = 0.34634075\n",
            "Iteration 132, loss = 0.34345352\n",
            "Iteration 133, loss = 0.34314350\n",
            "Iteration 134, loss = 0.34497206\n",
            "Iteration 135, loss = 0.34399742\n",
            "Iteration 136, loss = 0.34539681\n",
            "Iteration 137, loss = 0.35065654\n",
            "Iteration 138, loss = 0.34523556\n",
            "Iteration 139, loss = 0.34247337\n",
            "Iteration 140, loss = 0.34278285\n",
            "Iteration 141, loss = 0.34394626\n",
            "Iteration 142, loss = 0.34316319\n",
            "Iteration 143, loss = 0.34375212\n",
            "Iteration 144, loss = 0.35091296\n",
            "Iteration 145, loss = 0.34221066\n",
            "Iteration 146, loss = 0.34555545\n",
            "Iteration 147, loss = 0.34585828\n",
            "Iteration 148, loss = 0.34412787\n",
            "Iteration 149, loss = 0.34450553\n",
            "Iteration 150, loss = 0.34766098\n",
            "Iteration 151, loss = 0.34336645\n",
            "Iteration 152, loss = 0.34368719\n",
            "Iteration 153, loss = 0.34201997\n",
            "Iteration 154, loss = 0.34216442\n",
            "Iteration 155, loss = 0.34563747\n",
            "Iteration 156, loss = 0.34272106\n",
            "Iteration 157, loss = 0.34237283\n",
            "Iteration 158, loss = 0.34257361\n",
            "Iteration 159, loss = 0.34222517\n",
            "Iteration 160, loss = 0.34313924\n",
            "Iteration 161, loss = 0.34095737\n",
            "Iteration 162, loss = 0.34489415\n",
            "Iteration 163, loss = 0.34250811\n",
            "Iteration 164, loss = 0.34252579\n",
            "Iteration 165, loss = 0.34260297\n",
            "Iteration 166, loss = 0.34319092\n",
            "Iteration 167, loss = 0.34153835\n",
            "Iteration 168, loss = 0.34166093\n",
            "Iteration 169, loss = 0.34574368\n",
            "Iteration 170, loss = 0.34194591\n",
            "Iteration 171, loss = 0.34337857\n",
            "Iteration 172, loss = 0.35218543\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.32306971\n",
            "Iteration 2, loss = 6.12665672\n",
            "Iteration 3, loss = 5.01730239\n",
            "Iteration 4, loss = 3.68251990\n",
            "Iteration 5, loss = 2.39491963\n",
            "Iteration 6, loss = 1.27857617\n",
            "Iteration 7, loss = 0.51091901\n",
            "Iteration 8, loss = 0.41049202\n",
            "Iteration 9, loss = 0.40836471\n",
            "Iteration 10, loss = 0.40583959\n",
            "Iteration 11, loss = 0.40366629\n",
            "Iteration 12, loss = 0.40245489\n",
            "Iteration 13, loss = 0.39935462\n",
            "Iteration 14, loss = 0.39821757\n",
            "Iteration 15, loss = 0.39599158\n",
            "Iteration 16, loss = 0.39667752\n",
            "Iteration 17, loss = 0.39322524\n",
            "Iteration 18, loss = 0.39212852\n",
            "Iteration 19, loss = 0.39058636\n",
            "Iteration 20, loss = 0.38936482\n",
            "Iteration 21, loss = 0.38857322\n",
            "Iteration 22, loss = 0.38760801\n",
            "Iteration 23, loss = 0.38533223\n",
            "Iteration 24, loss = 0.38390436\n",
            "Iteration 25, loss = 0.38284953\n",
            "Iteration 26, loss = 0.38126215\n",
            "Iteration 27, loss = 0.38081044\n",
            "Iteration 28, loss = 0.37807567\n",
            "Iteration 29, loss = 0.37344560\n",
            "Iteration 30, loss = 0.37128209\n",
            "Iteration 31, loss = 0.37138951\n",
            "Iteration 32, loss = 0.36908043\n",
            "Iteration 33, loss = 0.36818275\n",
            "Iteration 34, loss = 0.36749979\n",
            "Iteration 35, loss = 0.36850910\n",
            "Iteration 36, loss = 0.36431144\n",
            "Iteration 37, loss = 0.36515545\n",
            "Iteration 38, loss = 0.36520468\n",
            "Iteration 39, loss = 0.36129509\n",
            "Iteration 40, loss = 0.36355702\n",
            "Iteration 41, loss = 0.36075908\n",
            "Iteration 42, loss = 0.35961729\n",
            "Iteration 43, loss = 0.35928335\n",
            "Iteration 44, loss = 0.35845852\n",
            "Iteration 45, loss = 0.35910927\n",
            "Iteration 46, loss = 0.35789932\n",
            "Iteration 47, loss = 0.35641112\n",
            "Iteration 48, loss = 0.35783861\n",
            "Iteration 49, loss = 0.35701016\n",
            "Iteration 50, loss = 0.35453345\n",
            "Iteration 51, loss = 0.35430863\n",
            "Iteration 52, loss = 0.35587671\n",
            "Iteration 53, loss = 0.35823946\n",
            "Iteration 54, loss = 0.35205102\n",
            "Iteration 55, loss = 0.35319614\n",
            "Iteration 56, loss = 0.35477347\n",
            "Iteration 57, loss = 0.35365853\n",
            "Iteration 58, loss = 0.35521940\n",
            "Iteration 59, loss = 0.35171586\n",
            "Iteration 60, loss = 0.35153885\n",
            "Iteration 61, loss = 0.35197571\n",
            "Iteration 62, loss = 0.35474816\n",
            "Iteration 63, loss = 0.35524436\n",
            "Iteration 64, loss = 0.35252816\n",
            "Iteration 65, loss = 0.35110854\n",
            "Iteration 66, loss = 0.35279709\n",
            "Iteration 67, loss = 0.35086447\n",
            "Iteration 68, loss = 0.35371162\n",
            "Iteration 69, loss = 0.35276685\n",
            "Iteration 70, loss = 0.35047673\n",
            "Iteration 71, loss = 0.35079804\n",
            "Iteration 72, loss = 0.35056934\n",
            "Iteration 73, loss = 0.35161588\n",
            "Iteration 74, loss = 0.34999390\n",
            "Iteration 75, loss = 0.35074476\n",
            "Iteration 76, loss = 0.35220462\n",
            "Iteration 77, loss = 0.35085608\n",
            "Iteration 78, loss = 0.34984207\n",
            "Iteration 79, loss = 0.35397528\n",
            "Iteration 80, loss = 0.34973252\n",
            "Iteration 81, loss = 0.34940537\n",
            "Iteration 82, loss = 0.35532476\n",
            "Iteration 83, loss = 0.34889915\n",
            "Iteration 84, loss = 0.34789067\n",
            "Iteration 85, loss = 0.34867900\n",
            "Iteration 86, loss = 0.35096782\n",
            "Iteration 87, loss = 0.34983244\n",
            "Iteration 88, loss = 0.34847057\n",
            "Iteration 89, loss = 0.35270846\n",
            "Iteration 90, loss = 0.35129858\n",
            "Iteration 91, loss = 0.35024777\n",
            "Iteration 92, loss = 0.35265092\n",
            "Iteration 93, loss = 0.34929889\n",
            "Iteration 94, loss = 0.34828055\n",
            "Iteration 95, loss = 0.34780092\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.17434932\n",
            "Iteration 2, loss = 5.81955431\n",
            "Iteration 3, loss = 4.41067948\n",
            "Iteration 4, loss = 2.85439776\n",
            "Iteration 5, loss = 1.49362839\n",
            "Iteration 6, loss = 0.51903664\n",
            "Iteration 7, loss = 0.40131908\n",
            "Iteration 8, loss = 0.39803680\n",
            "Iteration 9, loss = 0.39619405\n",
            "Iteration 10, loss = 0.39327932\n",
            "Iteration 11, loss = 0.39090001\n",
            "Iteration 12, loss = 0.38853184\n",
            "Iteration 13, loss = 0.38737197\n",
            "Iteration 14, loss = 0.38540021\n",
            "Iteration 15, loss = 0.38365344\n",
            "Iteration 16, loss = 0.38300110\n",
            "Iteration 17, loss = 0.38169422\n",
            "Iteration 18, loss = 0.37885382\n",
            "Iteration 19, loss = 0.37833176\n",
            "Iteration 20, loss = 0.37690366\n",
            "Iteration 21, loss = 0.37605513\n",
            "Iteration 22, loss = 0.37422692\n",
            "Iteration 23, loss = 0.37287177\n",
            "Iteration 24, loss = 0.37179380\n",
            "Iteration 25, loss = 0.37091982\n",
            "Iteration 26, loss = 0.37054416\n",
            "Iteration 27, loss = 0.37009991\n",
            "Iteration 28, loss = 0.36824356\n",
            "Iteration 29, loss = 0.36732819\n",
            "Iteration 30, loss = 0.36659582\n",
            "Iteration 31, loss = 0.36628582\n",
            "Iteration 32, loss = 0.36492508\n",
            "Iteration 33, loss = 0.36652900\n",
            "Iteration 34, loss = 0.36423488\n",
            "Iteration 35, loss = 0.36598029\n",
            "Iteration 36, loss = 0.36240215\n",
            "Iteration 37, loss = 0.36155784\n",
            "Iteration 38, loss = 0.36070831\n",
            "Iteration 39, loss = 0.36015338\n",
            "Iteration 40, loss = 0.35851869\n",
            "Iteration 41, loss = 0.35853463\n",
            "Iteration 42, loss = 0.35884571\n",
            "Iteration 43, loss = 0.35874425\n",
            "Iteration 44, loss = 0.35698043\n",
            "Iteration 45, loss = 0.35710811\n",
            "Iteration 46, loss = 0.35645007\n",
            "Iteration 47, loss = 0.35740514\n",
            "Iteration 48, loss = 0.35541564\n",
            "Iteration 49, loss = 0.35550258\n",
            "Iteration 50, loss = 0.35463247\n",
            "Iteration 51, loss = 0.35295451\n",
            "Iteration 52, loss = 0.35505721\n",
            "Iteration 53, loss = 0.35609825\n",
            "Iteration 54, loss = 0.35353647\n",
            "Iteration 55, loss = 0.35340675\n",
            "Iteration 56, loss = 0.35291895\n",
            "Iteration 57, loss = 0.35117085\n",
            "Iteration 58, loss = 0.35098958\n",
            "Iteration 59, loss = 0.35234811\n",
            "Iteration 60, loss = 0.35206168\n",
            "Iteration 61, loss = 0.35051021\n",
            "Iteration 62, loss = 0.35096753\n",
            "Iteration 63, loss = 0.34962761\n",
            "Iteration 64, loss = 0.35100172\n",
            "Iteration 65, loss = 0.34994234\n",
            "Iteration 66, loss = 0.34811343\n",
            "Iteration 67, loss = 0.35164936\n",
            "Iteration 68, loss = 0.34998693\n",
            "Iteration 69, loss = 0.34942529\n",
            "Iteration 70, loss = 0.34741441\n",
            "Iteration 71, loss = 0.34770236\n",
            "Iteration 72, loss = 0.34580055\n",
            "Iteration 73, loss = 0.34677979\n",
            "Iteration 74, loss = 0.34595101\n",
            "Iteration 75, loss = 0.34590570\n",
            "Iteration 76, loss = 0.34671107\n",
            "Iteration 77, loss = 0.34602867\n",
            "Iteration 78, loss = 0.34466400\n",
            "Iteration 79, loss = 0.34548913\n",
            "Iteration 80, loss = 0.34710038\n",
            "Iteration 81, loss = 0.34579242\n",
            "Iteration 82, loss = 0.34663089\n",
            "Iteration 83, loss = 0.34667712\n",
            "Iteration 84, loss = 0.34410382\n",
            "Iteration 85, loss = 0.34220630\n",
            "Iteration 86, loss = 0.34900889\n",
            "Iteration 87, loss = 0.34270701\n",
            "Iteration 88, loss = 0.34667305\n",
            "Iteration 89, loss = 0.34425915\n",
            "Iteration 90, loss = 0.34347405\n",
            "Iteration 91, loss = 0.34320881\n",
            "Iteration 92, loss = 0.34267533\n",
            "Iteration 93, loss = 0.34309540\n",
            "Iteration 94, loss = 0.34360207\n",
            "Iteration 95, loss = 0.34323486\n",
            "Iteration 96, loss = 0.34386772\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.08963036\n",
            "Iteration 2, loss = 5.55995890\n",
            "Iteration 3, loss = 3.87265943\n",
            "Iteration 4, loss = 2.19758106\n",
            "Iteration 5, loss = 0.81680670\n",
            "Iteration 6, loss = 0.39516746\n",
            "Iteration 7, loss = 0.39141406\n",
            "Iteration 8, loss = 0.38906549\n",
            "Iteration 9, loss = 0.38618567\n",
            "Iteration 10, loss = 0.38291919\n",
            "Iteration 11, loss = 0.38138077\n",
            "Iteration 12, loss = 0.37922790\n",
            "Iteration 13, loss = 0.37750438\n",
            "Iteration 14, loss = 0.37659823\n",
            "Iteration 15, loss = 0.37418316\n",
            "Iteration 16, loss = 0.37186759\n",
            "Iteration 17, loss = 0.37068615\n",
            "Iteration 18, loss = 0.36923104\n",
            "Iteration 19, loss = 0.36586703\n",
            "Iteration 20, loss = 0.36301463\n",
            "Iteration 21, loss = 0.36031671\n",
            "Iteration 22, loss = 0.35946890\n",
            "Iteration 23, loss = 0.35751096\n",
            "Iteration 24, loss = 0.35616527\n",
            "Iteration 25, loss = 0.35488593\n",
            "Iteration 26, loss = 0.35182430\n",
            "Iteration 27, loss = 0.35128155\n",
            "Iteration 28, loss = 0.34947067\n",
            "Iteration 29, loss = 0.34841005\n",
            "Iteration 30, loss = 0.34939720\n",
            "Iteration 31, loss = 0.34655974\n",
            "Iteration 32, loss = 0.35036920\n",
            "Iteration 33, loss = 0.34345497\n",
            "Iteration 34, loss = 0.34357467\n",
            "Iteration 35, loss = 0.34544214\n",
            "Iteration 36, loss = 0.34292682\n",
            "Iteration 37, loss = 0.34205984\n",
            "Iteration 38, loss = 0.34232549\n",
            "Iteration 39, loss = 0.34129934\n",
            "Iteration 40, loss = 0.34039165\n",
            "Iteration 41, loss = 0.34201095\n",
            "Iteration 42, loss = 0.33908065\n",
            "Iteration 43, loss = 0.33990967\n",
            "Iteration 44, loss = 0.33786626\n",
            "Iteration 45, loss = 0.33875347\n",
            "Iteration 46, loss = 0.33961014\n",
            "Iteration 47, loss = 0.33852301\n",
            "Iteration 48, loss = 0.33841925\n",
            "Iteration 49, loss = 0.33846440\n",
            "Iteration 50, loss = 0.33873715\n",
            "Iteration 51, loss = 0.34076492\n",
            "Iteration 52, loss = 0.33653798\n",
            "Iteration 53, loss = 0.33610437\n",
            "Iteration 54, loss = 0.33606481\n",
            "Iteration 55, loss = 0.33744040\n",
            "Iteration 56, loss = 0.33619597\n",
            "Iteration 57, loss = 0.33532566\n",
            "Iteration 58, loss = 0.33789260\n",
            "Iteration 59, loss = 0.33406670\n",
            "Iteration 60, loss = 0.33552518\n",
            "Iteration 61, loss = 0.33610181\n",
            "Iteration 62, loss = 0.33636332\n",
            "Iteration 63, loss = 0.33518348\n",
            "Iteration 64, loss = 0.33558554\n",
            "Iteration 65, loss = 0.33387486\n",
            "Iteration 66, loss = 0.33556204\n",
            "Iteration 67, loss = 0.33480094\n",
            "Iteration 68, loss = 0.33783829\n",
            "Iteration 69, loss = 0.33641588\n",
            "Iteration 70, loss = 0.33646756\n",
            "Iteration 71, loss = 0.33766334\n",
            "Iteration 72, loss = 0.33439267\n",
            "Iteration 73, loss = 0.33494760\n",
            "Iteration 74, loss = 0.33493090\n",
            "Iteration 75, loss = 0.33355619\n",
            "Iteration 76, loss = 0.33348187\n",
            "Iteration 77, loss = 0.33377963\n",
            "Iteration 78, loss = 0.33725291\n",
            "Iteration 79, loss = 0.33430056\n",
            "Iteration 80, loss = 0.33533030\n",
            "Iteration 81, loss = 0.33666168\n",
            "Iteration 82, loss = 0.33701677\n",
            "Iteration 83, loss = 0.33533195\n",
            "Iteration 84, loss = 0.33500604\n",
            "Iteration 85, loss = 0.33413041\n",
            "Iteration 86, loss = 0.33641239\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.14257444\n",
            "Iteration 2, loss = 5.29209319\n",
            "Iteration 3, loss = 3.31605419\n",
            "Iteration 4, loss = 1.51399531\n",
            "Iteration 5, loss = 0.44515587\n",
            "Iteration 6, loss = 0.39569048\n",
            "Iteration 7, loss = 0.39340418\n",
            "Iteration 8, loss = 0.38982132\n",
            "Iteration 9, loss = 0.38706676\n",
            "Iteration 10, loss = 0.38387520\n",
            "Iteration 11, loss = 0.38234426\n",
            "Iteration 12, loss = 0.37948100\n",
            "Iteration 13, loss = 0.37829929\n",
            "Iteration 14, loss = 0.37547201\n",
            "Iteration 15, loss = 0.37469814\n",
            "Iteration 16, loss = 0.37335469\n",
            "Iteration 17, loss = 0.37144155\n",
            "Iteration 18, loss = 0.36931961\n",
            "Iteration 19, loss = 0.36898167\n",
            "Iteration 20, loss = 0.36770289\n",
            "Iteration 21, loss = 0.36559037\n",
            "Iteration 22, loss = 0.36537634\n",
            "Iteration 23, loss = 0.36423525\n",
            "Iteration 24, loss = 0.36302197\n",
            "Iteration 25, loss = 0.36349393\n",
            "Iteration 26, loss = 0.36175930\n",
            "Iteration 27, loss = 0.36095081\n",
            "Iteration 28, loss = 0.36121074\n",
            "Iteration 29, loss = 0.35885864\n",
            "Iteration 30, loss = 0.36016489\n",
            "Iteration 31, loss = 0.35960342\n",
            "Iteration 32, loss = 0.35727289\n",
            "Iteration 33, loss = 0.35770517\n",
            "Iteration 34, loss = 0.35800624\n",
            "Iteration 35, loss = 0.35544061\n",
            "Iteration 36, loss = 0.35550787\n",
            "Iteration 37, loss = 0.35375585\n",
            "Iteration 38, loss = 0.35265148\n",
            "Iteration 39, loss = 0.35266582\n",
            "Iteration 40, loss = 0.35171630\n",
            "Iteration 41, loss = 0.35366591\n",
            "Iteration 42, loss = 0.35116096\n",
            "Iteration 43, loss = 0.35025999\n",
            "Iteration 44, loss = 0.35022323\n",
            "Iteration 45, loss = 0.34941394\n",
            "Iteration 46, loss = 0.35221741\n",
            "Iteration 47, loss = 0.34994714\n",
            "Iteration 48, loss = 0.34851229\n",
            "Iteration 49, loss = 0.34816016\n",
            "Iteration 50, loss = 0.34785045\n",
            "Iteration 51, loss = 0.34630768\n",
            "Iteration 52, loss = 0.34589771\n",
            "Iteration 53, loss = 0.34668342\n",
            "Iteration 54, loss = 0.34676038\n",
            "Iteration 55, loss = 0.34381171\n",
            "Iteration 56, loss = 0.34379618\n",
            "Iteration 57, loss = 0.34380018\n",
            "Iteration 58, loss = 0.34321715\n",
            "Iteration 59, loss = 0.34407853\n",
            "Iteration 60, loss = 0.34428180\n",
            "Iteration 61, loss = 0.34343251\n",
            "Iteration 62, loss = 0.34316480\n",
            "Iteration 63, loss = 0.34254785\n",
            "Iteration 64, loss = 0.34227178\n",
            "Iteration 65, loss = 0.34126040\n",
            "Iteration 66, loss = 0.34010234\n",
            "Iteration 67, loss = 0.34168823\n",
            "Iteration 68, loss = 0.33997341\n",
            "Iteration 69, loss = 0.34199821\n",
            "Iteration 70, loss = 0.34047696\n",
            "Iteration 71, loss = 0.34095815\n",
            "Iteration 72, loss = 0.33928492\n",
            "Iteration 73, loss = 0.33982544\n",
            "Iteration 74, loss = 0.34219825\n",
            "Iteration 75, loss = 0.33986282\n",
            "Iteration 76, loss = 0.33871186\n",
            "Iteration 77, loss = 0.33980946\n",
            "Iteration 78, loss = 0.33968788\n",
            "Iteration 79, loss = 0.33874104\n",
            "Iteration 80, loss = 0.33810551\n",
            "Iteration 81, loss = 0.33895947\n",
            "Iteration 82, loss = 0.33921844\n",
            "Iteration 83, loss = 0.33782908\n",
            "Iteration 84, loss = 0.33812392\n",
            "Iteration 85, loss = 0.33837735\n",
            "Iteration 86, loss = 0.33717957\n",
            "Iteration 87, loss = 0.33922241\n",
            "Iteration 88, loss = 0.33852004\n",
            "Iteration 89, loss = 0.33889277\n",
            "Iteration 90, loss = 0.33742577\n",
            "Iteration 91, loss = 0.33945287\n",
            "Iteration 92, loss = 0.33740270\n",
            "Iteration 93, loss = 0.33796366\n",
            "Iteration 94, loss = 0.33874226\n",
            "Iteration 95, loss = 0.33926210\n",
            "Iteration 96, loss = 0.33694751\n",
            "Iteration 97, loss = 0.33924185\n",
            "Iteration 98, loss = 0.33814601\n",
            "Iteration 99, loss = 0.33782272\n",
            "Iteration 100, loss = 0.33902997\n",
            "Iteration 101, loss = 0.33729240\n",
            "Iteration 102, loss = 0.33582120\n",
            "Iteration 103, loss = 0.33644409\n",
            "Iteration 104, loss = 0.33714947\n",
            "Iteration 105, loss = 0.33625824\n",
            "Iteration 106, loss = 0.33857625\n",
            "Iteration 107, loss = 0.33779699\n",
            "Iteration 108, loss = 0.33761406\n",
            "Iteration 109, loss = 0.33813901\n",
            "Iteration 110, loss = 0.33662167\n",
            "Iteration 111, loss = 0.33682153\n",
            "Iteration 112, loss = 0.33910540\n",
            "Iteration 113, loss = 0.33666100\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.07409130\n",
            "Iteration 2, loss = 5.06011242\n",
            "Iteration 3, loss = 2.99658624\n",
            "Iteration 4, loss = 1.18509158\n",
            "Iteration 5, loss = 0.40117772\n",
            "Iteration 6, loss = 0.39298947\n",
            "Iteration 7, loss = 0.39000781\n",
            "Iteration 8, loss = 0.38603052\n",
            "Iteration 9, loss = 0.38291295\n",
            "Iteration 10, loss = 0.38018878\n",
            "Iteration 11, loss = 0.37782858\n",
            "Iteration 12, loss = 0.37554477\n",
            "Iteration 13, loss = 0.37407613\n",
            "Iteration 14, loss = 0.37199935\n",
            "Iteration 15, loss = 0.37151307\n",
            "Iteration 16, loss = 0.36923150\n",
            "Iteration 17, loss = 0.36689978\n",
            "Iteration 18, loss = 0.36541496\n",
            "Iteration 19, loss = 0.36434008\n",
            "Iteration 20, loss = 0.36305498\n",
            "Iteration 21, loss = 0.36321678\n",
            "Iteration 22, loss = 0.36067402\n",
            "Iteration 23, loss = 0.36039943\n",
            "Iteration 24, loss = 0.35904638\n",
            "Iteration 25, loss = 0.35941012\n",
            "Iteration 26, loss = 0.35699525\n",
            "Iteration 27, loss = 0.35612574\n",
            "Iteration 28, loss = 0.35696406\n",
            "Iteration 29, loss = 0.35559524\n",
            "Iteration 30, loss = 0.35519209\n",
            "Iteration 31, loss = 0.35604216\n",
            "Iteration 32, loss = 0.35259005\n",
            "Iteration 33, loss = 0.35202587\n",
            "Iteration 34, loss = 0.35260865\n",
            "Iteration 35, loss = 0.35068546\n",
            "Iteration 36, loss = 0.35178014\n",
            "Iteration 37, loss = 0.35049034\n",
            "Iteration 38, loss = 0.35162433\n",
            "Iteration 39, loss = 0.34852738\n",
            "Iteration 40, loss = 0.34802793\n",
            "Iteration 41, loss = 0.34755819\n",
            "Iteration 42, loss = 0.34614271\n",
            "Iteration 43, loss = 0.34708567\n",
            "Iteration 44, loss = 0.34654619\n",
            "Iteration 45, loss = 0.34564331\n",
            "Iteration 46, loss = 0.34620085\n",
            "Iteration 47, loss = 0.34404409\n",
            "Iteration 48, loss = 0.34476896\n",
            "Iteration 49, loss = 0.34702203\n",
            "Iteration 50, loss = 0.34538623\n",
            "Iteration 51, loss = 0.34369908\n",
            "Iteration 52, loss = 0.34145561\n",
            "Iteration 53, loss = 0.34343912\n",
            "Iteration 54, loss = 0.34211223\n",
            "Iteration 55, loss = 0.34070221\n",
            "Iteration 56, loss = 0.33991823\n",
            "Iteration 57, loss = 0.34098289\n",
            "Iteration 58, loss = 0.33988997\n",
            "Iteration 59, loss = 0.34186352\n",
            "Iteration 60, loss = 0.33902049\n",
            "Iteration 61, loss = 0.34087365\n",
            "Iteration 62, loss = 0.33850336\n",
            "Iteration 63, loss = 0.33820691\n",
            "Iteration 64, loss = 0.34098152\n",
            "Iteration 65, loss = 0.33781828\n",
            "Iteration 66, loss = 0.33699229\n",
            "Iteration 67, loss = 0.34005958\n",
            "Iteration 68, loss = 0.33747213\n",
            "Iteration 69, loss = 0.33736339\n",
            "Iteration 70, loss = 0.33771453\n",
            "Iteration 71, loss = 0.33830607\n",
            "Iteration 72, loss = 0.33682084\n",
            "Iteration 73, loss = 0.33889456\n",
            "Iteration 74, loss = 0.33525220\n",
            "Iteration 75, loss = 0.33648147\n",
            "Iteration 76, loss = 0.33935374\n",
            "Iteration 77, loss = 0.33589044\n",
            "Iteration 78, loss = 0.33628435\n",
            "Iteration 79, loss = 0.33461374\n",
            "Iteration 80, loss = 0.33563860\n",
            "Iteration 81, loss = 0.33892388\n",
            "Iteration 82, loss = 0.33446235\n",
            "Iteration 83, loss = 0.33557900\n",
            "Iteration 84, loss = 0.33474736\n",
            "Iteration 85, loss = 0.33550244\n",
            "Iteration 86, loss = 0.33381717\n",
            "Iteration 87, loss = 0.33500596\n",
            "Iteration 88, loss = 0.33522341\n",
            "Iteration 89, loss = 0.33424022\n",
            "Iteration 90, loss = 0.33467610\n",
            "Iteration 91, loss = 0.33530523\n",
            "Iteration 92, loss = 0.33549435\n",
            "Iteration 93, loss = 0.33370085\n",
            "Iteration 94, loss = 0.33597689\n",
            "Iteration 95, loss = 0.33339245\n",
            "Iteration 96, loss = 0.33510159\n",
            "Iteration 97, loss = 0.33496265\n",
            "Iteration 98, loss = 0.33576871\n",
            "Iteration 99, loss = 0.33616747\n",
            "Iteration 100, loss = 0.33615629\n",
            "Iteration 101, loss = 0.33382781\n",
            "Iteration 102, loss = 0.33478891\n",
            "Iteration 103, loss = 0.33420027\n",
            "Iteration 104, loss = 0.33441936\n",
            "Iteration 105, loss = 0.33457781\n",
            "Iteration 106, loss = 0.33389630\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.09935130\n",
            "Iteration 2, loss = 5.05869834\n",
            "Iteration 3, loss = 2.92781769\n",
            "Iteration 4, loss = 1.07073920\n",
            "Iteration 5, loss = 0.39672399\n",
            "Iteration 6, loss = 0.39148507\n",
            "Iteration 7, loss = 0.38886294\n",
            "Iteration 8, loss = 0.38455357\n",
            "Iteration 9, loss = 0.38214179\n",
            "Iteration 10, loss = 0.37949180\n",
            "Iteration 11, loss = 0.37683595\n",
            "Iteration 12, loss = 0.37446021\n",
            "Iteration 13, loss = 0.37276254\n",
            "Iteration 14, loss = 0.37134275\n",
            "Iteration 15, loss = 0.36828299\n",
            "Iteration 16, loss = 0.36707347\n",
            "Iteration 17, loss = 0.36583187\n",
            "Iteration 18, loss = 0.36630190\n",
            "Iteration 19, loss = 0.36382275\n",
            "Iteration 20, loss = 0.36232849\n",
            "Iteration 21, loss = 0.36107525\n",
            "Iteration 22, loss = 0.36063782\n",
            "Iteration 23, loss = 0.35879590\n",
            "Iteration 24, loss = 0.35961021\n",
            "Iteration 25, loss = 0.35874718\n",
            "Iteration 26, loss = 0.35618108\n",
            "Iteration 27, loss = 0.35559194\n",
            "Iteration 28, loss = 0.35494558\n",
            "Iteration 29, loss = 0.35540367\n",
            "Iteration 30, loss = 0.35673650\n",
            "Iteration 31, loss = 0.35534836\n",
            "Iteration 32, loss = 0.35325055\n",
            "Iteration 33, loss = 0.35096832\n",
            "Iteration 34, loss = 0.35103446\n",
            "Iteration 35, loss = 0.35046321\n",
            "Iteration 36, loss = 0.34936353\n",
            "Iteration 37, loss = 0.34862693\n",
            "Iteration 38, loss = 0.34852602\n",
            "Iteration 39, loss = 0.34828214\n",
            "Iteration 40, loss = 0.34721710\n",
            "Iteration 41, loss = 0.34671378\n",
            "Iteration 42, loss = 0.34670909\n",
            "Iteration 43, loss = 0.34566162\n",
            "Iteration 44, loss = 0.34589234\n",
            "Iteration 45, loss = 0.34471242\n",
            "Iteration 46, loss = 0.34427926\n",
            "Iteration 47, loss = 0.34357806\n",
            "Iteration 48, loss = 0.34242439\n",
            "Iteration 49, loss = 0.34335801\n",
            "Iteration 50, loss = 0.34297649\n",
            "Iteration 51, loss = 0.34424729\n",
            "Iteration 52, loss = 0.34178319\n",
            "Iteration 53, loss = 0.34329651\n",
            "Iteration 54, loss = 0.34026509\n",
            "Iteration 55, loss = 0.34028880\n",
            "Iteration 56, loss = 0.34042024\n",
            "Iteration 57, loss = 0.33894101\n",
            "Iteration 58, loss = 0.33910113\n",
            "Iteration 59, loss = 0.33868333\n",
            "Iteration 60, loss = 0.33835335\n",
            "Iteration 61, loss = 0.33761258\n",
            "Iteration 62, loss = 0.33853334\n",
            "Iteration 63, loss = 0.33799114\n",
            "Iteration 64, loss = 0.33698836\n",
            "Iteration 65, loss = 0.33859846\n",
            "Iteration 66, loss = 0.33786338\n",
            "Iteration 67, loss = 0.33708248\n",
            "Iteration 68, loss = 0.33661838\n",
            "Iteration 69, loss = 0.33654973\n",
            "Iteration 70, loss = 0.33557315\n",
            "Iteration 71, loss = 0.33558285\n",
            "Iteration 72, loss = 0.33639714\n",
            "Iteration 73, loss = 0.33737854\n",
            "Iteration 74, loss = 0.33640592\n",
            "Iteration 75, loss = 0.33626887\n",
            "Iteration 76, loss = 0.33488190\n",
            "Iteration 77, loss = 0.33472913\n",
            "Iteration 78, loss = 0.33912526\n",
            "Iteration 79, loss = 0.33781103\n",
            "Iteration 80, loss = 0.33475695\n",
            "Iteration 81, loss = 0.33558987\n",
            "Iteration 82, loss = 0.33518661\n",
            "Iteration 83, loss = 0.33538903\n",
            "Iteration 84, loss = 0.33740350\n",
            "Iteration 85, loss = 0.33371164\n",
            "Iteration 86, loss = 0.33478514\n",
            "Iteration 87, loss = 0.33464578\n",
            "Iteration 88, loss = 0.33760114\n",
            "Iteration 89, loss = 0.33367015\n",
            "Iteration 90, loss = 0.33450056\n",
            "Iteration 91, loss = 0.33830030\n",
            "Iteration 92, loss = 0.33295039\n",
            "Iteration 93, loss = 0.33373163\n",
            "Iteration 94, loss = 0.33421526\n",
            "Iteration 95, loss = 0.33382394\n",
            "Iteration 96, loss = 0.33477186\n",
            "Iteration 97, loss = 0.33375036\n",
            "Iteration 98, loss = 0.33406480\n",
            "Iteration 99, loss = 0.33419862\n",
            "Iteration 100, loss = 0.33465739\n",
            "Iteration 101, loss = 0.33336242\n",
            "Iteration 102, loss = 0.33399875\n",
            "Iteration 103, loss = 0.33519846\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.05679964\n",
            "Iteration 2, loss = 4.95172987\n",
            "Iteration 3, loss = 2.76134216\n",
            "Iteration 4, loss = 0.93634123\n",
            "Iteration 5, loss = 0.39186131\n",
            "Iteration 6, loss = 0.38771344\n",
            "Iteration 7, loss = 0.38523430\n",
            "Iteration 8, loss = 0.38212432\n",
            "Iteration 9, loss = 0.38010548\n",
            "Iteration 10, loss = 0.37666773\n",
            "Iteration 11, loss = 0.37426969\n",
            "Iteration 12, loss = 0.37143736\n",
            "Iteration 13, loss = 0.37150960\n",
            "Iteration 14, loss = 0.37113370\n",
            "Iteration 15, loss = 0.36721825\n",
            "Iteration 16, loss = 0.36624030\n",
            "Iteration 17, loss = 0.36403076\n",
            "Iteration 18, loss = 0.36222175\n",
            "Iteration 19, loss = 0.36154470\n",
            "Iteration 20, loss = 0.36039691\n",
            "Iteration 21, loss = 0.35931794\n",
            "Iteration 22, loss = 0.35789952\n",
            "Iteration 23, loss = 0.35741154\n",
            "Iteration 24, loss = 0.35823004\n",
            "Iteration 25, loss = 0.35640572\n",
            "Iteration 26, loss = 0.35559651\n",
            "Iteration 27, loss = 0.35407789\n",
            "Iteration 28, loss = 0.35361079\n",
            "Iteration 29, loss = 0.35187780\n",
            "Iteration 30, loss = 0.35211545\n",
            "Iteration 31, loss = 0.35129268\n",
            "Iteration 32, loss = 0.35071390\n",
            "Iteration 33, loss = 0.34963423\n",
            "Iteration 34, loss = 0.34979555\n",
            "Iteration 35, loss = 0.34685283\n",
            "Iteration 36, loss = 0.35033225\n",
            "Iteration 37, loss = 0.34726208\n",
            "Iteration 38, loss = 0.34591899\n",
            "Iteration 39, loss = 0.34596284\n",
            "Iteration 40, loss = 0.34889362\n",
            "Iteration 41, loss = 0.34551645\n",
            "Iteration 42, loss = 0.34393032\n",
            "Iteration 43, loss = 0.34333006\n",
            "Iteration 44, loss = 0.34261918\n",
            "Iteration 45, loss = 0.34446026\n",
            "Iteration 46, loss = 0.34277410\n",
            "Iteration 47, loss = 0.34268402\n",
            "Iteration 48, loss = 0.34936728\n",
            "Iteration 49, loss = 0.34253748\n",
            "Iteration 50, loss = 0.34135088\n",
            "Iteration 51, loss = 0.34176919\n",
            "Iteration 52, loss = 0.34076166\n",
            "Iteration 53, loss = 0.34080034\n",
            "Iteration 54, loss = 0.33878641\n",
            "Iteration 55, loss = 0.33864202\n",
            "Iteration 56, loss = 0.34021572\n",
            "Iteration 57, loss = 0.33758079\n",
            "Iteration 58, loss = 0.34086573\n",
            "Iteration 59, loss = 0.34002593\n",
            "Iteration 60, loss = 0.33752485\n",
            "Iteration 61, loss = 0.33798293\n",
            "Iteration 62, loss = 0.33813213\n",
            "Iteration 63, loss = 0.33673754\n",
            "Iteration 64, loss = 0.33616998\n",
            "Iteration 65, loss = 0.33547200\n",
            "Iteration 66, loss = 0.33837080\n",
            "Iteration 67, loss = 0.33681155\n",
            "Iteration 68, loss = 0.33726086\n",
            "Iteration 69, loss = 0.33626531\n",
            "Iteration 70, loss = 0.33725773\n",
            "Iteration 71, loss = 0.33526976\n",
            "Iteration 72, loss = 0.33470836\n",
            "Iteration 73, loss = 0.33461138\n",
            "Iteration 74, loss = 0.33495173\n",
            "Iteration 75, loss = 0.33451558\n",
            "Iteration 76, loss = 0.33412577\n",
            "Iteration 77, loss = 0.33438098\n",
            "Iteration 78, loss = 0.33532707\n",
            "Iteration 79, loss = 0.33379061\n",
            "Iteration 80, loss = 0.33476197\n",
            "Iteration 81, loss = 0.33409264\n",
            "Iteration 82, loss = 0.33464637\n",
            "Iteration 83, loss = 0.33497236\n",
            "Iteration 84, loss = 0.33962978\n",
            "Iteration 85, loss = 0.33630030\n",
            "Iteration 86, loss = 0.33261418\n",
            "Iteration 87, loss = 0.33532731\n",
            "Iteration 88, loss = 0.33427077\n",
            "Iteration 89, loss = 0.33238112\n",
            "Iteration 90, loss = 0.33333947\n",
            "Iteration 91, loss = 0.33318652\n",
            "Iteration 92, loss = 0.33378702\n",
            "Iteration 93, loss = 0.33215247\n",
            "Iteration 94, loss = 0.33326782\n",
            "Iteration 95, loss = 0.33301879\n",
            "Iteration 96, loss = 0.33306943\n",
            "Iteration 97, loss = 0.33450818\n",
            "Iteration 98, loss = 0.33377626\n",
            "Iteration 99, loss = 0.33325452\n",
            "Iteration 100, loss = 0.33477650\n",
            "Iteration 101, loss = 0.33383401\n",
            "Iteration 102, loss = 0.33363752\n",
            "Iteration 103, loss = 0.33410539\n",
            "Iteration 104, loss = 0.33450538\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 7.12871227\n",
            "Iteration 2, loss = 7.12871084\n",
            "Iteration 3, loss = 7.12870984\n",
            "Iteration 4, loss = 7.12870887\n",
            "Iteration 5, loss = 7.12870795\n",
            "Iteration 6, loss = 7.12870710\n",
            "Iteration 7, loss = 7.12326389\n",
            "Iteration 8, loss = 7.11366449\n",
            "Iteration 9, loss = 7.08524052\n",
            "Iteration 10, loss = 6.99997215\n",
            "Iteration 11, loss = 6.82840886\n",
            "Iteration 12, loss = 6.63423915\n",
            "Iteration 13, loss = 6.40248963\n",
            "Iteration 14, loss = 6.18902270\n",
            "Iteration 15, loss = 5.95555111\n",
            "Iteration 16, loss = 5.70170004\n",
            "Iteration 17, loss = 5.43992137\n",
            "Iteration 18, loss = 5.20353722\n",
            "Iteration 19, loss = 4.90711011\n",
            "Iteration 20, loss = 4.62354722\n",
            "Iteration 21, loss = 4.36421015\n",
            "Iteration 22, loss = 4.10945002\n",
            "Iteration 23, loss = 3.88284634\n",
            "Iteration 24, loss = 3.67157006\n",
            "Iteration 25, loss = 3.46670020\n",
            "Iteration 26, loss = 3.26515925\n",
            "Iteration 27, loss = 3.06672200\n",
            "Iteration 28, loss = 2.86751272\n",
            "Iteration 29, loss = 2.65983611\n",
            "Iteration 30, loss = 2.43277249\n",
            "Iteration 31, loss = 2.24936322\n",
            "Iteration 32, loss = 2.05645192\n",
            "Iteration 33, loss = 1.87519165\n",
            "Iteration 34, loss = 1.66219379\n",
            "Iteration 35, loss = 1.42937371\n",
            "Iteration 36, loss = 1.21158903\n",
            "Iteration 37, loss = 1.03048222\n",
            "Iteration 38, loss = 0.86800187\n",
            "Iteration 39, loss = 0.72808006\n",
            "Iteration 40, loss = 0.60686738\n",
            "Iteration 41, loss = 0.50085192\n",
            "Iteration 42, loss = 0.43852106\n",
            "Iteration 43, loss = 0.41636091\n",
            "Iteration 44, loss = 0.41370314\n",
            "Iteration 45, loss = 0.41422365\n",
            "Iteration 46, loss = 0.41451525\n",
            "Iteration 47, loss = 0.41305881\n",
            "Iteration 48, loss = 0.41156806\n",
            "Iteration 49, loss = 0.41262791\n",
            "Iteration 50, loss = 0.41128049\n",
            "Iteration 51, loss = 0.41231135\n",
            "Iteration 52, loss = 0.41568337\n",
            "Iteration 53, loss = 0.41752627\n",
            "Iteration 54, loss = 0.41368167\n",
            "Iteration 55, loss = 0.41031644\n",
            "Iteration 56, loss = 0.41100702\n",
            "Iteration 57, loss = 0.41162943\n",
            "Iteration 58, loss = 0.41106364\n",
            "Iteration 59, loss = 0.41048469\n",
            "Iteration 60, loss = 0.40919025\n",
            "Iteration 61, loss = 0.40944030\n",
            "Iteration 62, loss = 0.40913917\n",
            "Iteration 63, loss = 0.40855511\n",
            "Iteration 64, loss = 0.40745280\n",
            "Iteration 65, loss = 0.40725656\n",
            "Iteration 66, loss = 0.40702935\n",
            "Iteration 67, loss = 0.40707261\n",
            "Iteration 68, loss = 0.40665097\n",
            "Iteration 69, loss = 0.40650843\n",
            "Iteration 70, loss = 0.40713841\n",
            "Iteration 71, loss = 0.40997868\n",
            "Iteration 72, loss = 0.40986378\n",
            "Iteration 73, loss = 0.40625678\n",
            "Iteration 74, loss = 0.40550245\n",
            "Iteration 75, loss = 0.40588079\n",
            "Iteration 76, loss = 0.40456398\n",
            "Iteration 77, loss = 0.40542413\n",
            "Iteration 78, loss = 0.40387889\n",
            "Iteration 79, loss = 0.40478233\n",
            "Iteration 80, loss = 0.40442680\n",
            "Iteration 81, loss = 0.40630176\n",
            "Iteration 82, loss = 0.40431827\n",
            "Iteration 83, loss = 0.40408979\n",
            "Iteration 84, loss = 0.40417521\n",
            "Iteration 85, loss = 0.40262899\n",
            "Iteration 86, loss = 0.40133824\n",
            "Iteration 87, loss = 0.40619612\n",
            "Iteration 88, loss = 0.40826907\n",
            "Iteration 89, loss = 0.40604399\n",
            "Iteration 90, loss = 0.40403006\n",
            "Iteration 91, loss = 0.40302739\n",
            "Iteration 92, loss = 0.40190401\n",
            "Iteration 93, loss = 0.40091299\n",
            "Iteration 94, loss = 0.40069091\n",
            "Iteration 95, loss = 0.39994617\n",
            "Iteration 96, loss = 0.39858024\n",
            "Iteration 97, loss = 0.39893025\n",
            "Iteration 98, loss = 0.40053014\n",
            "Iteration 99, loss = 0.39956487\n",
            "Iteration 100, loss = 0.39847690\n",
            "Iteration 101, loss = 0.39827341\n",
            "Iteration 102, loss = 0.40337979\n",
            "Iteration 103, loss = 0.40932385\n",
            "Iteration 104, loss = 0.40422460\n",
            "Iteration 105, loss = 0.39708892\n",
            "Iteration 106, loss = 0.39714801\n",
            "Iteration 107, loss = 0.39693382\n",
            "Iteration 108, loss = 0.39790630\n",
            "Iteration 109, loss = 0.39765917\n",
            "Iteration 110, loss = 0.39797444\n",
            "Iteration 111, loss = 0.39761938\n",
            "Iteration 112, loss = 0.39742277\n",
            "Iteration 113, loss = 0.39709786\n",
            "Iteration 114, loss = 0.39733830\n",
            "Iteration 115, loss = 0.39702180\n",
            "Iteration 116, loss = 0.39567857\n",
            "Iteration 117, loss = 0.39515490\n",
            "Iteration 118, loss = 0.39567486\n",
            "Iteration 119, loss = 0.39501245\n",
            "Iteration 120, loss = 0.39604059\n",
            "Iteration 121, loss = 0.39538544\n",
            "Iteration 122, loss = 0.39627794\n",
            "Iteration 123, loss = 0.39843097\n",
            "Iteration 124, loss = 0.39458984\n",
            "Iteration 125, loss = 0.39467048\n",
            "Iteration 126, loss = 0.39537428\n",
            "Iteration 127, loss = 0.39538237\n",
            "Iteration 128, loss = 0.39342931\n",
            "Iteration 129, loss = 0.39320360\n",
            "Iteration 130, loss = 0.39353775\n",
            "Iteration 131, loss = 0.39386720\n",
            "Iteration 132, loss = 0.39544931\n",
            "Iteration 133, loss = 0.39694526\n",
            "Iteration 134, loss = 0.39642286\n",
            "Iteration 135, loss = 0.39571575\n",
            "Iteration 136, loss = 0.39566995\n",
            "Iteration 137, loss = 0.39450027\n",
            "Iteration 138, loss = 0.39271671\n",
            "Iteration 139, loss = 0.39363567\n",
            "Iteration 140, loss = 0.39214012\n",
            "Iteration 141, loss = 0.39386617\n",
            "Iteration 142, loss = 0.39057489\n",
            "Iteration 143, loss = 0.39342736\n",
            "Iteration 144, loss = 0.39229663\n",
            "Iteration 145, loss = 0.39165375\n",
            "Iteration 146, loss = 0.39196404\n",
            "Iteration 147, loss = 0.39156994\n",
            "Iteration 148, loss = 0.39185634\n",
            "Iteration 149, loss = 0.39042741\n",
            "Iteration 150, loss = 0.39047749\n",
            "Iteration 151, loss = 0.39065773\n",
            "Iteration 152, loss = 0.38979801\n",
            "Iteration 153, loss = 0.39035610\n",
            "Iteration 154, loss = 0.39083206\n",
            "Iteration 155, loss = 0.39271657\n",
            "Iteration 156, loss = 0.38762988\n",
            "Iteration 157, loss = 0.39062057\n",
            "Iteration 158, loss = 0.39034548\n",
            "Iteration 159, loss = 0.38799530\n",
            "Iteration 160, loss = 0.38872389\n",
            "Iteration 161, loss = 0.39020709\n",
            "Iteration 162, loss = 0.39590603\n",
            "Iteration 163, loss = 0.39203399\n",
            "Iteration 164, loss = 0.39248236\n",
            "Iteration 165, loss = 0.39671613\n",
            "Iteration 166, loss = 0.39377784\n",
            "Iteration 167, loss = 0.38975269\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.88841557\n",
            "Iteration 2, loss = 6.88841299\n",
            "Iteration 3, loss = 6.88590458\n",
            "Iteration 4, loss = 6.87140796\n",
            "Iteration 5, loss = 6.69285463\n",
            "Iteration 6, loss = 6.30240000\n",
            "Iteration 7, loss = 5.83356034\n",
            "Iteration 8, loss = 5.32590150\n",
            "Iteration 9, loss = 4.79425849\n",
            "Iteration 10, loss = 4.27262644\n",
            "Iteration 11, loss = 3.76717927\n",
            "Iteration 12, loss = 3.29727189\n",
            "Iteration 13, loss = 2.83471411\n",
            "Iteration 14, loss = 2.42576721\n",
            "Iteration 15, loss = 2.02818363\n",
            "Iteration 16, loss = 1.64410634\n",
            "Iteration 17, loss = 1.27330443\n",
            "Iteration 18, loss = 0.91752736\n",
            "Iteration 19, loss = 0.61458840\n",
            "Iteration 20, loss = 0.44861847\n",
            "Iteration 21, loss = 0.43188421\n",
            "Iteration 22, loss = 0.43051718\n",
            "Iteration 23, loss = 0.43109445\n",
            "Iteration 24, loss = 0.42796550\n",
            "Iteration 25, loss = 0.42606025\n",
            "Iteration 26, loss = 0.42519725\n",
            "Iteration 27, loss = 0.42487784\n",
            "Iteration 28, loss = 0.42608287\n",
            "Iteration 29, loss = 0.42377914\n",
            "Iteration 30, loss = 0.42359999\n",
            "Iteration 31, loss = 0.42579266\n",
            "Iteration 32, loss = 0.42642845\n",
            "Iteration 33, loss = 0.42192923\n",
            "Iteration 34, loss = 0.42166754\n",
            "Iteration 35, loss = 0.41985692\n",
            "Iteration 36, loss = 0.41980653\n",
            "Iteration 37, loss = 0.41912417\n",
            "Iteration 38, loss = 0.41858041\n",
            "Iteration 39, loss = 0.41848925\n",
            "Iteration 40, loss = 0.41820831\n",
            "Iteration 41, loss = 0.41747357\n",
            "Iteration 42, loss = 0.41650998\n",
            "Iteration 43, loss = 0.41589364\n",
            "Iteration 44, loss = 0.41663739\n",
            "Iteration 45, loss = 0.41532824\n",
            "Iteration 46, loss = 0.41459672\n",
            "Iteration 47, loss = 0.41399724\n",
            "Iteration 48, loss = 0.41358999\n",
            "Iteration 49, loss = 0.41649552\n",
            "Iteration 50, loss = 0.41212059\n",
            "Iteration 51, loss = 0.41430124\n",
            "Iteration 52, loss = 0.41188774\n",
            "Iteration 53, loss = 0.41037284\n",
            "Iteration 54, loss = 0.41254508\n",
            "Iteration 55, loss = 0.41071802\n",
            "Iteration 56, loss = 0.41081769\n",
            "Iteration 57, loss = 0.41303598\n",
            "Iteration 58, loss = 0.41076042\n",
            "Iteration 59, loss = 0.40908790\n",
            "Iteration 60, loss = 0.40884713\n",
            "Iteration 61, loss = 0.40885915\n",
            "Iteration 62, loss = 0.40807583\n",
            "Iteration 63, loss = 0.40746826\n",
            "Iteration 64, loss = 0.40784650\n",
            "Iteration 65, loss = 0.40681604\n",
            "Iteration 66, loss = 0.40642529\n",
            "Iteration 67, loss = 0.40590356\n",
            "Iteration 68, loss = 0.40598873\n",
            "Iteration 69, loss = 0.40509396\n",
            "Iteration 70, loss = 0.40730725\n",
            "Iteration 71, loss = 0.40461315\n",
            "Iteration 72, loss = 0.40447111\n",
            "Iteration 73, loss = 0.40366540\n",
            "Iteration 74, loss = 0.40611768\n",
            "Iteration 75, loss = 0.40763359\n",
            "Iteration 76, loss = 0.40351927\n",
            "Iteration 77, loss = 0.40260919\n",
            "Iteration 78, loss = 0.40209491\n",
            "Iteration 79, loss = 0.40147143\n",
            "Iteration 80, loss = 0.40076799\n",
            "Iteration 81, loss = 0.40550526\n",
            "Iteration 82, loss = 0.40043574\n",
            "Iteration 83, loss = 0.39985327\n",
            "Iteration 84, loss = 0.40474788\n",
            "Iteration 85, loss = 0.40002239\n",
            "Iteration 86, loss = 0.39865565\n",
            "Iteration 87, loss = 0.39913902\n",
            "Iteration 88, loss = 0.39848621\n",
            "Iteration 89, loss = 0.39861231\n",
            "Iteration 90, loss = 0.39738206\n",
            "Iteration 91, loss = 0.39819313\n",
            "Iteration 92, loss = 0.39869431\n",
            "Iteration 93, loss = 0.39671090\n",
            "Iteration 94, loss = 0.39806494\n",
            "Iteration 95, loss = 0.39664781\n",
            "Iteration 96, loss = 0.39728316\n",
            "Iteration 97, loss = 0.39654073\n",
            "Iteration 98, loss = 0.39730214\n",
            "Iteration 99, loss = 0.39563344\n",
            "Iteration 100, loss = 0.39522642\n",
            "Iteration 101, loss = 0.39504194\n",
            "Iteration 102, loss = 0.39399844\n",
            "Iteration 103, loss = 0.39410640\n",
            "Iteration 104, loss = 0.39402297\n",
            "Iteration 105, loss = 0.39476692\n",
            "Iteration 106, loss = 0.39378251\n",
            "Iteration 107, loss = 0.39278388\n",
            "Iteration 108, loss = 0.39633373\n",
            "Iteration 109, loss = 0.39213954\n",
            "Iteration 110, loss = 0.39438791\n",
            "Iteration 111, loss = 0.39395294\n",
            "Iteration 112, loss = 0.39218867\n",
            "Iteration 113, loss = 0.39145335\n",
            "Iteration 114, loss = 0.39178432\n",
            "Iteration 115, loss = 0.39554411\n",
            "Iteration 116, loss = 0.39043291\n",
            "Iteration 117, loss = 0.39148855\n",
            "Iteration 118, loss = 0.39087955\n",
            "Iteration 119, loss = 0.39357477\n",
            "Iteration 120, loss = 0.39169458\n",
            "Iteration 121, loss = 0.39159179\n",
            "Iteration 122, loss = 0.38988586\n",
            "Iteration 123, loss = 0.38940125\n",
            "Iteration 124, loss = 0.38932009\n",
            "Iteration 125, loss = 0.38949155\n",
            "Iteration 126, loss = 0.38887263\n",
            "Iteration 127, loss = 0.38926921\n",
            "Iteration 128, loss = 0.38901051\n",
            "Iteration 129, loss = 0.39074775\n",
            "Iteration 130, loss = 0.38868705\n",
            "Iteration 131, loss = 0.38940099\n",
            "Iteration 132, loss = 0.38788378\n",
            "Iteration 133, loss = 0.38908563\n",
            "Iteration 134, loss = 0.38690754\n",
            "Iteration 135, loss = 0.38697162\n",
            "Iteration 136, loss = 0.38990769\n",
            "Iteration 137, loss = 0.39280119\n",
            "Iteration 138, loss = 0.39021450\n",
            "Iteration 139, loss = 0.38793700\n",
            "Iteration 140, loss = 0.39306321\n",
            "Iteration 141, loss = 0.38622359\n",
            "Iteration 142, loss = 0.38902204\n",
            "Iteration 143, loss = 0.38743874\n",
            "Iteration 144, loss = 0.38769719\n",
            "Iteration 145, loss = 0.38883753\n",
            "Iteration 146, loss = 0.38753171\n",
            "Iteration 147, loss = 0.38610580\n",
            "Iteration 148, loss = 0.38692537\n",
            "Iteration 149, loss = 0.38447314\n",
            "Iteration 150, loss = 0.38758978\n",
            "Iteration 151, loss = 0.38914216\n",
            "Iteration 152, loss = 0.38915681\n",
            "Iteration 153, loss = 0.38953872\n",
            "Iteration 154, loss = 0.38440939\n",
            "Iteration 155, loss = 0.38703313\n",
            "Iteration 156, loss = 0.38384453\n",
            "Iteration 157, loss = 0.38390918\n",
            "Iteration 158, loss = 0.38346736\n",
            "Iteration 159, loss = 0.38455374\n",
            "Iteration 160, loss = 0.38757367\n",
            "Iteration 161, loss = 0.38670003\n",
            "Iteration 162, loss = 0.38482421\n",
            "Iteration 163, loss = 0.38438066\n",
            "Iteration 164, loss = 0.38355825\n",
            "Iteration 165, loss = 0.38804175\n",
            "Iteration 166, loss = 0.38256213\n",
            "Iteration 167, loss = 0.38392714\n",
            "Iteration 168, loss = 0.38592754\n",
            "Iteration 169, loss = 0.38224906\n",
            "Iteration 170, loss = 0.38232458\n",
            "Iteration 171, loss = 0.38370611\n",
            "Iteration 172, loss = 0.38505964\n",
            "Iteration 173, loss = 0.38333426\n",
            "Iteration 174, loss = 0.38224712\n",
            "Iteration 175, loss = 0.38217530\n",
            "Iteration 176, loss = 0.39391597\n",
            "Iteration 177, loss = 0.38969316\n",
            "Iteration 178, loss = 0.38402904\n",
            "Iteration 179, loss = 0.38407692\n",
            "Iteration 180, loss = 0.39048847\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.37650962\n",
            "Iteration 2, loss = 6.37460461\n",
            "Iteration 3, loss = 6.32679594\n",
            "Iteration 4, loss = 5.92811639\n",
            "Iteration 5, loss = 5.30490966\n",
            "Iteration 6, loss = 4.61306721\n",
            "Iteration 7, loss = 3.92598686\n",
            "Iteration 8, loss = 3.29140923\n",
            "Iteration 9, loss = 2.67424447\n",
            "Iteration 10, loss = 2.09449039\n",
            "Iteration 11, loss = 1.54866118\n",
            "Iteration 12, loss = 1.01400260\n",
            "Iteration 13, loss = 0.58389157\n",
            "Iteration 14, loss = 0.41891242\n",
            "Iteration 15, loss = 0.40911573\n",
            "Iteration 16, loss = 0.40776618\n",
            "Iteration 17, loss = 0.40643129\n",
            "Iteration 18, loss = 0.40648356\n",
            "Iteration 19, loss = 0.40743940\n",
            "Iteration 20, loss = 0.40495034\n",
            "Iteration 21, loss = 0.40376984\n",
            "Iteration 22, loss = 0.40296235\n",
            "Iteration 23, loss = 0.40153679\n",
            "Iteration 24, loss = 0.40049780\n",
            "Iteration 25, loss = 0.40000737\n",
            "Iteration 26, loss = 0.39855980\n",
            "Iteration 27, loss = 0.39797752\n",
            "Iteration 28, loss = 0.39622774\n",
            "Iteration 29, loss = 0.39679382\n",
            "Iteration 30, loss = 0.39559501\n",
            "Iteration 31, loss = 0.39523484\n",
            "Iteration 32, loss = 0.39345231\n",
            "Iteration 33, loss = 0.39290780\n",
            "Iteration 34, loss = 0.39236696\n",
            "Iteration 35, loss = 0.39273773\n",
            "Iteration 36, loss = 0.39101039\n",
            "Iteration 37, loss = 0.39121177\n",
            "Iteration 38, loss = 0.39001838\n",
            "Iteration 39, loss = 0.38929849\n",
            "Iteration 40, loss = 0.38837547\n",
            "Iteration 41, loss = 0.38934197\n",
            "Iteration 42, loss = 0.38836631\n",
            "Iteration 43, loss = 0.38789092\n",
            "Iteration 44, loss = 0.38591491\n",
            "Iteration 45, loss = 0.38566486\n",
            "Iteration 46, loss = 0.38585822\n",
            "Iteration 47, loss = 0.38451378\n",
            "Iteration 48, loss = 0.38482283\n",
            "Iteration 49, loss = 0.38355496\n",
            "Iteration 50, loss = 0.38353965\n",
            "Iteration 51, loss = 0.38273613\n",
            "Iteration 52, loss = 0.38343661\n",
            "Iteration 53, loss = 0.38584350\n",
            "Iteration 54, loss = 0.38379468\n",
            "Iteration 55, loss = 0.38174325\n",
            "Iteration 56, loss = 0.38092883\n",
            "Iteration 57, loss = 0.38007554\n",
            "Iteration 58, loss = 0.37978973\n",
            "Iteration 59, loss = 0.37941844\n",
            "Iteration 60, loss = 0.38261379\n",
            "Iteration 61, loss = 0.38072581\n",
            "Iteration 62, loss = 0.37945365\n",
            "Iteration 63, loss = 0.37736865\n",
            "Iteration 64, loss = 0.37827065\n",
            "Iteration 65, loss = 0.37735031\n",
            "Iteration 66, loss = 0.37771741\n",
            "Iteration 67, loss = 0.37697124\n",
            "Iteration 68, loss = 0.37562851\n",
            "Iteration 69, loss = 0.37495570\n",
            "Iteration 70, loss = 0.37553384\n",
            "Iteration 71, loss = 0.37428178\n",
            "Iteration 72, loss = 0.37473865\n",
            "Iteration 73, loss = 0.37444509\n",
            "Iteration 74, loss = 0.37248273\n",
            "Iteration 75, loss = 0.37359084\n",
            "Iteration 76, loss = 0.37283504\n",
            "Iteration 77, loss = 0.37175260\n",
            "Iteration 78, loss = 0.37227226\n",
            "Iteration 79, loss = 0.37563532\n",
            "Iteration 80, loss = 0.37628531\n",
            "Iteration 81, loss = 0.37267160\n",
            "Iteration 82, loss = 0.37167191\n",
            "Iteration 83, loss = 0.37044586\n",
            "Iteration 84, loss = 0.37106079\n",
            "Iteration 85, loss = 0.37008737\n",
            "Iteration 86, loss = 0.37178660\n",
            "Iteration 87, loss = 0.36950053\n",
            "Iteration 88, loss = 0.37000429\n",
            "Iteration 89, loss = 0.37002825\n",
            "Iteration 90, loss = 0.36915426\n",
            "Iteration 91, loss = 0.37138916\n",
            "Iteration 92, loss = 0.37001261\n",
            "Iteration 93, loss = 0.36946653\n",
            "Iteration 94, loss = 0.36964929\n",
            "Iteration 95, loss = 0.36799287\n",
            "Iteration 96, loss = 0.36793468\n",
            "Iteration 97, loss = 0.36771439\n",
            "Iteration 98, loss = 0.36750946\n",
            "Iteration 99, loss = 0.36682998\n",
            "Iteration 100, loss = 0.36622164\n",
            "Iteration 101, loss = 0.36762336\n",
            "Iteration 102, loss = 0.36801260\n",
            "Iteration 103, loss = 0.36642067\n",
            "Iteration 104, loss = 0.36638068\n",
            "Iteration 105, loss = 0.36529510\n",
            "Iteration 106, loss = 0.36527116\n",
            "Iteration 107, loss = 0.37174271\n",
            "Iteration 108, loss = 0.36592916\n",
            "Iteration 109, loss = 0.36528426\n",
            "Iteration 110, loss = 0.36554148\n",
            "Iteration 111, loss = 0.36463885\n",
            "Iteration 112, loss = 0.36532912\n",
            "Iteration 113, loss = 0.36473681\n",
            "Iteration 114, loss = 0.36558612\n",
            "Iteration 115, loss = 0.36694847\n",
            "Iteration 116, loss = 0.36775970\n",
            "Iteration 117, loss = 0.36438401\n",
            "Iteration 118, loss = 0.36359023\n",
            "Iteration 119, loss = 0.36393367\n",
            "Iteration 120, loss = 0.36462195\n",
            "Iteration 121, loss = 0.36407387\n",
            "Iteration 122, loss = 0.36234182\n",
            "Iteration 123, loss = 0.36474798\n",
            "Iteration 124, loss = 0.36290823\n",
            "Iteration 125, loss = 0.36381231\n",
            "Iteration 126, loss = 0.36253101\n",
            "Iteration 127, loss = 0.36106937\n",
            "Iteration 128, loss = 0.36200814\n",
            "Iteration 129, loss = 0.36181105\n",
            "Iteration 130, loss = 0.36289251\n",
            "Iteration 131, loss = 0.36770900\n",
            "Iteration 132, loss = 0.36146143\n",
            "Iteration 133, loss = 0.36190905\n",
            "Iteration 134, loss = 0.36139139\n",
            "Iteration 135, loss = 0.36094096\n",
            "Iteration 136, loss = 0.36203546\n",
            "Iteration 137, loss = 0.36257842\n",
            "Iteration 138, loss = 0.36133458\n",
            "Iteration 139, loss = 0.35987200\n",
            "Iteration 140, loss = 0.36308841\n",
            "Iteration 141, loss = 0.36050178\n",
            "Iteration 142, loss = 0.36204110\n",
            "Iteration 143, loss = 0.35891102\n",
            "Iteration 144, loss = 0.35948819\n",
            "Iteration 145, loss = 0.35902029\n",
            "Iteration 146, loss = 0.35906957\n",
            "Iteration 147, loss = 0.35977171\n",
            "Iteration 148, loss = 0.36185070\n",
            "Iteration 149, loss = 0.36122386\n",
            "Iteration 150, loss = 0.35867582\n",
            "Iteration 151, loss = 0.35890993\n",
            "Iteration 152, loss = 0.36399829\n",
            "Iteration 153, loss = 0.36038207\n",
            "Iteration 154, loss = 0.36371779\n",
            "Iteration 155, loss = 0.35987489\n",
            "Iteration 156, loss = 0.35769604\n",
            "Iteration 157, loss = 0.35821825\n",
            "Iteration 158, loss = 0.35890248\n",
            "Iteration 159, loss = 0.35759455\n",
            "Iteration 160, loss = 0.35977708\n",
            "Iteration 161, loss = 0.35802106\n",
            "Iteration 162, loss = 0.35821495\n",
            "Iteration 163, loss = 0.36052558\n",
            "Iteration 164, loss = 0.35953093\n",
            "Iteration 165, loss = 0.35944236\n",
            "Iteration 166, loss = 0.36168586\n",
            "Iteration 167, loss = 0.35658557\n",
            "Iteration 168, loss = 0.35827662\n",
            "Iteration 169, loss = 0.35863738\n",
            "Iteration 170, loss = 0.35727476\n",
            "Iteration 171, loss = 0.35699474\n",
            "Iteration 172, loss = 0.35702226\n",
            "Iteration 173, loss = 0.35778789\n",
            "Iteration 174, loss = 0.35882566\n",
            "Iteration 175, loss = 0.35607465\n",
            "Iteration 176, loss = 0.35668373\n",
            "Iteration 177, loss = 0.35530223\n",
            "Iteration 178, loss = 0.36025295\n",
            "Iteration 179, loss = 0.36154479\n",
            "Iteration 180, loss = 0.35821730\n",
            "Iteration 181, loss = 0.35972414\n",
            "Iteration 182, loss = 0.35961570\n",
            "Iteration 183, loss = 0.35947180\n",
            "Iteration 184, loss = 0.35754688\n",
            "Iteration 185, loss = 0.35565449\n",
            "Iteration 186, loss = 0.35934017\n",
            "Iteration 187, loss = 0.35605533\n",
            "Iteration 188, loss = 0.35849679\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.16420017\n",
            "Iteration 2, loss = 6.15598127\n",
            "Iteration 3, loss = 5.85551546\n",
            "Iteration 4, loss = 5.03693623\n",
            "Iteration 5, loss = 4.12375440\n",
            "Iteration 6, loss = 3.24011338\n",
            "Iteration 7, loss = 2.45595300\n",
            "Iteration 8, loss = 1.72396518\n",
            "Iteration 9, loss = 1.07079916\n",
            "Iteration 10, loss = 0.53747614\n",
            "Iteration 11, loss = 0.39960290\n",
            "Iteration 12, loss = 0.39436386\n",
            "Iteration 13, loss = 0.39395601\n",
            "Iteration 14, loss = 0.39273769\n",
            "Iteration 15, loss = 0.39107435\n",
            "Iteration 16, loss = 0.39026525\n",
            "Iteration 17, loss = 0.38884590\n",
            "Iteration 18, loss = 0.38790502\n",
            "Iteration 19, loss = 0.38880573\n",
            "Iteration 20, loss = 0.38616430\n",
            "Iteration 21, loss = 0.38579675\n",
            "Iteration 22, loss = 0.38351588\n",
            "Iteration 23, loss = 0.38264605\n",
            "Iteration 24, loss = 0.38205234\n",
            "Iteration 25, loss = 0.38305036\n",
            "Iteration 26, loss = 0.38022033\n",
            "Iteration 27, loss = 0.37914842\n",
            "Iteration 28, loss = 0.37919635\n",
            "Iteration 29, loss = 0.37910352\n",
            "Iteration 30, loss = 0.37698325\n",
            "Iteration 31, loss = 0.37604524\n",
            "Iteration 32, loss = 0.37511560\n",
            "Iteration 33, loss = 0.37488459\n",
            "Iteration 34, loss = 0.37391448\n",
            "Iteration 35, loss = 0.37301334\n",
            "Iteration 36, loss = 0.37264612\n",
            "Iteration 37, loss = 0.37206826\n",
            "Iteration 38, loss = 0.37140277\n",
            "Iteration 39, loss = 0.37020533\n",
            "Iteration 40, loss = 0.37014967\n",
            "Iteration 41, loss = 0.36967770\n",
            "Iteration 42, loss = 0.36833614\n",
            "Iteration 43, loss = 0.36799979\n",
            "Iteration 44, loss = 0.36746215\n",
            "Iteration 45, loss = 0.36810304\n",
            "Iteration 46, loss = 0.36656249\n",
            "Iteration 47, loss = 0.36638588\n",
            "Iteration 48, loss = 0.36539454\n",
            "Iteration 49, loss = 0.36448429\n",
            "Iteration 50, loss = 0.36496272\n",
            "Iteration 51, loss = 0.36349169\n",
            "Iteration 52, loss = 0.36538537\n",
            "Iteration 53, loss = 0.36255721\n",
            "Iteration 54, loss = 0.36400268\n",
            "Iteration 55, loss = 0.36379390\n",
            "Iteration 56, loss = 0.36096003\n",
            "Iteration 57, loss = 0.36090150\n",
            "Iteration 58, loss = 0.36019379\n",
            "Iteration 59, loss = 0.36021331\n",
            "Iteration 60, loss = 0.36128654\n",
            "Iteration 61, loss = 0.36097220\n",
            "Iteration 62, loss = 0.35992932\n",
            "Iteration 63, loss = 0.36070071\n",
            "Iteration 64, loss = 0.35793058\n",
            "Iteration 65, loss = 0.35845649\n",
            "Iteration 66, loss = 0.35774798\n",
            "Iteration 67, loss = 0.35735253\n",
            "Iteration 68, loss = 0.35795121\n",
            "Iteration 69, loss = 0.35742731\n",
            "Iteration 70, loss = 0.35686666\n",
            "Iteration 71, loss = 0.35662183\n",
            "Iteration 72, loss = 0.35630568\n",
            "Iteration 73, loss = 0.35773439\n",
            "Iteration 74, loss = 0.35562005\n",
            "Iteration 75, loss = 0.35566218\n",
            "Iteration 76, loss = 0.35522714\n",
            "Iteration 77, loss = 0.35455969\n",
            "Iteration 78, loss = 0.35555756\n",
            "Iteration 79, loss = 0.35743352\n",
            "Iteration 80, loss = 0.35590519\n",
            "Iteration 81, loss = 0.35510467\n",
            "Iteration 82, loss = 0.35426146\n",
            "Iteration 83, loss = 0.35541521\n",
            "Iteration 84, loss = 0.35367658\n",
            "Iteration 85, loss = 0.35310757\n",
            "Iteration 86, loss = 0.35608578\n",
            "Iteration 87, loss = 0.35458903\n",
            "Iteration 88, loss = 0.35702779\n",
            "Iteration 89, loss = 0.35236934\n",
            "Iteration 90, loss = 0.35427202\n",
            "Iteration 91, loss = 0.35717514\n",
            "Iteration 92, loss = 0.35242899\n",
            "Iteration 93, loss = 0.35199646\n",
            "Iteration 94, loss = 0.35118703\n",
            "Iteration 95, loss = 0.35335013\n",
            "Iteration 96, loss = 0.35148263\n",
            "Iteration 97, loss = 0.35220611\n",
            "Iteration 98, loss = 0.35035301\n",
            "Iteration 99, loss = 0.34985143\n",
            "Iteration 100, loss = 0.35090806\n",
            "Iteration 101, loss = 0.35002361\n",
            "Iteration 102, loss = 0.35101822\n",
            "Iteration 103, loss = 0.34900561\n",
            "Iteration 104, loss = 0.34952910\n",
            "Iteration 105, loss = 0.35132808\n",
            "Iteration 106, loss = 0.34974480\n",
            "Iteration 107, loss = 0.35114350\n",
            "Iteration 108, loss = 0.35032639\n",
            "Iteration 109, loss = 0.34877586\n",
            "Iteration 110, loss = 0.34861032\n",
            "Iteration 111, loss = 0.34951804\n",
            "Iteration 112, loss = 0.34830846\n",
            "Iteration 113, loss = 0.34937123\n",
            "Iteration 114, loss = 0.35039661\n",
            "Iteration 115, loss = 0.34853567\n",
            "Iteration 116, loss = 0.34857071\n",
            "Iteration 117, loss = 0.34811593\n",
            "Iteration 118, loss = 0.34779063\n",
            "Iteration 119, loss = 0.34872229\n",
            "Iteration 120, loss = 0.34601102\n",
            "Iteration 121, loss = 0.34666823\n",
            "Iteration 122, loss = 0.34593044\n",
            "Iteration 123, loss = 0.34602743\n",
            "Iteration 124, loss = 0.34913105\n",
            "Iteration 125, loss = 0.34990628\n",
            "Iteration 126, loss = 0.34854265\n",
            "Iteration 127, loss = 0.34543778\n",
            "Iteration 128, loss = 0.34700395\n",
            "Iteration 129, loss = 0.34687763\n",
            "Iteration 130, loss = 0.34589812\n",
            "Iteration 131, loss = 0.34538596\n",
            "Iteration 132, loss = 0.35028291\n",
            "Iteration 133, loss = 0.34620124\n",
            "Iteration 134, loss = 0.34603784\n",
            "Iteration 135, loss = 0.34731616\n",
            "Iteration 136, loss = 0.34688992\n",
            "Iteration 137, loss = 0.34584236\n",
            "Iteration 138, loss = 0.34705304\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.19416629\n",
            "Iteration 2, loss = 6.11964712\n",
            "Iteration 3, loss = 5.38769819\n",
            "Iteration 4, loss = 4.28499573\n",
            "Iteration 5, loss = 3.18395368\n",
            "Iteration 6, loss = 2.16174053\n",
            "Iteration 7, loss = 1.26696426\n",
            "Iteration 8, loss = 0.55722300\n",
            "Iteration 9, loss = 0.40572278\n",
            "Iteration 10, loss = 0.40334362\n",
            "Iteration 11, loss = 0.40133453\n",
            "Iteration 12, loss = 0.40064799\n",
            "Iteration 13, loss = 0.39801787\n",
            "Iteration 14, loss = 0.39683932\n",
            "Iteration 15, loss = 0.39587845\n",
            "Iteration 16, loss = 0.39429164\n",
            "Iteration 17, loss = 0.39481572\n",
            "Iteration 18, loss = 0.39200355\n",
            "Iteration 19, loss = 0.39055476\n",
            "Iteration 20, loss = 0.38929903\n",
            "Iteration 21, loss = 0.38909894\n",
            "Iteration 22, loss = 0.38724601\n",
            "Iteration 23, loss = 0.38661305\n",
            "Iteration 24, loss = 0.38492311\n",
            "Iteration 25, loss = 0.38401196\n",
            "Iteration 26, loss = 0.38282277\n",
            "Iteration 27, loss = 0.38394132\n",
            "Iteration 28, loss = 0.38159300\n",
            "Iteration 29, loss = 0.38071773\n",
            "Iteration 30, loss = 0.38006064\n",
            "Iteration 31, loss = 0.37912593\n",
            "Iteration 32, loss = 0.37907443\n",
            "Iteration 33, loss = 0.37681042\n",
            "Iteration 34, loss = 0.37694469\n",
            "Iteration 35, loss = 0.37519906\n",
            "Iteration 36, loss = 0.37417854\n",
            "Iteration 37, loss = 0.37431977\n",
            "Iteration 38, loss = 0.37325263\n",
            "Iteration 39, loss = 0.37415172\n",
            "Iteration 40, loss = 0.37144448\n",
            "Iteration 41, loss = 0.37104423\n",
            "Iteration 42, loss = 0.36997174\n",
            "Iteration 43, loss = 0.37008133\n",
            "Iteration 44, loss = 0.36948840\n",
            "Iteration 45, loss = 0.36975976\n",
            "Iteration 46, loss = 0.36840123\n",
            "Iteration 47, loss = 0.36862928\n",
            "Iteration 48, loss = 0.36965081\n",
            "Iteration 49, loss = 0.36654568\n",
            "Iteration 50, loss = 0.36701077\n",
            "Iteration 51, loss = 0.36613179\n",
            "Iteration 52, loss = 0.36513281\n",
            "Iteration 53, loss = 0.36615746\n",
            "Iteration 54, loss = 0.36553549\n",
            "Iteration 55, loss = 0.36561725\n",
            "Iteration 56, loss = 0.36390312\n",
            "Iteration 57, loss = 0.36355986\n",
            "Iteration 58, loss = 0.36271776\n",
            "Iteration 59, loss = 0.36302853\n",
            "Iteration 60, loss = 0.36503972\n",
            "Iteration 61, loss = 0.36271648\n",
            "Iteration 62, loss = 0.36347254\n",
            "Iteration 63, loss = 0.36309065\n",
            "Iteration 64, loss = 0.36070568\n",
            "Iteration 65, loss = 0.36249232\n",
            "Iteration 66, loss = 0.36267110\n",
            "Iteration 67, loss = 0.36177636\n",
            "Iteration 68, loss = 0.36264669\n",
            "Iteration 69, loss = 0.36073922\n",
            "Iteration 70, loss = 0.35885718\n",
            "Iteration 71, loss = 0.35936749\n",
            "Iteration 72, loss = 0.35994746\n",
            "Iteration 73, loss = 0.35987631\n",
            "Iteration 74, loss = 0.35934612\n",
            "Iteration 75, loss = 0.35898675\n",
            "Iteration 76, loss = 0.35747712\n",
            "Iteration 77, loss = 0.35831309\n",
            "Iteration 78, loss = 0.36228899\n",
            "Iteration 79, loss = 0.35652968\n",
            "Iteration 80, loss = 0.35763688\n",
            "Iteration 81, loss = 0.35636920\n",
            "Iteration 82, loss = 0.35613816\n",
            "Iteration 83, loss = 0.35556615\n",
            "Iteration 84, loss = 0.35710627\n",
            "Iteration 85, loss = 0.35456748\n",
            "Iteration 86, loss = 0.35524834\n",
            "Iteration 87, loss = 0.35575120\n",
            "Iteration 88, loss = 0.35405677\n",
            "Iteration 89, loss = 0.35653240\n",
            "Iteration 90, loss = 0.35441585\n",
            "Iteration 91, loss = 0.35340142\n",
            "Iteration 92, loss = 0.35263372\n",
            "Iteration 93, loss = 0.35267311\n",
            "Iteration 94, loss = 0.35272869\n",
            "Iteration 95, loss = 0.35309239\n",
            "Iteration 96, loss = 0.35139265\n",
            "Iteration 97, loss = 0.35428533\n",
            "Iteration 98, loss = 0.35418791\n",
            "Iteration 99, loss = 0.35270936\n",
            "Iteration 100, loss = 0.35236163\n",
            "Iteration 101, loss = 0.35062675\n",
            "Iteration 102, loss = 0.35255017\n",
            "Iteration 103, loss = 0.35120916\n",
            "Iteration 104, loss = 0.35238422\n",
            "Iteration 105, loss = 0.35214505\n",
            "Iteration 106, loss = 0.35066781\n",
            "Iteration 107, loss = 0.35189335\n",
            "Iteration 108, loss = 0.35057042\n",
            "Iteration 109, loss = 0.35080262\n",
            "Iteration 110, loss = 0.35040940\n",
            "Iteration 111, loss = 0.35055940\n",
            "Iteration 112, loss = 0.35197192\n",
            "Iteration 113, loss = 0.35334136\n",
            "Iteration 114, loss = 0.34928913\n",
            "Iteration 115, loss = 0.34904725\n",
            "Iteration 116, loss = 0.34885457\n",
            "Iteration 117, loss = 0.34914067\n",
            "Iteration 118, loss = 0.35266351\n",
            "Iteration 119, loss = 0.34893597\n",
            "Iteration 120, loss = 0.34987436\n",
            "Iteration 121, loss = 0.34926886\n",
            "Iteration 122, loss = 0.34824511\n",
            "Iteration 123, loss = 0.34914502\n",
            "Iteration 124, loss = 0.34720983\n",
            "Iteration 125, loss = 0.34797038\n",
            "Iteration 126, loss = 0.35042785\n",
            "Iteration 127, loss = 0.34778291\n",
            "Iteration 128, loss = 0.34825280\n",
            "Iteration 129, loss = 0.34656843\n",
            "Iteration 130, loss = 0.34923921\n",
            "Iteration 131, loss = 0.34884184\n",
            "Iteration 132, loss = 0.34600983\n",
            "Iteration 133, loss = 0.34589067\n",
            "Iteration 134, loss = 0.34796407\n",
            "Iteration 135, loss = 0.34640227\n",
            "Iteration 136, loss = 0.34732892\n",
            "Iteration 137, loss = 0.35311015\n",
            "Iteration 138, loss = 0.34734102\n",
            "Iteration 139, loss = 0.34544968\n",
            "Iteration 140, loss = 0.34582092\n",
            "Iteration 141, loss = 0.34674485\n",
            "Iteration 142, loss = 0.34590305\n",
            "Iteration 143, loss = 0.34659112\n",
            "Iteration 144, loss = 0.35353111\n",
            "Iteration 145, loss = 0.34516307\n",
            "Iteration 146, loss = 0.34785147\n",
            "Iteration 147, loss = 0.34883120\n",
            "Iteration 148, loss = 0.34659195\n",
            "Iteration 149, loss = 0.34770721\n",
            "Iteration 150, loss = 0.35034459\n",
            "Iteration 151, loss = 0.34612183\n",
            "Iteration 152, loss = 0.34677311\n",
            "Iteration 153, loss = 0.34462324\n",
            "Iteration 154, loss = 0.34471992\n",
            "Iteration 155, loss = 0.34824297\n",
            "Iteration 156, loss = 0.34548379\n",
            "Iteration 157, loss = 0.34498631\n",
            "Iteration 158, loss = 0.34550733\n",
            "Iteration 159, loss = 0.34503577\n",
            "Iteration 160, loss = 0.34585579\n",
            "Iteration 161, loss = 0.34357553\n",
            "Iteration 162, loss = 0.34692458\n",
            "Iteration 163, loss = 0.34555031\n",
            "Iteration 164, loss = 0.34502883\n",
            "Iteration 165, loss = 0.34511134\n",
            "Iteration 166, loss = 0.34583357\n",
            "Iteration 167, loss = 0.34411833\n",
            "Iteration 168, loss = 0.34448289\n",
            "Iteration 169, loss = 0.34757104\n",
            "Iteration 170, loss = 0.34479779\n",
            "Iteration 171, loss = 0.34596923\n",
            "Iteration 172, loss = 0.35537356\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.16297195\n",
            "Iteration 2, loss = 5.92285547\n",
            "Iteration 3, loss = 4.75071872\n",
            "Iteration 4, loss = 3.45612791\n",
            "Iteration 5, loss = 2.24756174\n",
            "Iteration 6, loss = 1.20249385\n",
            "Iteration 7, loss = 0.49251837\n",
            "Iteration 8, loss = 0.40303917\n",
            "Iteration 9, loss = 0.40076165\n",
            "Iteration 10, loss = 0.39844570\n",
            "Iteration 11, loss = 0.39664625\n",
            "Iteration 12, loss = 0.39515508\n",
            "Iteration 13, loss = 0.39364518\n",
            "Iteration 14, loss = 0.39203622\n",
            "Iteration 15, loss = 0.38959817\n",
            "Iteration 16, loss = 0.39006753\n",
            "Iteration 17, loss = 0.38737435\n",
            "Iteration 18, loss = 0.38654060\n",
            "Iteration 19, loss = 0.38525514\n",
            "Iteration 20, loss = 0.38407363\n",
            "Iteration 21, loss = 0.38363529\n",
            "Iteration 22, loss = 0.38188721\n",
            "Iteration 23, loss = 0.38203564\n",
            "Iteration 24, loss = 0.37995796\n",
            "Iteration 25, loss = 0.37902211\n",
            "Iteration 26, loss = 0.37757610\n",
            "Iteration 27, loss = 0.37561031\n",
            "Iteration 28, loss = 0.37447469\n",
            "Iteration 29, loss = 0.37219112\n",
            "Iteration 30, loss = 0.36821845\n",
            "Iteration 31, loss = 0.36796951\n",
            "Iteration 32, loss = 0.36620266\n",
            "Iteration 33, loss = 0.36493290\n",
            "Iteration 34, loss = 0.36545348\n",
            "Iteration 35, loss = 0.36402597\n",
            "Iteration 36, loss = 0.36386057\n",
            "Iteration 37, loss = 0.36208109\n",
            "Iteration 38, loss = 0.36256552\n",
            "Iteration 39, loss = 0.35880038\n",
            "Iteration 40, loss = 0.35988235\n",
            "Iteration 41, loss = 0.35771206\n",
            "Iteration 42, loss = 0.35765780\n",
            "Iteration 43, loss = 0.35792523\n",
            "Iteration 44, loss = 0.35732244\n",
            "Iteration 45, loss = 0.35613587\n",
            "Iteration 46, loss = 0.35662046\n",
            "Iteration 47, loss = 0.35425694\n",
            "Iteration 48, loss = 0.35416324\n",
            "Iteration 49, loss = 0.35330117\n",
            "Iteration 50, loss = 0.35174340\n",
            "Iteration 51, loss = 0.35245648\n",
            "Iteration 52, loss = 0.35217903\n",
            "Iteration 53, loss = 0.35270739\n",
            "Iteration 54, loss = 0.35064907\n",
            "Iteration 55, loss = 0.35081482\n",
            "Iteration 56, loss = 0.35254812\n",
            "Iteration 57, loss = 0.35077844\n",
            "Iteration 58, loss = 0.35086777\n",
            "Iteration 59, loss = 0.34999414\n",
            "Iteration 60, loss = 0.34942972\n",
            "Iteration 61, loss = 0.35203026\n",
            "Iteration 62, loss = 0.35108156\n",
            "Iteration 63, loss = 0.35362099\n",
            "Iteration 64, loss = 0.34923691\n",
            "Iteration 65, loss = 0.34808990\n",
            "Iteration 66, loss = 0.34940921\n",
            "Iteration 67, loss = 0.34856890\n",
            "Iteration 68, loss = 0.34707864\n",
            "Iteration 69, loss = 0.34765943\n",
            "Iteration 70, loss = 0.34720468\n",
            "Iteration 71, loss = 0.34706784\n",
            "Iteration 72, loss = 0.34842500\n",
            "Iteration 73, loss = 0.35000088\n",
            "Iteration 74, loss = 0.34839815\n",
            "Iteration 75, loss = 0.34863092\n",
            "Iteration 76, loss = 0.34710689\n",
            "Iteration 77, loss = 0.34704565\n",
            "Iteration 78, loss = 0.34771278\n",
            "Iteration 79, loss = 0.35103220\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.24221567\n",
            "Iteration 2, loss = 5.85414351\n",
            "Iteration 3, loss = 4.38780252\n",
            "Iteration 4, loss = 2.83982233\n",
            "Iteration 5, loss = 1.50239149\n",
            "Iteration 6, loss = 0.53524411\n",
            "Iteration 7, loss = 0.40044506\n",
            "Iteration 8, loss = 0.39778879\n",
            "Iteration 9, loss = 0.39621334\n",
            "Iteration 10, loss = 0.39441386\n",
            "Iteration 11, loss = 0.39196491\n",
            "Iteration 12, loss = 0.39095320\n",
            "Iteration 13, loss = 0.38953303\n",
            "Iteration 14, loss = 0.38809236\n",
            "Iteration 15, loss = 0.38600143\n",
            "Iteration 16, loss = 0.38453530\n",
            "Iteration 17, loss = 0.38319453\n",
            "Iteration 18, loss = 0.38154029\n",
            "Iteration 19, loss = 0.38069211\n",
            "Iteration 20, loss = 0.38012329\n",
            "Iteration 21, loss = 0.37825547\n",
            "Iteration 22, loss = 0.37664531\n",
            "Iteration 23, loss = 0.37557823\n",
            "Iteration 24, loss = 0.37479620\n",
            "Iteration 25, loss = 0.37407952\n",
            "Iteration 26, loss = 0.37217278\n",
            "Iteration 27, loss = 0.37178910\n",
            "Iteration 28, loss = 0.37112090\n",
            "Iteration 29, loss = 0.37065589\n",
            "Iteration 30, loss = 0.36963156\n",
            "Iteration 31, loss = 0.36931823\n",
            "Iteration 32, loss = 0.36846722\n",
            "Iteration 33, loss = 0.36702409\n",
            "Iteration 34, loss = 0.36685409\n",
            "Iteration 35, loss = 0.36814653\n",
            "Iteration 36, loss = 0.36369701\n",
            "Iteration 37, loss = 0.36561032\n",
            "Iteration 38, loss = 0.36300894\n",
            "Iteration 39, loss = 0.36423828\n",
            "Iteration 40, loss = 0.36276247\n",
            "Iteration 41, loss = 0.36282324\n",
            "Iteration 42, loss = 0.36155637\n",
            "Iteration 43, loss = 0.36090225\n",
            "Iteration 44, loss = 0.36058784\n",
            "Iteration 45, loss = 0.36162504\n",
            "Iteration 46, loss = 0.36077676\n",
            "Iteration 47, loss = 0.35949424\n",
            "Iteration 48, loss = 0.35927719\n",
            "Iteration 49, loss = 0.35871356\n",
            "Iteration 50, loss = 0.35912535\n",
            "Iteration 51, loss = 0.35789911\n",
            "Iteration 52, loss = 0.36288455\n",
            "Iteration 53, loss = 0.35771727\n",
            "Iteration 54, loss = 0.35720549\n",
            "Iteration 55, loss = 0.35940699\n",
            "Iteration 56, loss = 0.35642598\n",
            "Iteration 57, loss = 0.35596757\n",
            "Iteration 58, loss = 0.35484246\n",
            "Iteration 59, loss = 0.35597539\n",
            "Iteration 60, loss = 0.35536265\n",
            "Iteration 61, loss = 0.35559226\n",
            "Iteration 62, loss = 0.35507628\n",
            "Iteration 63, loss = 0.35619351\n",
            "Iteration 64, loss = 0.35646272\n",
            "Iteration 65, loss = 0.35417531\n",
            "Iteration 66, loss = 0.35174601\n",
            "Iteration 67, loss = 0.35327894\n",
            "Iteration 68, loss = 0.35328302\n",
            "Iteration 69, loss = 0.35554138\n",
            "Iteration 70, loss = 0.35302721\n",
            "Iteration 71, loss = 0.35299716\n",
            "Iteration 72, loss = 0.35174863\n",
            "Iteration 73, loss = 0.35155382\n",
            "Iteration 74, loss = 0.35003059\n",
            "Iteration 75, loss = 0.35020051\n",
            "Iteration 76, loss = 0.35183661\n",
            "Iteration 77, loss = 0.35146406\n",
            "Iteration 78, loss = 0.34982847\n",
            "Iteration 79, loss = 0.34929788\n",
            "Iteration 80, loss = 0.35075656\n",
            "Iteration 81, loss = 0.35022335\n",
            "Iteration 82, loss = 0.34945245\n",
            "Iteration 83, loss = 0.34821486\n",
            "Iteration 84, loss = 0.35039791\n",
            "Iteration 85, loss = 0.34929915\n",
            "Iteration 86, loss = 0.35394569\n",
            "Iteration 87, loss = 0.34900187\n",
            "Iteration 88, loss = 0.35188102\n",
            "Iteration 89, loss = 0.34708421\n",
            "Iteration 90, loss = 0.34868814\n",
            "Iteration 91, loss = 0.34784580\n",
            "Iteration 92, loss = 0.34625820\n",
            "Iteration 93, loss = 0.34813268\n",
            "Iteration 94, loss = 0.34709446\n",
            "Iteration 95, loss = 0.34768222\n",
            "Iteration 96, loss = 0.34724969\n",
            "Iteration 97, loss = 0.34772424\n",
            "Iteration 98, loss = 0.34872594\n",
            "Iteration 99, loss = 0.34632288\n",
            "Iteration 100, loss = 0.34839110\n",
            "Iteration 101, loss = 0.34735897\n",
            "Iteration 102, loss = 0.35079767\n",
            "Iteration 103, loss = 0.34848840\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.09780500\n",
            "Iteration 2, loss = 5.47178975\n",
            "Iteration 3, loss = 3.76481490\n",
            "Iteration 4, loss = 2.13016257\n",
            "Iteration 5, loss = 0.78454833\n",
            "Iteration 6, loss = 0.39910085\n",
            "Iteration 7, loss = 0.39395170\n",
            "Iteration 8, loss = 0.39163714\n",
            "Iteration 9, loss = 0.38897777\n",
            "Iteration 10, loss = 0.38665653\n",
            "Iteration 11, loss = 0.38468184\n",
            "Iteration 12, loss = 0.38270787\n",
            "Iteration 13, loss = 0.38061340\n",
            "Iteration 14, loss = 0.37939145\n",
            "Iteration 15, loss = 0.37778156\n",
            "Iteration 16, loss = 0.37599948\n",
            "Iteration 17, loss = 0.37482199\n",
            "Iteration 18, loss = 0.37204978\n",
            "Iteration 19, loss = 0.36931190\n",
            "Iteration 20, loss = 0.36648923\n",
            "Iteration 21, loss = 0.36376252\n",
            "Iteration 22, loss = 0.36146500\n",
            "Iteration 23, loss = 0.36134619\n",
            "Iteration 24, loss = 0.36020399\n",
            "Iteration 25, loss = 0.35964510\n",
            "Iteration 26, loss = 0.35557701\n",
            "Iteration 27, loss = 0.35593607\n",
            "Iteration 28, loss = 0.35344116\n",
            "Iteration 29, loss = 0.35339820\n",
            "Iteration 30, loss = 0.35521473\n",
            "Iteration 31, loss = 0.35089762\n",
            "Iteration 32, loss = 0.35432395\n",
            "Iteration 33, loss = 0.34968400\n",
            "Iteration 34, loss = 0.34888121\n",
            "Iteration 35, loss = 0.34863979\n",
            "Iteration 36, loss = 0.34704175\n",
            "Iteration 37, loss = 0.34781710\n",
            "Iteration 38, loss = 0.34735676\n",
            "Iteration 39, loss = 0.34545464\n",
            "Iteration 40, loss = 0.34767644\n",
            "Iteration 41, loss = 0.34557947\n",
            "Iteration 42, loss = 0.34414172\n",
            "Iteration 43, loss = 0.34393040\n",
            "Iteration 44, loss = 0.34393303\n",
            "Iteration 45, loss = 0.34552516\n",
            "Iteration 46, loss = 0.34359100\n",
            "Iteration 47, loss = 0.34329974\n",
            "Iteration 48, loss = 0.34263139\n",
            "Iteration 49, loss = 0.34433203\n",
            "Iteration 50, loss = 0.34161906\n",
            "Iteration 51, loss = 0.34222540\n",
            "Iteration 52, loss = 0.34168771\n",
            "Iteration 53, loss = 0.34160619\n",
            "Iteration 54, loss = 0.34311069\n",
            "Iteration 55, loss = 0.34054442\n",
            "Iteration 56, loss = 0.33998960\n",
            "Iteration 57, loss = 0.34237461\n",
            "Iteration 58, loss = 0.34068916\n",
            "Iteration 59, loss = 0.33897086\n",
            "Iteration 60, loss = 0.34024403\n",
            "Iteration 61, loss = 0.33944286\n",
            "Iteration 62, loss = 0.34055786\n",
            "Iteration 63, loss = 0.33960962\n",
            "Iteration 64, loss = 0.33803714\n",
            "Iteration 65, loss = 0.34011398\n",
            "Iteration 66, loss = 0.33915797\n",
            "Iteration 67, loss = 0.33962073\n",
            "Iteration 68, loss = 0.34120727\n",
            "Iteration 69, loss = 0.33803980\n",
            "Iteration 70, loss = 0.33794418\n",
            "Iteration 71, loss = 0.34347841\n",
            "Iteration 72, loss = 0.33862714\n",
            "Iteration 73, loss = 0.33828713\n",
            "Iteration 74, loss = 0.33916975\n",
            "Iteration 75, loss = 0.33809354\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.15093298\n",
            "Iteration 2, loss = 5.25905714\n",
            "Iteration 3, loss = 3.30746119\n",
            "Iteration 4, loss = 1.54134917\n",
            "Iteration 5, loss = 0.45631268\n",
            "Iteration 6, loss = 0.39842081\n",
            "Iteration 7, loss = 0.39619733\n",
            "Iteration 8, loss = 0.39354352\n",
            "Iteration 9, loss = 0.39065631\n",
            "Iteration 10, loss = 0.38800037\n",
            "Iteration 11, loss = 0.38588389\n",
            "Iteration 12, loss = 0.38323322\n",
            "Iteration 13, loss = 0.38142487\n",
            "Iteration 14, loss = 0.37953224\n",
            "Iteration 15, loss = 0.37858433\n",
            "Iteration 16, loss = 0.37596394\n",
            "Iteration 17, loss = 0.37184522\n",
            "Iteration 18, loss = 0.36792852\n",
            "Iteration 19, loss = 0.36570064\n",
            "Iteration 20, loss = 0.36265394\n",
            "Iteration 21, loss = 0.36013301\n",
            "Iteration 22, loss = 0.35964268\n",
            "Iteration 23, loss = 0.35928280\n",
            "Iteration 24, loss = 0.35614204\n",
            "Iteration 25, loss = 0.35500406\n",
            "Iteration 26, loss = 0.35455146\n",
            "Iteration 27, loss = 0.35295606\n",
            "Iteration 28, loss = 0.35525571\n",
            "Iteration 29, loss = 0.35127511\n",
            "Iteration 30, loss = 0.35110433\n",
            "Iteration 31, loss = 0.35380966\n",
            "Iteration 32, loss = 0.34974885\n",
            "Iteration 33, loss = 0.34766086\n",
            "Iteration 34, loss = 0.34924686\n",
            "Iteration 35, loss = 0.34666620\n",
            "Iteration 36, loss = 0.34674718\n",
            "Iteration 37, loss = 0.34684763\n",
            "Iteration 38, loss = 0.34705050\n",
            "Iteration 39, loss = 0.34559157\n",
            "Iteration 40, loss = 0.34474224\n",
            "Iteration 41, loss = 0.34937691\n",
            "Iteration 42, loss = 0.34490998\n",
            "Iteration 43, loss = 0.34495070\n",
            "Iteration 44, loss = 0.34394758\n",
            "Iteration 45, loss = 0.34474631\n",
            "Iteration 46, loss = 0.34452045\n",
            "Iteration 47, loss = 0.34534398\n",
            "Iteration 48, loss = 0.34497945\n",
            "Iteration 49, loss = 0.34350250\n",
            "Iteration 50, loss = 0.34450865\n",
            "Iteration 51, loss = 0.34127629\n",
            "Iteration 52, loss = 0.34154122\n",
            "Iteration 53, loss = 0.34483716\n",
            "Iteration 54, loss = 0.34408532\n",
            "Iteration 55, loss = 0.34324423\n",
            "Iteration 56, loss = 0.34183564\n",
            "Iteration 57, loss = 0.34158024\n",
            "Iteration 58, loss = 0.34074573\n",
            "Iteration 59, loss = 0.34375076\n",
            "Iteration 60, loss = 0.34395406\n",
            "Iteration 61, loss = 0.34399557\n",
            "Iteration 62, loss = 0.34754400\n",
            "Iteration 63, loss = 0.34267937\n",
            "Iteration 64, loss = 0.34278023\n",
            "Iteration 65, loss = 0.34151386\n",
            "Iteration 66, loss = 0.34065575\n",
            "Iteration 67, loss = 0.34077545\n",
            "Iteration 68, loss = 0.34047597\n",
            "Iteration 69, loss = 0.34226936\n",
            "Iteration 70, loss = 0.34118748\n",
            "Iteration 71, loss = 0.34166152\n",
            "Iteration 72, loss = 0.34085023\n",
            "Iteration 73, loss = 0.34065294\n",
            "Iteration 74, loss = 0.34505999\n",
            "Iteration 75, loss = 0.34310484\n",
            "Iteration 76, loss = 0.34223804\n",
            "Iteration 77, loss = 0.34019643\n",
            "Iteration 78, loss = 0.34291062\n",
            "Iteration 79, loss = 0.34308342\n",
            "Iteration 80, loss = 0.34012513\n",
            "Iteration 81, loss = 0.34211154\n",
            "Iteration 82, loss = 0.34021242\n",
            "Iteration 83, loss = 0.34115673\n",
            "Iteration 84, loss = 0.34152402\n",
            "Iteration 85, loss = 0.34253768\n",
            "Iteration 86, loss = 0.34140157\n",
            "Iteration 87, loss = 0.34099811\n",
            "Iteration 88, loss = 0.34072102\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.08162527\n",
            "Iteration 2, loss = 5.05631297\n",
            "Iteration 3, loss = 2.99978386\n",
            "Iteration 4, loss = 1.19998692\n",
            "Iteration 5, loss = 0.40624160\n",
            "Iteration 6, loss = 0.39484531\n",
            "Iteration 7, loss = 0.39198210\n",
            "Iteration 8, loss = 0.38939279\n",
            "Iteration 9, loss = 0.38624223\n",
            "Iteration 10, loss = 0.38596309\n",
            "Iteration 11, loss = 0.38223622\n",
            "Iteration 12, loss = 0.37968875\n",
            "Iteration 13, loss = 0.37777954\n",
            "Iteration 14, loss = 0.37596120\n",
            "Iteration 15, loss = 0.37346817\n",
            "Iteration 16, loss = 0.37126374\n",
            "Iteration 17, loss = 0.36997956\n",
            "Iteration 18, loss = 0.36889150\n",
            "Iteration 19, loss = 0.36724520\n",
            "Iteration 20, loss = 0.36603231\n",
            "Iteration 21, loss = 0.36537804\n",
            "Iteration 22, loss = 0.36380752\n",
            "Iteration 23, loss = 0.36398865\n",
            "Iteration 24, loss = 0.36209154\n",
            "Iteration 25, loss = 0.36235609\n",
            "Iteration 26, loss = 0.36023776\n",
            "Iteration 27, loss = 0.35970596\n",
            "Iteration 28, loss = 0.36142693\n",
            "Iteration 29, loss = 0.35921508\n",
            "Iteration 30, loss = 0.35863000\n",
            "Iteration 31, loss = 0.35782008\n",
            "Iteration 32, loss = 0.35660354\n",
            "Iteration 33, loss = 0.35562108\n",
            "Iteration 34, loss = 0.35593738\n",
            "Iteration 35, loss = 0.35482988\n",
            "Iteration 36, loss = 0.35480661\n",
            "Iteration 37, loss = 0.35294068\n",
            "Iteration 38, loss = 0.35298331\n",
            "Iteration 39, loss = 0.35236956\n",
            "Iteration 40, loss = 0.35254394\n",
            "Iteration 41, loss = 0.35105664\n",
            "Iteration 42, loss = 0.35040630\n",
            "Iteration 43, loss = 0.35065299\n",
            "Iteration 44, loss = 0.35116529\n",
            "Iteration 45, loss = 0.34947200\n",
            "Iteration 46, loss = 0.35015064\n",
            "Iteration 47, loss = 0.34841773\n",
            "Iteration 48, loss = 0.34884896\n",
            "Iteration 49, loss = 0.34895397\n",
            "Iteration 50, loss = 0.34621457\n",
            "Iteration 51, loss = 0.34604080\n",
            "Iteration 52, loss = 0.34518130\n",
            "Iteration 53, loss = 0.34666306\n",
            "Iteration 54, loss = 0.34527537\n",
            "Iteration 55, loss = 0.34550978\n",
            "Iteration 56, loss = 0.34411690\n",
            "Iteration 57, loss = 0.34503320\n",
            "Iteration 58, loss = 0.34450553\n",
            "Iteration 59, loss = 0.34623402\n",
            "Iteration 60, loss = 0.34243362\n",
            "Iteration 61, loss = 0.34543239\n",
            "Iteration 62, loss = 0.34396688\n",
            "Iteration 63, loss = 0.34245717\n",
            "Iteration 64, loss = 0.34315888\n",
            "Iteration 65, loss = 0.34145092\n",
            "Iteration 66, loss = 0.34156679\n",
            "Iteration 67, loss = 0.34195985\n",
            "Iteration 68, loss = 0.34156903\n",
            "Iteration 69, loss = 0.34121722\n",
            "Iteration 70, loss = 0.34079116\n",
            "Iteration 71, loss = 0.34068552\n",
            "Iteration 72, loss = 0.34145660\n",
            "Iteration 73, loss = 0.34131645\n",
            "Iteration 74, loss = 0.34010230\n",
            "Iteration 75, loss = 0.34210008\n",
            "Iteration 76, loss = 0.34069447\n",
            "Iteration 77, loss = 0.33930593\n",
            "Iteration 78, loss = 0.34252867\n",
            "Iteration 79, loss = 0.34014346\n",
            "Iteration 80, loss = 0.33962486\n",
            "Iteration 81, loss = 0.34055783\n",
            "Iteration 82, loss = 0.33877738\n",
            "Iteration 83, loss = 0.33973754\n",
            "Iteration 84, loss = 0.33981722\n",
            "Iteration 85, loss = 0.34007341\n",
            "Iteration 86, loss = 0.33912434\n",
            "Iteration 87, loss = 0.34146617\n",
            "Iteration 88, loss = 0.33917056\n",
            "Iteration 89, loss = 0.33982920\n",
            "Iteration 90, loss = 0.34028250\n",
            "Iteration 91, loss = 0.33876544\n",
            "Iteration 92, loss = 0.33870677\n",
            "Iteration 93, loss = 0.33841637\n",
            "Iteration 94, loss = 0.34038626\n",
            "Iteration 95, loss = 0.33933051\n",
            "Iteration 96, loss = 0.34042579\n",
            "Iteration 97, loss = 0.33946393\n",
            "Iteration 98, loss = 0.33945510\n",
            "Iteration 99, loss = 0.34318600\n",
            "Iteration 100, loss = 0.33770582\n",
            "Iteration 101, loss = 0.33936606\n",
            "Iteration 102, loss = 0.33877888\n",
            "Iteration 103, loss = 0.33937406\n",
            "Iteration 104, loss = 0.34100879\n",
            "Iteration 105, loss = 0.33882636\n",
            "Iteration 106, loss = 0.33784983\n",
            "Iteration 107, loss = 0.33960483\n",
            "Iteration 108, loss = 0.33859766\n",
            "Iteration 109, loss = 0.33770292\n",
            "Iteration 110, loss = 0.33844518\n",
            "Iteration 111, loss = 0.33803347\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.10639472\n",
            "Iteration 2, loss = 5.03298042\n",
            "Iteration 3, loss = 2.92208606\n",
            "Iteration 4, loss = 1.10095636\n",
            "Iteration 5, loss = 0.40013091\n",
            "Iteration 6, loss = 0.39406067\n",
            "Iteration 7, loss = 0.39198412\n",
            "Iteration 8, loss = 0.38816910\n",
            "Iteration 9, loss = 0.38543504\n",
            "Iteration 10, loss = 0.38403620\n",
            "Iteration 11, loss = 0.38098049\n",
            "Iteration 12, loss = 0.37817597\n",
            "Iteration 13, loss = 0.37618448\n",
            "Iteration 14, loss = 0.37429179\n",
            "Iteration 15, loss = 0.37278600\n",
            "Iteration 16, loss = 0.37061011\n",
            "Iteration 17, loss = 0.36930848\n",
            "Iteration 18, loss = 0.36859496\n",
            "Iteration 19, loss = 0.36679447\n",
            "Iteration 20, loss = 0.36579688\n",
            "Iteration 21, loss = 0.36464346\n",
            "Iteration 22, loss = 0.36367446\n",
            "Iteration 23, loss = 0.36236505\n",
            "Iteration 24, loss = 0.36225842\n",
            "Iteration 25, loss = 0.36063149\n",
            "Iteration 26, loss = 0.35988874\n",
            "Iteration 27, loss = 0.35876860\n",
            "Iteration 28, loss = 0.35874950\n",
            "Iteration 29, loss = 0.35729763\n",
            "Iteration 30, loss = 0.35715868\n",
            "Iteration 31, loss = 0.35654212\n",
            "Iteration 32, loss = 0.35520814\n",
            "Iteration 33, loss = 0.35463757\n",
            "Iteration 34, loss = 0.35361301\n",
            "Iteration 35, loss = 0.35249427\n",
            "Iteration 36, loss = 0.35277170\n",
            "Iteration 37, loss = 0.35118641\n",
            "Iteration 38, loss = 0.35235630\n",
            "Iteration 39, loss = 0.35251606\n",
            "Iteration 40, loss = 0.35139206\n",
            "Iteration 41, loss = 0.35070639\n",
            "Iteration 42, loss = 0.34971450\n",
            "Iteration 43, loss = 0.34923783\n",
            "Iteration 44, loss = 0.34878521\n",
            "Iteration 45, loss = 0.34812129\n",
            "Iteration 46, loss = 0.34672711\n",
            "Iteration 47, loss = 0.34695866\n",
            "Iteration 48, loss = 0.34597292\n",
            "Iteration 49, loss = 0.34676813\n",
            "Iteration 50, loss = 0.34582305\n",
            "Iteration 51, loss = 0.34484928\n",
            "Iteration 52, loss = 0.34409030\n",
            "Iteration 53, loss = 0.34637191\n",
            "Iteration 54, loss = 0.34535356\n",
            "Iteration 55, loss = 0.34432853\n",
            "Iteration 56, loss = 0.34284751\n",
            "Iteration 57, loss = 0.34336511\n",
            "Iteration 58, loss = 0.34265422\n",
            "Iteration 59, loss = 0.34325354\n",
            "Iteration 60, loss = 0.34336240\n",
            "Iteration 61, loss = 0.34147854\n",
            "Iteration 62, loss = 0.34214738\n",
            "Iteration 63, loss = 0.34152074\n",
            "Iteration 64, loss = 0.34188328\n",
            "Iteration 65, loss = 0.34118149\n",
            "Iteration 66, loss = 0.34150892\n",
            "Iteration 67, loss = 0.34062728\n",
            "Iteration 68, loss = 0.34147781\n",
            "Iteration 69, loss = 0.34062309\n",
            "Iteration 70, loss = 0.34038480\n",
            "Iteration 71, loss = 0.34128178\n",
            "Iteration 72, loss = 0.34272013\n",
            "Iteration 73, loss = 0.33968286\n",
            "Iteration 74, loss = 0.33941085\n",
            "Iteration 75, loss = 0.34165095\n",
            "Iteration 76, loss = 0.33971351\n",
            "Iteration 77, loss = 0.33945277\n",
            "Iteration 78, loss = 0.34107699\n",
            "Iteration 79, loss = 0.33956265\n",
            "Iteration 80, loss = 0.33890557\n",
            "Iteration 81, loss = 0.33753800\n",
            "Iteration 82, loss = 0.33982943\n",
            "Iteration 83, loss = 0.34054168\n",
            "Iteration 84, loss = 0.34011018\n",
            "Iteration 85, loss = 0.33730134\n",
            "Iteration 86, loss = 0.33986384\n",
            "Iteration 87, loss = 0.33855697\n",
            "Iteration 88, loss = 0.34082883\n",
            "Iteration 89, loss = 0.33821407\n",
            "Iteration 90, loss = 0.33875811\n",
            "Iteration 91, loss = 0.34305541\n",
            "Iteration 92, loss = 0.33779061\n",
            "Iteration 93, loss = 0.33827148\n",
            "Iteration 94, loss = 0.33768508\n",
            "Iteration 95, loss = 0.33855574\n",
            "Iteration 96, loss = 0.33910260\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.06894313\n",
            "Iteration 2, loss = 4.95990156\n",
            "Iteration 3, loss = 2.82283895\n",
            "Iteration 4, loss = 1.01616948\n",
            "Iteration 5, loss = 0.39464376\n",
            "Iteration 6, loss = 0.39078905\n",
            "Iteration 7, loss = 0.38826726\n",
            "Iteration 8, loss = 0.38501786\n",
            "Iteration 9, loss = 0.38298036\n",
            "Iteration 10, loss = 0.38042553\n",
            "Iteration 11, loss = 0.37733017\n",
            "Iteration 12, loss = 0.37570370\n",
            "Iteration 13, loss = 0.37389990\n",
            "Iteration 14, loss = 0.37165308\n",
            "Iteration 15, loss = 0.36765035\n",
            "Iteration 16, loss = 0.36310272\n",
            "Iteration 17, loss = 0.36066798\n",
            "Iteration 18, loss = 0.35774784\n",
            "Iteration 19, loss = 0.35573801\n",
            "Iteration 20, loss = 0.35467684\n",
            "Iteration 21, loss = 0.35439183\n",
            "Iteration 22, loss = 0.35080436\n",
            "Iteration 23, loss = 0.35021024\n",
            "Iteration 24, loss = 0.34845777\n",
            "Iteration 25, loss = 0.34711628\n",
            "Iteration 26, loss = 0.34858029\n",
            "Iteration 27, loss = 0.34669206\n",
            "Iteration 28, loss = 0.34522575\n",
            "Iteration 29, loss = 0.34433381\n",
            "Iteration 30, loss = 0.34555478\n",
            "Iteration 31, loss = 0.34412196\n",
            "Iteration 32, loss = 0.34340066\n",
            "Iteration 33, loss = 0.34274356\n",
            "Iteration 34, loss = 0.34542123\n",
            "Iteration 35, loss = 0.34125891\n",
            "Iteration 36, loss = 0.34163269\n",
            "Iteration 37, loss = 0.33968285\n",
            "Iteration 38, loss = 0.34005689\n",
            "Iteration 39, loss = 0.33892816\n",
            "Iteration 40, loss = 0.33952654\n",
            "Iteration 41, loss = 0.34086752\n",
            "Iteration 42, loss = 0.33962650\n",
            "Iteration 43, loss = 0.33861250\n",
            "Iteration 44, loss = 0.33998418\n",
            "Iteration 45, loss = 0.34068882\n",
            "Iteration 46, loss = 0.34111355\n",
            "Iteration 47, loss = 0.33907835\n",
            "Iteration 48, loss = 0.34468766\n",
            "Iteration 49, loss = 0.33978041\n",
            "Iteration 50, loss = 0.33838605\n",
            "Iteration 51, loss = 0.33895384\n",
            "Iteration 52, loss = 0.33787063\n",
            "Iteration 53, loss = 0.33936621\n",
            "Iteration 54, loss = 0.33725712\n",
            "Iteration 55, loss = 0.33637386\n",
            "Iteration 56, loss = 0.33782089\n",
            "Iteration 57, loss = 0.33783713\n",
            "Iteration 58, loss = 0.34215149\n",
            "Iteration 59, loss = 0.33782716\n",
            "Iteration 60, loss = 0.33797782\n",
            "Iteration 61, loss = 0.33870615\n",
            "Iteration 62, loss = 0.33690785\n",
            "Iteration 63, loss = 0.33751359\n",
            "Iteration 64, loss = 0.33712773\n",
            "Iteration 65, loss = 0.33590567\n",
            "Iteration 66, loss = 0.34031761\n",
            "Iteration 67, loss = 0.33825642\n",
            "Iteration 68, loss = 0.33811632\n",
            "Iteration 69, loss = 0.33808232\n",
            "Iteration 70, loss = 0.33743771\n",
            "Iteration 71, loss = 0.33767810\n",
            "Iteration 72, loss = 0.33667919\n",
            "Iteration 73, loss = 0.33687260\n",
            "Iteration 74, loss = 0.34098479\n",
            "Iteration 75, loss = 0.33589146\n",
            "Iteration 76, loss = 0.33648850\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 7.12871227\n",
            "Iteration 2, loss = 7.12871084\n",
            "Iteration 3, loss = 7.12870984\n",
            "Iteration 4, loss = 7.12870887\n",
            "Iteration 5, loss = 7.12870795\n",
            "Iteration 6, loss = 7.12870710\n",
            "Iteration 7, loss = 7.12326389\n",
            "Iteration 8, loss = 7.11366449\n",
            "Iteration 9, loss = 7.08524052\n",
            "Iteration 10, loss = 6.99997215\n",
            "Iteration 11, loss = 6.82840886\n",
            "Iteration 12, loss = 6.63423915\n",
            "Iteration 13, loss = 6.40248963\n",
            "Iteration 14, loss = 6.18902270\n",
            "Iteration 15, loss = 5.95555111\n",
            "Iteration 16, loss = 5.70170004\n",
            "Iteration 17, loss = 5.43992137\n",
            "Iteration 18, loss = 5.20353722\n",
            "Iteration 19, loss = 4.90711011\n",
            "Iteration 20, loss = 4.62354722\n",
            "Iteration 21, loss = 4.36421015\n",
            "Iteration 22, loss = 4.10945002\n",
            "Iteration 23, loss = 3.88284634\n",
            "Iteration 24, loss = 3.67157006\n",
            "Iteration 25, loss = 3.46670020\n",
            "Iteration 26, loss = 3.26515925\n",
            "Iteration 27, loss = 3.06672200\n",
            "Iteration 28, loss = 2.86751272\n",
            "Iteration 29, loss = 2.65983611\n",
            "Iteration 30, loss = 2.43277249\n",
            "Iteration 31, loss = 2.24936322\n",
            "Iteration 32, loss = 2.05645192\n",
            "Iteration 33, loss = 1.87519165\n",
            "Iteration 34, loss = 1.66219379\n",
            "Iteration 35, loss = 1.42937371\n",
            "Iteration 36, loss = 1.21158903\n",
            "Iteration 37, loss = 1.03048222\n",
            "Iteration 38, loss = 0.86800187\n",
            "Iteration 39, loss = 0.72808006\n",
            "Iteration 40, loss = 0.60686738\n",
            "Iteration 41, loss = 0.50085192\n",
            "Iteration 42, loss = 0.43852106\n",
            "Iteration 43, loss = 0.41636091\n",
            "Iteration 44, loss = 0.41370314\n",
            "Iteration 45, loss = 0.41422365\n",
            "Iteration 46, loss = 0.41451525\n",
            "Iteration 47, loss = 0.41305881\n",
            "Iteration 48, loss = 0.41156806\n",
            "Iteration 49, loss = 0.41262791\n",
            "Iteration 50, loss = 0.41128049\n",
            "Iteration 51, loss = 0.41231135\n",
            "Iteration 52, loss = 0.41568337\n",
            "Iteration 53, loss = 0.41752627\n",
            "Iteration 54, loss = 0.41368167\n",
            "Iteration 55, loss = 0.41031644\n",
            "Iteration 56, loss = 0.41100702\n",
            "Iteration 57, loss = 0.41162943\n",
            "Iteration 58, loss = 0.41106364\n",
            "Iteration 59, loss = 0.41048469\n",
            "Iteration 60, loss = 0.40919025\n",
            "Iteration 61, loss = 0.40944030\n",
            "Iteration 62, loss = 0.40913917\n",
            "Iteration 63, loss = 0.40855511\n",
            "Iteration 64, loss = 0.40745280\n",
            "Iteration 65, loss = 0.40725656\n",
            "Iteration 66, loss = 0.40702935\n",
            "Iteration 67, loss = 0.40707261\n",
            "Iteration 68, loss = 0.40665097\n",
            "Iteration 69, loss = 0.40650843\n",
            "Iteration 70, loss = 0.40713841\n",
            "Iteration 71, loss = 0.40997868\n",
            "Iteration 72, loss = 0.40986378\n",
            "Iteration 73, loss = 0.40625678\n",
            "Iteration 74, loss = 0.40550245\n",
            "Iteration 75, loss = 0.40588079\n",
            "Iteration 76, loss = 0.40456398\n",
            "Iteration 77, loss = 0.40542413\n",
            "Iteration 78, loss = 0.40387889\n",
            "Iteration 79, loss = 0.40478233\n",
            "Iteration 80, loss = 0.40442680\n",
            "Iteration 81, loss = 0.40630176\n",
            "Iteration 82, loss = 0.40431827\n",
            "Iteration 83, loss = 0.40408979\n",
            "Iteration 84, loss = 0.40417521\n",
            "Iteration 85, loss = 0.40262899\n",
            "Iteration 86, loss = 0.40133824\n",
            "Iteration 87, loss = 0.40619612\n",
            "Iteration 88, loss = 0.40826907\n",
            "Iteration 89, loss = 0.40604399\n",
            "Iteration 90, loss = 0.40403006\n",
            "Iteration 91, loss = 0.40302739\n",
            "Iteration 92, loss = 0.40190401\n",
            "Iteration 93, loss = 0.40091299\n",
            "Iteration 94, loss = 0.40069091\n",
            "Iteration 95, loss = 0.39994617\n",
            "Iteration 96, loss = 0.39858024\n",
            "Iteration 97, loss = 0.39893025\n",
            "Iteration 98, loss = 0.40053014\n",
            "Iteration 99, loss = 0.39956487\n",
            "Iteration 100, loss = 0.39847690\n",
            "Iteration 101, loss = 0.39827341\n",
            "Iteration 102, loss = 0.40337979\n",
            "Iteration 103, loss = 0.40932385\n",
            "Iteration 104, loss = 0.40422460\n",
            "Iteration 105, loss = 0.39708892\n",
            "Iteration 106, loss = 0.39714801\n",
            "Iteration 107, loss = 0.39693382\n",
            "Iteration 108, loss = 0.39790630\n",
            "Iteration 109, loss = 0.39765917\n",
            "Iteration 110, loss = 0.39797444\n",
            "Iteration 111, loss = 0.39761938\n",
            "Iteration 112, loss = 0.39742277\n",
            "Iteration 113, loss = 0.39709786\n",
            "Iteration 114, loss = 0.39733830\n",
            "Iteration 115, loss = 0.39702180\n",
            "Iteration 116, loss = 0.39567857\n",
            "Iteration 117, loss = 0.39515490\n",
            "Iteration 118, loss = 0.39567486\n",
            "Iteration 119, loss = 0.39501245\n",
            "Iteration 120, loss = 0.39604059\n",
            "Iteration 121, loss = 0.39538544\n",
            "Iteration 122, loss = 0.39627794\n",
            "Iteration 123, loss = 0.39843097\n",
            "Iteration 124, loss = 0.39458984\n",
            "Iteration 125, loss = 0.39467048\n",
            "Iteration 126, loss = 0.39537428\n",
            "Iteration 127, loss = 0.39538237\n",
            "Iteration 128, loss = 0.39342931\n",
            "Iteration 129, loss = 0.39320360\n",
            "Iteration 130, loss = 0.39353775\n",
            "Iteration 131, loss = 0.39386720\n",
            "Iteration 132, loss = 0.39544931\n",
            "Iteration 133, loss = 0.39694526\n",
            "Iteration 134, loss = 0.39642286\n",
            "Iteration 135, loss = 0.39571575\n",
            "Iteration 136, loss = 0.39566995\n",
            "Iteration 137, loss = 0.39450027\n",
            "Iteration 138, loss = 0.39271671\n",
            "Iteration 139, loss = 0.39363567\n",
            "Iteration 140, loss = 0.39214012\n",
            "Iteration 141, loss = 0.39386617\n",
            "Iteration 142, loss = 0.39057489\n",
            "Iteration 143, loss = 0.39342736\n",
            "Iteration 144, loss = 0.39229663\n",
            "Iteration 145, loss = 0.39165375\n",
            "Iteration 146, loss = 0.39196404\n",
            "Iteration 147, loss = 0.39156994\n",
            "Iteration 148, loss = 0.39185634\n",
            "Iteration 149, loss = 0.39042741\n",
            "Iteration 150, loss = 0.39047749\n",
            "Iteration 151, loss = 0.39065773\n",
            "Iteration 152, loss = 0.38979801\n",
            "Iteration 153, loss = 0.39035610\n",
            "Iteration 154, loss = 0.39083206\n",
            "Iteration 155, loss = 0.39271657\n",
            "Iteration 156, loss = 0.38762988\n",
            "Iteration 157, loss = 0.39062057\n",
            "Iteration 158, loss = 0.39034548\n",
            "Iteration 159, loss = 0.38799530\n",
            "Iteration 160, loss = 0.38872389\n",
            "Iteration 161, loss = 0.39020709\n",
            "Iteration 162, loss = 0.39590603\n",
            "Iteration 163, loss = 0.39203399\n",
            "Iteration 164, loss = 0.39248236\n",
            "Iteration 165, loss = 0.39671613\n",
            "Iteration 166, loss = 0.39377784\n",
            "Iteration 167, loss = 0.38975269\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.88841557\n",
            "Iteration 2, loss = 6.88841299\n",
            "Iteration 3, loss = 6.88590458\n",
            "Iteration 4, loss = 6.87140796\n",
            "Iteration 5, loss = 6.69285463\n",
            "Iteration 6, loss = 6.30240000\n",
            "Iteration 7, loss = 5.83356034\n",
            "Iteration 8, loss = 5.32590150\n",
            "Iteration 9, loss = 4.79425849\n",
            "Iteration 10, loss = 4.27262644\n",
            "Iteration 11, loss = 3.76717927\n",
            "Iteration 12, loss = 3.29727189\n",
            "Iteration 13, loss = 2.83471411\n",
            "Iteration 14, loss = 2.42576721\n",
            "Iteration 15, loss = 2.02818363\n",
            "Iteration 16, loss = 1.64410634\n",
            "Iteration 17, loss = 1.27330443\n",
            "Iteration 18, loss = 0.91752736\n",
            "Iteration 19, loss = 0.61458840\n",
            "Iteration 20, loss = 0.44861847\n",
            "Iteration 21, loss = 0.43188421\n",
            "Iteration 22, loss = 0.43051718\n",
            "Iteration 23, loss = 0.43109445\n",
            "Iteration 24, loss = 0.42796550\n",
            "Iteration 25, loss = 0.42606025\n",
            "Iteration 26, loss = 0.42519725\n",
            "Iteration 27, loss = 0.42487784\n",
            "Iteration 28, loss = 0.42608287\n",
            "Iteration 29, loss = 0.42377914\n",
            "Iteration 30, loss = 0.42359999\n",
            "Iteration 31, loss = 0.42579266\n",
            "Iteration 32, loss = 0.42642845\n",
            "Iteration 33, loss = 0.42192923\n",
            "Iteration 34, loss = 0.42166754\n",
            "Iteration 35, loss = 0.41985692\n",
            "Iteration 36, loss = 0.41980653\n",
            "Iteration 37, loss = 0.41912417\n",
            "Iteration 38, loss = 0.41858041\n",
            "Iteration 39, loss = 0.41848925\n",
            "Iteration 40, loss = 0.41820831\n",
            "Iteration 41, loss = 0.41747357\n",
            "Iteration 42, loss = 0.41650998\n",
            "Iteration 43, loss = 0.41589364\n",
            "Iteration 44, loss = 0.41663739\n",
            "Iteration 45, loss = 0.41532824\n",
            "Iteration 46, loss = 0.41459672\n",
            "Iteration 47, loss = 0.41399724\n",
            "Iteration 48, loss = 0.41358999\n",
            "Iteration 49, loss = 0.41649552\n",
            "Iteration 50, loss = 0.41212059\n",
            "Iteration 51, loss = 0.41430124\n",
            "Iteration 52, loss = 0.41188774\n",
            "Iteration 53, loss = 0.41037284\n",
            "Iteration 54, loss = 0.41254508\n",
            "Iteration 55, loss = 0.41071802\n",
            "Iteration 56, loss = 0.41081769\n",
            "Iteration 57, loss = 0.41303598\n",
            "Iteration 58, loss = 0.41076042\n",
            "Iteration 59, loss = 0.40908790\n",
            "Iteration 60, loss = 0.40884713\n",
            "Iteration 61, loss = 0.40885915\n",
            "Iteration 62, loss = 0.40807583\n",
            "Iteration 63, loss = 0.40746826\n",
            "Iteration 64, loss = 0.40784650\n",
            "Iteration 65, loss = 0.40681604\n",
            "Iteration 66, loss = 0.40642529\n",
            "Iteration 67, loss = 0.40590356\n",
            "Iteration 68, loss = 0.40598873\n",
            "Iteration 69, loss = 0.40509396\n",
            "Iteration 70, loss = 0.40730725\n",
            "Iteration 71, loss = 0.40461315\n",
            "Iteration 72, loss = 0.40447111\n",
            "Iteration 73, loss = 0.40366540\n",
            "Iteration 74, loss = 0.40611768\n",
            "Iteration 75, loss = 0.40763359\n",
            "Iteration 76, loss = 0.40351927\n",
            "Iteration 77, loss = 0.40260919\n",
            "Iteration 78, loss = 0.40209491\n",
            "Iteration 79, loss = 0.40147143\n",
            "Iteration 80, loss = 0.40076799\n",
            "Iteration 81, loss = 0.40550526\n",
            "Iteration 82, loss = 0.40043574\n",
            "Iteration 83, loss = 0.39985327\n",
            "Iteration 84, loss = 0.40474788\n",
            "Iteration 85, loss = 0.40002239\n",
            "Iteration 86, loss = 0.39865565\n",
            "Iteration 87, loss = 0.39913902\n",
            "Iteration 88, loss = 0.39848621\n",
            "Iteration 89, loss = 0.39861231\n",
            "Iteration 90, loss = 0.39738206\n",
            "Iteration 91, loss = 0.39819313\n",
            "Iteration 92, loss = 0.39869431\n",
            "Iteration 93, loss = 0.39671090\n",
            "Iteration 94, loss = 0.39806494\n",
            "Iteration 95, loss = 0.39664781\n",
            "Iteration 96, loss = 0.39728316\n",
            "Iteration 97, loss = 0.39654073\n",
            "Iteration 98, loss = 0.39730214\n",
            "Iteration 99, loss = 0.39563344\n",
            "Iteration 100, loss = 0.39522642\n",
            "Iteration 101, loss = 0.39504194\n",
            "Iteration 102, loss = 0.39399844\n",
            "Iteration 103, loss = 0.39410640\n",
            "Iteration 104, loss = 0.39402297\n",
            "Iteration 105, loss = 0.39476692\n",
            "Iteration 106, loss = 0.39378251\n",
            "Iteration 107, loss = 0.39278388\n",
            "Iteration 108, loss = 0.39633373\n",
            "Iteration 109, loss = 0.39213954\n",
            "Iteration 110, loss = 0.39438791\n",
            "Iteration 111, loss = 0.39395294\n",
            "Iteration 112, loss = 0.39218867\n",
            "Iteration 113, loss = 0.39145335\n",
            "Iteration 114, loss = 0.39178432\n",
            "Iteration 115, loss = 0.39554411\n",
            "Iteration 116, loss = 0.39043291\n",
            "Iteration 117, loss = 0.39148855\n",
            "Iteration 118, loss = 0.39087955\n",
            "Iteration 119, loss = 0.39357477\n",
            "Iteration 120, loss = 0.39169458\n",
            "Iteration 121, loss = 0.39159179\n",
            "Iteration 122, loss = 0.38988586\n",
            "Iteration 123, loss = 0.38940125\n",
            "Iteration 124, loss = 0.38932009\n",
            "Iteration 125, loss = 0.38949155\n",
            "Iteration 126, loss = 0.38887263\n",
            "Iteration 127, loss = 0.38926921\n",
            "Iteration 128, loss = 0.38901051\n",
            "Iteration 129, loss = 0.39074775\n",
            "Iteration 130, loss = 0.38868705\n",
            "Iteration 131, loss = 0.38940099\n",
            "Iteration 132, loss = 0.38788378\n",
            "Iteration 133, loss = 0.38908563\n",
            "Iteration 134, loss = 0.38690754\n",
            "Iteration 135, loss = 0.38697162\n",
            "Iteration 136, loss = 0.38990769\n",
            "Iteration 137, loss = 0.39280119\n",
            "Iteration 138, loss = 0.39021450\n",
            "Iteration 139, loss = 0.38793700\n",
            "Iteration 140, loss = 0.39306321\n",
            "Iteration 141, loss = 0.38622359\n",
            "Iteration 142, loss = 0.38902204\n",
            "Iteration 143, loss = 0.38743874\n",
            "Iteration 144, loss = 0.38769719\n",
            "Iteration 145, loss = 0.38883753\n",
            "Iteration 146, loss = 0.38753171\n",
            "Iteration 147, loss = 0.38610580\n",
            "Iteration 148, loss = 0.38692537\n",
            "Iteration 149, loss = 0.38447314\n",
            "Iteration 150, loss = 0.38758978\n",
            "Iteration 151, loss = 0.38914216\n",
            "Iteration 152, loss = 0.38915681\n",
            "Iteration 153, loss = 0.38953872\n",
            "Iteration 154, loss = 0.38440939\n",
            "Iteration 155, loss = 0.38703313\n",
            "Iteration 156, loss = 0.38384453\n",
            "Iteration 157, loss = 0.38390918\n",
            "Iteration 158, loss = 0.38346736\n",
            "Iteration 159, loss = 0.38455374\n",
            "Iteration 160, loss = 0.38757367\n",
            "Iteration 161, loss = 0.38670003\n",
            "Iteration 162, loss = 0.38482421\n",
            "Iteration 163, loss = 0.38438066\n",
            "Iteration 164, loss = 0.38355825\n",
            "Iteration 165, loss = 0.38804175\n",
            "Iteration 166, loss = 0.38256213\n",
            "Iteration 167, loss = 0.38392714\n",
            "Iteration 168, loss = 0.38592754\n",
            "Iteration 169, loss = 0.38224906\n",
            "Iteration 170, loss = 0.38232458\n",
            "Iteration 171, loss = 0.38370611\n",
            "Iteration 172, loss = 0.38505964\n",
            "Iteration 173, loss = 0.38333426\n",
            "Iteration 174, loss = 0.38224712\n",
            "Iteration 175, loss = 0.38217530\n",
            "Iteration 176, loss = 0.39391597\n",
            "Iteration 177, loss = 0.38969316\n",
            "Iteration 178, loss = 0.38402904\n",
            "Iteration 179, loss = 0.38407692\n",
            "Iteration 180, loss = 0.39048847\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.37650962\n",
            "Iteration 2, loss = 6.37460461\n",
            "Iteration 3, loss = 6.32679594\n",
            "Iteration 4, loss = 5.92811639\n",
            "Iteration 5, loss = 5.30490966\n",
            "Iteration 6, loss = 4.61306721\n",
            "Iteration 7, loss = 3.92598686\n",
            "Iteration 8, loss = 3.29140923\n",
            "Iteration 9, loss = 2.67424447\n",
            "Iteration 10, loss = 2.09449039\n",
            "Iteration 11, loss = 1.54866118\n",
            "Iteration 12, loss = 1.01400260\n",
            "Iteration 13, loss = 0.58389157\n",
            "Iteration 14, loss = 0.41891242\n",
            "Iteration 15, loss = 0.40911573\n",
            "Iteration 16, loss = 0.40776618\n",
            "Iteration 17, loss = 0.40643129\n",
            "Iteration 18, loss = 0.40648356\n",
            "Iteration 19, loss = 0.40743940\n",
            "Iteration 20, loss = 0.40495034\n",
            "Iteration 21, loss = 0.40376984\n",
            "Iteration 22, loss = 0.40296235\n",
            "Iteration 23, loss = 0.40153679\n",
            "Iteration 24, loss = 0.40049780\n",
            "Iteration 25, loss = 0.40000737\n",
            "Iteration 26, loss = 0.39855980\n",
            "Iteration 27, loss = 0.39797752\n",
            "Iteration 28, loss = 0.39622774\n",
            "Iteration 29, loss = 0.39679382\n",
            "Iteration 30, loss = 0.39559501\n",
            "Iteration 31, loss = 0.39523484\n",
            "Iteration 32, loss = 0.39345231\n",
            "Iteration 33, loss = 0.39290780\n",
            "Iteration 34, loss = 0.39236696\n",
            "Iteration 35, loss = 0.39273773\n",
            "Iteration 36, loss = 0.39101039\n",
            "Iteration 37, loss = 0.39121177\n",
            "Iteration 38, loss = 0.39001838\n",
            "Iteration 39, loss = 0.38929849\n",
            "Iteration 40, loss = 0.38837547\n",
            "Iteration 41, loss = 0.38934197\n",
            "Iteration 42, loss = 0.38836631\n",
            "Iteration 43, loss = 0.38789092\n",
            "Iteration 44, loss = 0.38591491\n",
            "Iteration 45, loss = 0.38566486\n",
            "Iteration 46, loss = 0.38585822\n",
            "Iteration 47, loss = 0.38451378\n",
            "Iteration 48, loss = 0.38482283\n",
            "Iteration 49, loss = 0.38355496\n",
            "Iteration 50, loss = 0.38353965\n",
            "Iteration 51, loss = 0.38273613\n",
            "Iteration 52, loss = 0.38343661\n",
            "Iteration 53, loss = 0.38584350\n",
            "Iteration 54, loss = 0.38379468\n",
            "Iteration 55, loss = 0.38174325\n",
            "Iteration 56, loss = 0.38092883\n",
            "Iteration 57, loss = 0.38007554\n",
            "Iteration 58, loss = 0.37978973\n",
            "Iteration 59, loss = 0.37941844\n",
            "Iteration 60, loss = 0.38261379\n",
            "Iteration 61, loss = 0.38072581\n",
            "Iteration 62, loss = 0.37945365\n",
            "Iteration 63, loss = 0.37736865\n",
            "Iteration 64, loss = 0.37827065\n",
            "Iteration 65, loss = 0.37735031\n",
            "Iteration 66, loss = 0.37771741\n",
            "Iteration 67, loss = 0.37697124\n",
            "Iteration 68, loss = 0.37562851\n",
            "Iteration 69, loss = 0.37495570\n",
            "Iteration 70, loss = 0.37553384\n",
            "Iteration 71, loss = 0.37428178\n",
            "Iteration 72, loss = 0.37473865\n",
            "Iteration 73, loss = 0.37444509\n",
            "Iteration 74, loss = 0.37248273\n",
            "Iteration 75, loss = 0.37359084\n",
            "Iteration 76, loss = 0.37283504\n",
            "Iteration 77, loss = 0.37175260\n",
            "Iteration 78, loss = 0.37227226\n",
            "Iteration 79, loss = 0.37563532\n",
            "Iteration 80, loss = 0.37628531\n",
            "Iteration 81, loss = 0.37267160\n",
            "Iteration 82, loss = 0.37167191\n",
            "Iteration 83, loss = 0.37044586\n",
            "Iteration 84, loss = 0.37106079\n",
            "Iteration 85, loss = 0.37008737\n",
            "Iteration 86, loss = 0.37178660\n",
            "Iteration 87, loss = 0.36950053\n",
            "Iteration 88, loss = 0.37000429\n",
            "Iteration 89, loss = 0.37002825\n",
            "Iteration 90, loss = 0.36915426\n",
            "Iteration 91, loss = 0.37138916\n",
            "Iteration 92, loss = 0.37001261\n",
            "Iteration 93, loss = 0.36946653\n",
            "Iteration 94, loss = 0.36964929\n",
            "Iteration 95, loss = 0.36799287\n",
            "Iteration 96, loss = 0.36793468\n",
            "Iteration 97, loss = 0.36771439\n",
            "Iteration 98, loss = 0.36750946\n",
            "Iteration 99, loss = 0.36682998\n",
            "Iteration 100, loss = 0.36622164\n",
            "Iteration 101, loss = 0.36762336\n",
            "Iteration 102, loss = 0.36801260\n",
            "Iteration 103, loss = 0.36642067\n",
            "Iteration 104, loss = 0.36638068\n",
            "Iteration 105, loss = 0.36529510\n",
            "Iteration 106, loss = 0.36527116\n",
            "Iteration 107, loss = 0.37174271\n",
            "Iteration 108, loss = 0.36592916\n",
            "Iteration 109, loss = 0.36528426\n",
            "Iteration 110, loss = 0.36554148\n",
            "Iteration 111, loss = 0.36463885\n",
            "Iteration 112, loss = 0.36532912\n",
            "Iteration 113, loss = 0.36473681\n",
            "Iteration 114, loss = 0.36558612\n",
            "Iteration 115, loss = 0.36694847\n",
            "Iteration 116, loss = 0.36775970\n",
            "Iteration 117, loss = 0.36438401\n",
            "Iteration 118, loss = 0.36359023\n",
            "Iteration 119, loss = 0.36393367\n",
            "Iteration 120, loss = 0.36462195\n",
            "Iteration 121, loss = 0.36407387\n",
            "Iteration 122, loss = 0.36234182\n",
            "Iteration 123, loss = 0.36474798\n",
            "Iteration 124, loss = 0.36290823\n",
            "Iteration 125, loss = 0.36381231\n",
            "Iteration 126, loss = 0.36253101\n",
            "Iteration 127, loss = 0.36106937\n",
            "Iteration 128, loss = 0.36200814\n",
            "Iteration 129, loss = 0.36181105\n",
            "Iteration 130, loss = 0.36289251\n",
            "Iteration 131, loss = 0.36770900\n",
            "Iteration 132, loss = 0.36146143\n",
            "Iteration 133, loss = 0.36190905\n",
            "Iteration 134, loss = 0.36139139\n",
            "Iteration 135, loss = 0.36094096\n",
            "Iteration 136, loss = 0.36203546\n",
            "Iteration 137, loss = 0.36257842\n",
            "Iteration 138, loss = 0.36133458\n",
            "Iteration 139, loss = 0.35987200\n",
            "Iteration 140, loss = 0.36308841\n",
            "Iteration 141, loss = 0.36050178\n",
            "Iteration 142, loss = 0.36204110\n",
            "Iteration 143, loss = 0.35891102\n",
            "Iteration 144, loss = 0.35948819\n",
            "Iteration 145, loss = 0.35902029\n",
            "Iteration 146, loss = 0.35906957\n",
            "Iteration 147, loss = 0.35977171\n",
            "Iteration 148, loss = 0.36185070\n",
            "Iteration 149, loss = 0.36122386\n",
            "Iteration 150, loss = 0.35867582\n",
            "Iteration 151, loss = 0.35890993\n",
            "Iteration 152, loss = 0.36399829\n",
            "Iteration 153, loss = 0.36038207\n",
            "Iteration 154, loss = 0.36371779\n",
            "Iteration 155, loss = 0.35987489\n",
            "Iteration 156, loss = 0.35769604\n",
            "Iteration 157, loss = 0.35821825\n",
            "Iteration 158, loss = 0.35890248\n",
            "Iteration 159, loss = 0.35759455\n",
            "Iteration 160, loss = 0.35977708\n",
            "Iteration 161, loss = 0.35802106\n",
            "Iteration 162, loss = 0.35821495\n",
            "Iteration 163, loss = 0.36052558\n",
            "Iteration 164, loss = 0.35953093\n",
            "Iteration 165, loss = 0.35944236\n",
            "Iteration 166, loss = 0.36168586\n",
            "Iteration 167, loss = 0.35658557\n",
            "Iteration 168, loss = 0.35827662\n",
            "Iteration 169, loss = 0.35863738\n",
            "Iteration 170, loss = 0.35727476\n",
            "Iteration 171, loss = 0.35699474\n",
            "Iteration 172, loss = 0.35702226\n",
            "Iteration 173, loss = 0.35778789\n",
            "Iteration 174, loss = 0.35882566\n",
            "Iteration 175, loss = 0.35607465\n",
            "Iteration 176, loss = 0.35668373\n",
            "Iteration 177, loss = 0.35530223\n",
            "Iteration 178, loss = 0.36025295\n",
            "Iteration 179, loss = 0.36154479\n",
            "Iteration 180, loss = 0.35821730\n",
            "Iteration 181, loss = 0.35972414\n",
            "Iteration 182, loss = 0.35961570\n",
            "Iteration 183, loss = 0.35947180\n",
            "Iteration 184, loss = 0.35754688\n",
            "Iteration 185, loss = 0.35565449\n",
            "Iteration 186, loss = 0.35934017\n",
            "Iteration 187, loss = 0.35605533\n",
            "Iteration 188, loss = 0.35849679\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.16420017\n",
            "Iteration 2, loss = 6.15598127\n",
            "Iteration 3, loss = 5.85551546\n",
            "Iteration 4, loss = 5.03693623\n",
            "Iteration 5, loss = 4.12375440\n",
            "Iteration 6, loss = 3.24011338\n",
            "Iteration 7, loss = 2.45595300\n",
            "Iteration 8, loss = 1.72396518\n",
            "Iteration 9, loss = 1.07079916\n",
            "Iteration 10, loss = 0.53747614\n",
            "Iteration 11, loss = 0.39960290\n",
            "Iteration 12, loss = 0.39436386\n",
            "Iteration 13, loss = 0.39395601\n",
            "Iteration 14, loss = 0.39273769\n",
            "Iteration 15, loss = 0.39107435\n",
            "Iteration 16, loss = 0.39026525\n",
            "Iteration 17, loss = 0.38884590\n",
            "Iteration 18, loss = 0.38790502\n",
            "Iteration 19, loss = 0.38880573\n",
            "Iteration 20, loss = 0.38616430\n",
            "Iteration 21, loss = 0.38579675\n",
            "Iteration 22, loss = 0.38351588\n",
            "Iteration 23, loss = 0.38264605\n",
            "Iteration 24, loss = 0.38205234\n",
            "Iteration 25, loss = 0.38305036\n",
            "Iteration 26, loss = 0.38022033\n",
            "Iteration 27, loss = 0.37914842\n",
            "Iteration 28, loss = 0.37919635\n",
            "Iteration 29, loss = 0.37910352\n",
            "Iteration 30, loss = 0.37698325\n",
            "Iteration 31, loss = 0.37604524\n",
            "Iteration 32, loss = 0.37511560\n",
            "Iteration 33, loss = 0.37488459\n",
            "Iteration 34, loss = 0.37391448\n",
            "Iteration 35, loss = 0.37301334\n",
            "Iteration 36, loss = 0.37264612\n",
            "Iteration 37, loss = 0.37206826\n",
            "Iteration 38, loss = 0.37140277\n",
            "Iteration 39, loss = 0.37020533\n",
            "Iteration 40, loss = 0.37014967\n",
            "Iteration 41, loss = 0.36967770\n",
            "Iteration 42, loss = 0.36833614\n",
            "Iteration 43, loss = 0.36799979\n",
            "Iteration 44, loss = 0.36746215\n",
            "Iteration 45, loss = 0.36810304\n",
            "Iteration 46, loss = 0.36656249\n",
            "Iteration 47, loss = 0.36638588\n",
            "Iteration 48, loss = 0.36539454\n",
            "Iteration 49, loss = 0.36448429\n",
            "Iteration 50, loss = 0.36496272\n",
            "Iteration 51, loss = 0.36349169\n",
            "Iteration 52, loss = 0.36538537\n",
            "Iteration 53, loss = 0.36255721\n",
            "Iteration 54, loss = 0.36400268\n",
            "Iteration 55, loss = 0.36379390\n",
            "Iteration 56, loss = 0.36096003\n",
            "Iteration 57, loss = 0.36090150\n",
            "Iteration 58, loss = 0.36019379\n",
            "Iteration 59, loss = 0.36021331\n",
            "Iteration 60, loss = 0.36128654\n",
            "Iteration 61, loss = 0.36097220\n",
            "Iteration 62, loss = 0.35992932\n",
            "Iteration 63, loss = 0.36070071\n",
            "Iteration 64, loss = 0.35793058\n",
            "Iteration 65, loss = 0.35845649\n",
            "Iteration 66, loss = 0.35774798\n",
            "Iteration 67, loss = 0.35735253\n",
            "Iteration 68, loss = 0.35795121\n",
            "Iteration 69, loss = 0.35742731\n",
            "Iteration 70, loss = 0.35686666\n",
            "Iteration 71, loss = 0.35662183\n",
            "Iteration 72, loss = 0.35630568\n",
            "Iteration 73, loss = 0.35773439\n",
            "Iteration 74, loss = 0.35562005\n",
            "Iteration 75, loss = 0.35566218\n",
            "Iteration 76, loss = 0.35522714\n",
            "Iteration 77, loss = 0.35455969\n",
            "Iteration 78, loss = 0.35555756\n",
            "Iteration 79, loss = 0.35743352\n",
            "Iteration 80, loss = 0.35590519\n",
            "Iteration 81, loss = 0.35510467\n",
            "Iteration 82, loss = 0.35426146\n",
            "Iteration 83, loss = 0.35541521\n",
            "Iteration 84, loss = 0.35367658\n",
            "Iteration 85, loss = 0.35310757\n",
            "Iteration 86, loss = 0.35608578\n",
            "Iteration 87, loss = 0.35458903\n",
            "Iteration 88, loss = 0.35702779\n",
            "Iteration 89, loss = 0.35236934\n",
            "Iteration 90, loss = 0.35427202\n",
            "Iteration 91, loss = 0.35717514\n",
            "Iteration 92, loss = 0.35242899\n",
            "Iteration 93, loss = 0.35199646\n",
            "Iteration 94, loss = 0.35118703\n",
            "Iteration 95, loss = 0.35335013\n",
            "Iteration 96, loss = 0.35148263\n",
            "Iteration 97, loss = 0.35220611\n",
            "Iteration 98, loss = 0.35035301\n",
            "Iteration 99, loss = 0.34985143\n",
            "Iteration 100, loss = 0.35090806\n",
            "Iteration 101, loss = 0.35002361\n",
            "Iteration 102, loss = 0.35101822\n",
            "Iteration 103, loss = 0.34900561\n",
            "Iteration 104, loss = 0.34952910\n",
            "Iteration 105, loss = 0.35132808\n",
            "Iteration 106, loss = 0.34974480\n",
            "Iteration 107, loss = 0.35114350\n",
            "Iteration 108, loss = 0.35032639\n",
            "Iteration 109, loss = 0.34877586\n",
            "Iteration 110, loss = 0.34861032\n",
            "Iteration 111, loss = 0.34951804\n",
            "Iteration 112, loss = 0.34830846\n",
            "Iteration 113, loss = 0.34937123\n",
            "Iteration 114, loss = 0.35039661\n",
            "Iteration 115, loss = 0.34853567\n",
            "Iteration 116, loss = 0.34857071\n",
            "Iteration 117, loss = 0.34811593\n",
            "Iteration 118, loss = 0.34779063\n",
            "Iteration 119, loss = 0.34872229\n",
            "Iteration 120, loss = 0.34601102\n",
            "Iteration 121, loss = 0.34666823\n",
            "Iteration 122, loss = 0.34593044\n",
            "Iteration 123, loss = 0.34602743\n",
            "Iteration 124, loss = 0.34913105\n",
            "Iteration 125, loss = 0.34990628\n",
            "Iteration 126, loss = 0.34854265\n",
            "Iteration 127, loss = 0.34543778\n",
            "Iteration 128, loss = 0.34700395\n",
            "Iteration 129, loss = 0.34687763\n",
            "Iteration 130, loss = 0.34589812\n",
            "Iteration 131, loss = 0.34538596\n",
            "Iteration 132, loss = 0.35028291\n",
            "Iteration 133, loss = 0.34620124\n",
            "Iteration 134, loss = 0.34603784\n",
            "Iteration 135, loss = 0.34731616\n",
            "Iteration 136, loss = 0.34688992\n",
            "Iteration 137, loss = 0.34584236\n",
            "Iteration 138, loss = 0.34705304\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.19416629\n",
            "Iteration 2, loss = 6.11964712\n",
            "Iteration 3, loss = 5.38769819\n",
            "Iteration 4, loss = 4.28499573\n",
            "Iteration 5, loss = 3.18395368\n",
            "Iteration 6, loss = 2.16174053\n",
            "Iteration 7, loss = 1.26696426\n",
            "Iteration 8, loss = 0.55722300\n",
            "Iteration 9, loss = 0.40572278\n",
            "Iteration 10, loss = 0.40334362\n",
            "Iteration 11, loss = 0.40133453\n",
            "Iteration 12, loss = 0.40064799\n",
            "Iteration 13, loss = 0.39801787\n",
            "Iteration 14, loss = 0.39683932\n",
            "Iteration 15, loss = 0.39587845\n",
            "Iteration 16, loss = 0.39429164\n",
            "Iteration 17, loss = 0.39481572\n",
            "Iteration 18, loss = 0.39200355\n",
            "Iteration 19, loss = 0.39055476\n",
            "Iteration 20, loss = 0.38929903\n",
            "Iteration 21, loss = 0.38909894\n",
            "Iteration 22, loss = 0.38724601\n",
            "Iteration 23, loss = 0.38661305\n",
            "Iteration 24, loss = 0.38492311\n",
            "Iteration 25, loss = 0.38401196\n",
            "Iteration 26, loss = 0.38282277\n",
            "Iteration 27, loss = 0.38394132\n",
            "Iteration 28, loss = 0.38159300\n",
            "Iteration 29, loss = 0.38071773\n",
            "Iteration 30, loss = 0.38006064\n",
            "Iteration 31, loss = 0.37912593\n",
            "Iteration 32, loss = 0.37907443\n",
            "Iteration 33, loss = 0.37681042\n",
            "Iteration 34, loss = 0.37694469\n",
            "Iteration 35, loss = 0.37519906\n",
            "Iteration 36, loss = 0.37417854\n",
            "Iteration 37, loss = 0.37431977\n",
            "Iteration 38, loss = 0.37325263\n",
            "Iteration 39, loss = 0.37415172\n",
            "Iteration 40, loss = 0.37144448\n",
            "Iteration 41, loss = 0.37104423\n",
            "Iteration 42, loss = 0.36997174\n",
            "Iteration 43, loss = 0.37008133\n",
            "Iteration 44, loss = 0.36948840\n",
            "Iteration 45, loss = 0.36975976\n",
            "Iteration 46, loss = 0.36840123\n",
            "Iteration 47, loss = 0.36862928\n",
            "Iteration 48, loss = 0.36965081\n",
            "Iteration 49, loss = 0.36654568\n",
            "Iteration 50, loss = 0.36701077\n",
            "Iteration 51, loss = 0.36613179\n",
            "Iteration 52, loss = 0.36513281\n",
            "Iteration 53, loss = 0.36615746\n",
            "Iteration 54, loss = 0.36553549\n",
            "Iteration 55, loss = 0.36561725\n",
            "Iteration 56, loss = 0.36390312\n",
            "Iteration 57, loss = 0.36355986\n",
            "Iteration 58, loss = 0.36271776\n",
            "Iteration 59, loss = 0.36302853\n",
            "Iteration 60, loss = 0.36503972\n",
            "Iteration 61, loss = 0.36271648\n",
            "Iteration 62, loss = 0.36347254\n",
            "Iteration 63, loss = 0.36309065\n",
            "Iteration 64, loss = 0.36070568\n",
            "Iteration 65, loss = 0.36249232\n",
            "Iteration 66, loss = 0.36267110\n",
            "Iteration 67, loss = 0.36177636\n",
            "Iteration 68, loss = 0.36264669\n",
            "Iteration 69, loss = 0.36073922\n",
            "Iteration 70, loss = 0.35885718\n",
            "Iteration 71, loss = 0.35936749\n",
            "Iteration 72, loss = 0.35994746\n",
            "Iteration 73, loss = 0.35987631\n",
            "Iteration 74, loss = 0.35934612\n",
            "Iteration 75, loss = 0.35898675\n",
            "Iteration 76, loss = 0.35747712\n",
            "Iteration 77, loss = 0.35831309\n",
            "Iteration 78, loss = 0.36228899\n",
            "Iteration 79, loss = 0.35652968\n",
            "Iteration 80, loss = 0.35763688\n",
            "Iteration 81, loss = 0.35636920\n",
            "Iteration 82, loss = 0.35613816\n",
            "Iteration 83, loss = 0.35556615\n",
            "Iteration 84, loss = 0.35710627\n",
            "Iteration 85, loss = 0.35456748\n",
            "Iteration 86, loss = 0.35524834\n",
            "Iteration 87, loss = 0.35575120\n",
            "Iteration 88, loss = 0.35405677\n",
            "Iteration 89, loss = 0.35653240\n",
            "Iteration 90, loss = 0.35441585\n",
            "Iteration 91, loss = 0.35340142\n",
            "Iteration 92, loss = 0.35263372\n",
            "Iteration 93, loss = 0.35267311\n",
            "Iteration 94, loss = 0.35272869\n",
            "Iteration 95, loss = 0.35309239\n",
            "Iteration 96, loss = 0.35139265\n",
            "Iteration 97, loss = 0.35428533\n",
            "Iteration 98, loss = 0.35418791\n",
            "Iteration 99, loss = 0.35270936\n",
            "Iteration 100, loss = 0.35236163\n",
            "Iteration 101, loss = 0.35062675\n",
            "Iteration 102, loss = 0.35255017\n",
            "Iteration 103, loss = 0.35120916\n",
            "Iteration 104, loss = 0.35238422\n",
            "Iteration 105, loss = 0.35214505\n",
            "Iteration 106, loss = 0.35066781\n",
            "Iteration 107, loss = 0.35189335\n",
            "Iteration 108, loss = 0.35057042\n",
            "Iteration 109, loss = 0.35080262\n",
            "Iteration 110, loss = 0.35040940\n",
            "Iteration 111, loss = 0.35055940\n",
            "Iteration 112, loss = 0.35197192\n",
            "Iteration 113, loss = 0.35334136\n",
            "Iteration 114, loss = 0.34928913\n",
            "Iteration 115, loss = 0.34904725\n",
            "Iteration 116, loss = 0.34885457\n",
            "Iteration 117, loss = 0.34914067\n",
            "Iteration 118, loss = 0.35266351\n",
            "Iteration 119, loss = 0.34893597\n",
            "Iteration 120, loss = 0.34987436\n",
            "Iteration 121, loss = 0.34926886\n",
            "Iteration 122, loss = 0.34824511\n",
            "Iteration 123, loss = 0.34914502\n",
            "Iteration 124, loss = 0.34720983\n",
            "Iteration 125, loss = 0.34797038\n",
            "Iteration 126, loss = 0.35042785\n",
            "Iteration 127, loss = 0.34778291\n",
            "Iteration 128, loss = 0.34825280\n",
            "Iteration 129, loss = 0.34656843\n",
            "Iteration 130, loss = 0.34923921\n",
            "Iteration 131, loss = 0.34884184\n",
            "Iteration 132, loss = 0.34600983\n",
            "Iteration 133, loss = 0.34589067\n",
            "Iteration 134, loss = 0.34796407\n",
            "Iteration 135, loss = 0.34640227\n",
            "Iteration 136, loss = 0.34732892\n",
            "Iteration 137, loss = 0.35311015\n",
            "Iteration 138, loss = 0.34734102\n",
            "Iteration 139, loss = 0.34544968\n",
            "Iteration 140, loss = 0.34582092\n",
            "Iteration 141, loss = 0.34674485\n",
            "Iteration 142, loss = 0.34590305\n",
            "Iteration 143, loss = 0.34659112\n",
            "Iteration 144, loss = 0.35353111\n",
            "Iteration 145, loss = 0.34516307\n",
            "Iteration 146, loss = 0.34785147\n",
            "Iteration 147, loss = 0.34883120\n",
            "Iteration 148, loss = 0.34659195\n",
            "Iteration 149, loss = 0.34770721\n",
            "Iteration 150, loss = 0.35034459\n",
            "Iteration 151, loss = 0.34612183\n",
            "Iteration 152, loss = 0.34677311\n",
            "Iteration 153, loss = 0.34462324\n",
            "Iteration 154, loss = 0.34471992\n",
            "Iteration 155, loss = 0.34824297\n",
            "Iteration 156, loss = 0.34548379\n",
            "Iteration 157, loss = 0.34498631\n",
            "Iteration 158, loss = 0.34550733\n",
            "Iteration 159, loss = 0.34503577\n",
            "Iteration 160, loss = 0.34585579\n",
            "Iteration 161, loss = 0.34357553\n",
            "Iteration 162, loss = 0.34692458\n",
            "Iteration 163, loss = 0.34555031\n",
            "Iteration 164, loss = 0.34502883\n",
            "Iteration 165, loss = 0.34511134\n",
            "Iteration 166, loss = 0.34583357\n",
            "Iteration 167, loss = 0.34411833\n",
            "Iteration 168, loss = 0.34448289\n",
            "Iteration 169, loss = 0.34757104\n",
            "Iteration 170, loss = 0.34479779\n",
            "Iteration 171, loss = 0.34596923\n",
            "Iteration 172, loss = 0.35537356\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.16297195\n",
            "Iteration 2, loss = 5.92285547\n",
            "Iteration 3, loss = 4.75071872\n",
            "Iteration 4, loss = 3.45612791\n",
            "Iteration 5, loss = 2.24756174\n",
            "Iteration 6, loss = 1.20249385\n",
            "Iteration 7, loss = 0.49251837\n",
            "Iteration 8, loss = 0.40303917\n",
            "Iteration 9, loss = 0.40076165\n",
            "Iteration 10, loss = 0.39844570\n",
            "Iteration 11, loss = 0.39664625\n",
            "Iteration 12, loss = 0.39515508\n",
            "Iteration 13, loss = 0.39364518\n",
            "Iteration 14, loss = 0.39203622\n",
            "Iteration 15, loss = 0.38959817\n",
            "Iteration 16, loss = 0.39006753\n",
            "Iteration 17, loss = 0.38737435\n",
            "Iteration 18, loss = 0.38654060\n",
            "Iteration 19, loss = 0.38525514\n",
            "Iteration 20, loss = 0.38407363\n",
            "Iteration 21, loss = 0.38363529\n",
            "Iteration 22, loss = 0.38188721\n",
            "Iteration 23, loss = 0.38203564\n",
            "Iteration 24, loss = 0.37995796\n",
            "Iteration 25, loss = 0.37902211\n",
            "Iteration 26, loss = 0.37757610\n",
            "Iteration 27, loss = 0.37561031\n",
            "Iteration 28, loss = 0.37447469\n",
            "Iteration 29, loss = 0.37219112\n",
            "Iteration 30, loss = 0.36821845\n",
            "Iteration 31, loss = 0.36796951\n",
            "Iteration 32, loss = 0.36620266\n",
            "Iteration 33, loss = 0.36493290\n",
            "Iteration 34, loss = 0.36545348\n",
            "Iteration 35, loss = 0.36402597\n",
            "Iteration 36, loss = 0.36386057\n",
            "Iteration 37, loss = 0.36208109\n",
            "Iteration 38, loss = 0.36256552\n",
            "Iteration 39, loss = 0.35880038\n",
            "Iteration 40, loss = 0.35988235\n",
            "Iteration 41, loss = 0.35771206\n",
            "Iteration 42, loss = 0.35765780\n",
            "Iteration 43, loss = 0.35792523\n",
            "Iteration 44, loss = 0.35732244\n",
            "Iteration 45, loss = 0.35613587\n",
            "Iteration 46, loss = 0.35662046\n",
            "Iteration 47, loss = 0.35425694\n",
            "Iteration 48, loss = 0.35416324\n",
            "Iteration 49, loss = 0.35330117\n",
            "Iteration 50, loss = 0.35174340\n",
            "Iteration 51, loss = 0.35245648\n",
            "Iteration 52, loss = 0.35217903\n",
            "Iteration 53, loss = 0.35270739\n",
            "Iteration 54, loss = 0.35064907\n",
            "Iteration 55, loss = 0.35081482\n",
            "Iteration 56, loss = 0.35254812\n",
            "Iteration 57, loss = 0.35077844\n",
            "Iteration 58, loss = 0.35086777\n",
            "Iteration 59, loss = 0.34999414\n",
            "Iteration 60, loss = 0.34942972\n",
            "Iteration 61, loss = 0.35203026\n",
            "Iteration 62, loss = 0.35108156\n",
            "Iteration 63, loss = 0.35362099\n",
            "Iteration 64, loss = 0.34923691\n",
            "Iteration 65, loss = 0.34808990\n",
            "Iteration 66, loss = 0.34940921\n",
            "Iteration 67, loss = 0.34856890\n",
            "Iteration 68, loss = 0.34707864\n",
            "Iteration 69, loss = 0.34765943\n",
            "Iteration 70, loss = 0.34720468\n",
            "Iteration 71, loss = 0.34706784\n",
            "Iteration 72, loss = 0.34842500\n",
            "Iteration 73, loss = 0.35000088\n",
            "Iteration 74, loss = 0.34839815\n",
            "Iteration 75, loss = 0.34863092\n",
            "Iteration 76, loss = 0.34710689\n",
            "Iteration 77, loss = 0.34704565\n",
            "Iteration 78, loss = 0.34771278\n",
            "Iteration 79, loss = 0.35103220\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.24221567\n",
            "Iteration 2, loss = 5.85414351\n",
            "Iteration 3, loss = 4.38780252\n",
            "Iteration 4, loss = 2.83982233\n",
            "Iteration 5, loss = 1.50239149\n",
            "Iteration 6, loss = 0.53524411\n",
            "Iteration 7, loss = 0.40044506\n",
            "Iteration 8, loss = 0.39778879\n",
            "Iteration 9, loss = 0.39621334\n",
            "Iteration 10, loss = 0.39441386\n",
            "Iteration 11, loss = 0.39196491\n",
            "Iteration 12, loss = 0.39095320\n",
            "Iteration 13, loss = 0.38953303\n",
            "Iteration 14, loss = 0.38809236\n",
            "Iteration 15, loss = 0.38600143\n",
            "Iteration 16, loss = 0.38453530\n",
            "Iteration 17, loss = 0.38319453\n",
            "Iteration 18, loss = 0.38154029\n",
            "Iteration 19, loss = 0.38069211\n",
            "Iteration 20, loss = 0.38012329\n",
            "Iteration 21, loss = 0.37825547\n",
            "Iteration 22, loss = 0.37664531\n",
            "Iteration 23, loss = 0.37557823\n",
            "Iteration 24, loss = 0.37479620\n",
            "Iteration 25, loss = 0.37407952\n",
            "Iteration 26, loss = 0.37217278\n",
            "Iteration 27, loss = 0.37178910\n",
            "Iteration 28, loss = 0.37112090\n",
            "Iteration 29, loss = 0.37065589\n",
            "Iteration 30, loss = 0.36963156\n",
            "Iteration 31, loss = 0.36931823\n",
            "Iteration 32, loss = 0.36846722\n",
            "Iteration 33, loss = 0.36702409\n",
            "Iteration 34, loss = 0.36685409\n",
            "Iteration 35, loss = 0.36814653\n",
            "Iteration 36, loss = 0.36369701\n",
            "Iteration 37, loss = 0.36561032\n",
            "Iteration 38, loss = 0.36300894\n",
            "Iteration 39, loss = 0.36423828\n",
            "Iteration 40, loss = 0.36276247\n",
            "Iteration 41, loss = 0.36282324\n",
            "Iteration 42, loss = 0.36155637\n",
            "Iteration 43, loss = 0.36090225\n",
            "Iteration 44, loss = 0.36058784\n",
            "Iteration 45, loss = 0.36162504\n",
            "Iteration 46, loss = 0.36077676\n",
            "Iteration 47, loss = 0.35949424\n",
            "Iteration 48, loss = 0.35927719\n",
            "Iteration 49, loss = 0.35871356\n",
            "Iteration 50, loss = 0.35912535\n",
            "Iteration 51, loss = 0.35789911\n",
            "Iteration 52, loss = 0.36288455\n",
            "Iteration 53, loss = 0.35771727\n",
            "Iteration 54, loss = 0.35720549\n",
            "Iteration 55, loss = 0.35940699\n",
            "Iteration 56, loss = 0.35642598\n",
            "Iteration 57, loss = 0.35596757\n",
            "Iteration 58, loss = 0.35484246\n",
            "Iteration 59, loss = 0.35597539\n",
            "Iteration 60, loss = 0.35536265\n",
            "Iteration 61, loss = 0.35559226\n",
            "Iteration 62, loss = 0.35507628\n",
            "Iteration 63, loss = 0.35619351\n",
            "Iteration 64, loss = 0.35646272\n",
            "Iteration 65, loss = 0.35417531\n",
            "Iteration 66, loss = 0.35174601\n",
            "Iteration 67, loss = 0.35327894\n",
            "Iteration 68, loss = 0.35328302\n",
            "Iteration 69, loss = 0.35554138\n",
            "Iteration 70, loss = 0.35302721\n",
            "Iteration 71, loss = 0.35299716\n",
            "Iteration 72, loss = 0.35174863\n",
            "Iteration 73, loss = 0.35155382\n",
            "Iteration 74, loss = 0.35003059\n",
            "Iteration 75, loss = 0.35020051\n",
            "Iteration 76, loss = 0.35183661\n",
            "Iteration 77, loss = 0.35146406\n",
            "Iteration 78, loss = 0.34982847\n",
            "Iteration 79, loss = 0.34929788\n",
            "Iteration 80, loss = 0.35075656\n",
            "Iteration 81, loss = 0.35022335\n",
            "Iteration 82, loss = 0.34945245\n",
            "Iteration 83, loss = 0.34821486\n",
            "Iteration 84, loss = 0.35039791\n",
            "Iteration 85, loss = 0.34929915\n",
            "Iteration 86, loss = 0.35394569\n",
            "Iteration 87, loss = 0.34900187\n",
            "Iteration 88, loss = 0.35188102\n",
            "Iteration 89, loss = 0.34708421\n",
            "Iteration 90, loss = 0.34868814\n",
            "Iteration 91, loss = 0.34784580\n",
            "Iteration 92, loss = 0.34625820\n",
            "Iteration 93, loss = 0.34813268\n",
            "Iteration 94, loss = 0.34709446\n",
            "Iteration 95, loss = 0.34768222\n",
            "Iteration 96, loss = 0.34724969\n",
            "Iteration 97, loss = 0.34772424\n",
            "Iteration 98, loss = 0.34872594\n",
            "Iteration 99, loss = 0.34632288\n",
            "Iteration 100, loss = 0.34839110\n",
            "Iteration 101, loss = 0.34735897\n",
            "Iteration 102, loss = 0.35079767\n",
            "Iteration 103, loss = 0.34848840\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.24777477\n",
            "Iteration 2, loss = 5.59146368\n",
            "Iteration 3, loss = 3.84862883\n",
            "Iteration 4, loss = 2.17137590\n",
            "Iteration 5, loss = 0.79549482\n",
            "Iteration 6, loss = 0.40495147\n",
            "Iteration 7, loss = 0.40019397\n",
            "Iteration 8, loss = 0.39770574\n",
            "Iteration 9, loss = 0.39508823\n",
            "Iteration 10, loss = 0.39267316\n",
            "Iteration 11, loss = 0.39048895\n",
            "Iteration 12, loss = 0.38912302\n",
            "Iteration 13, loss = 0.38662161\n",
            "Iteration 14, loss = 0.38517972\n",
            "Iteration 15, loss = 0.38345168\n",
            "Iteration 16, loss = 0.38179886\n",
            "Iteration 17, loss = 0.38047091\n",
            "Iteration 18, loss = 0.37752233\n",
            "Iteration 19, loss = 0.37563021\n",
            "Iteration 20, loss = 0.37272139\n",
            "Iteration 21, loss = 0.37018821\n",
            "Iteration 22, loss = 0.36831133\n",
            "Iteration 23, loss = 0.36684388\n",
            "Iteration 24, loss = 0.36653834\n",
            "Iteration 25, loss = 0.36511050\n",
            "Iteration 26, loss = 0.36264843\n",
            "Iteration 27, loss = 0.36283964\n",
            "Iteration 28, loss = 0.36091768\n",
            "Iteration 29, loss = 0.35938732\n",
            "Iteration 30, loss = 0.35964294\n",
            "Iteration 31, loss = 0.35680027\n",
            "Iteration 32, loss = 0.36012326\n",
            "Iteration 33, loss = 0.35660590\n",
            "Iteration 34, loss = 0.35533203\n",
            "Iteration 35, loss = 0.35581263\n",
            "Iteration 36, loss = 0.35300501\n",
            "Iteration 37, loss = 0.35399574\n",
            "Iteration 38, loss = 0.35355996\n",
            "Iteration 39, loss = 0.35127314\n",
            "Iteration 40, loss = 0.35403824\n",
            "Iteration 41, loss = 0.35018226\n",
            "Iteration 42, loss = 0.34952820\n",
            "Iteration 43, loss = 0.35108642\n",
            "Iteration 44, loss = 0.34914972\n",
            "Iteration 45, loss = 0.35036610\n",
            "Iteration 46, loss = 0.34974993\n",
            "Iteration 47, loss = 0.34910149\n",
            "Iteration 48, loss = 0.34802663\n",
            "Iteration 49, loss = 0.34854713\n",
            "Iteration 50, loss = 0.34724008\n",
            "Iteration 51, loss = 0.34764849\n",
            "Iteration 52, loss = 0.34801493\n",
            "Iteration 53, loss = 0.34699128\n",
            "Iteration 54, loss = 0.34948051\n",
            "Iteration 55, loss = 0.34564057\n",
            "Iteration 56, loss = 0.34550835\n",
            "Iteration 57, loss = 0.34790034\n",
            "Iteration 58, loss = 0.34759704\n",
            "Iteration 59, loss = 0.34446904\n",
            "Iteration 60, loss = 0.34455429\n",
            "Iteration 61, loss = 0.34401174\n",
            "Iteration 62, loss = 0.34686003\n",
            "Iteration 63, loss = 0.34420790\n",
            "Iteration 64, loss = 0.34353899\n",
            "Iteration 65, loss = 0.34617110\n",
            "Iteration 66, loss = 0.34472500\n",
            "Iteration 67, loss = 0.34433428\n",
            "Iteration 68, loss = 0.34471702\n",
            "Iteration 69, loss = 0.34329109\n",
            "Iteration 70, loss = 0.34367878\n",
            "Iteration 71, loss = 0.34884894\n",
            "Iteration 72, loss = 0.34420420\n",
            "Iteration 73, loss = 0.34434253\n",
            "Iteration 74, loss = 0.34390668\n",
            "Iteration 75, loss = 0.34359870\n",
            "Iteration 76, loss = 0.34522858\n",
            "Iteration 77, loss = 0.34529729\n",
            "Iteration 78, loss = 0.34816497\n",
            "Iteration 79, loss = 0.34445491\n",
            "Iteration 80, loss = 0.34386277\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.20468708\n",
            "Iteration 2, loss = 5.31641477\n",
            "Iteration 3, loss = 3.37104403\n",
            "Iteration 4, loss = 1.58691654\n",
            "Iteration 5, loss = 0.46622299\n",
            "Iteration 6, loss = 0.39791210\n",
            "Iteration 7, loss = 0.39580053\n",
            "Iteration 8, loss = 0.39365163\n",
            "Iteration 9, loss = 0.39086763\n",
            "Iteration 10, loss = 0.38833064\n",
            "Iteration 11, loss = 0.38706285\n",
            "Iteration 12, loss = 0.38329963\n",
            "Iteration 13, loss = 0.38175641\n",
            "Iteration 14, loss = 0.37979629\n",
            "Iteration 15, loss = 0.37814041\n",
            "Iteration 16, loss = 0.37691157\n",
            "Iteration 17, loss = 0.37538066\n",
            "Iteration 18, loss = 0.37361142\n",
            "Iteration 19, loss = 0.37248647\n",
            "Iteration 20, loss = 0.37161077\n",
            "Iteration 21, loss = 0.37062730\n",
            "Iteration 22, loss = 0.36936316\n",
            "Iteration 23, loss = 0.36924511\n",
            "Iteration 24, loss = 0.36709215\n",
            "Iteration 25, loss = 0.36537789\n",
            "Iteration 26, loss = 0.36533835\n",
            "Iteration 27, loss = 0.36479743\n",
            "Iteration 28, loss = 0.36546473\n",
            "Iteration 29, loss = 0.36255395\n",
            "Iteration 30, loss = 0.36191382\n",
            "Iteration 31, loss = 0.36449068\n",
            "Iteration 32, loss = 0.36056767\n",
            "Iteration 33, loss = 0.36015310\n",
            "Iteration 34, loss = 0.35946983\n",
            "Iteration 35, loss = 0.35959727\n",
            "Iteration 36, loss = 0.35928295\n",
            "Iteration 37, loss = 0.35778976\n",
            "Iteration 38, loss = 0.35656148\n",
            "Iteration 39, loss = 0.35693283\n",
            "Iteration 40, loss = 0.35602784\n",
            "Iteration 41, loss = 0.36243755\n",
            "Iteration 42, loss = 0.35436563\n",
            "Iteration 43, loss = 0.35512763\n",
            "Iteration 44, loss = 0.35391684\n",
            "Iteration 45, loss = 0.35317384\n",
            "Iteration 46, loss = 0.35232266\n",
            "Iteration 47, loss = 0.35402495\n",
            "Iteration 48, loss = 0.35182397\n",
            "Iteration 49, loss = 0.35144851\n",
            "Iteration 50, loss = 0.35304285\n",
            "Iteration 51, loss = 0.35046478\n",
            "Iteration 52, loss = 0.34999879\n",
            "Iteration 53, loss = 0.34985740\n",
            "Iteration 54, loss = 0.34936400\n",
            "Iteration 55, loss = 0.35019583\n",
            "Iteration 56, loss = 0.34940287\n",
            "Iteration 57, loss = 0.34783094\n",
            "Iteration 58, loss = 0.34871500\n",
            "Iteration 59, loss = 0.34941696\n",
            "Iteration 60, loss = 0.34842775\n",
            "Iteration 61, loss = 0.34912339\n",
            "Iteration 62, loss = 0.34765322\n",
            "Iteration 63, loss = 0.34721512\n",
            "Iteration 64, loss = 0.34771079\n",
            "Iteration 65, loss = 0.34618059\n",
            "Iteration 66, loss = 0.34601087\n",
            "Iteration 67, loss = 0.34509532\n",
            "Iteration 68, loss = 0.34561814\n",
            "Iteration 69, loss = 0.34607162\n",
            "Iteration 70, loss = 0.34470069\n",
            "Iteration 71, loss = 0.34558880\n",
            "Iteration 72, loss = 0.34483682\n",
            "Iteration 73, loss = 0.34379920\n",
            "Iteration 74, loss = 0.34697570\n",
            "Iteration 75, loss = 0.34495678\n",
            "Iteration 76, loss = 0.34410565\n",
            "Iteration 77, loss = 0.34418630\n",
            "Iteration 78, loss = 0.34524629\n",
            "Iteration 79, loss = 0.34500299\n",
            "Iteration 80, loss = 0.34311061\n",
            "Iteration 81, loss = 0.34178173\n",
            "Iteration 82, loss = 0.34257019\n",
            "Iteration 83, loss = 0.34315481\n",
            "Iteration 84, loss = 0.34350333\n",
            "Iteration 85, loss = 0.34317336\n",
            "Iteration 86, loss = 0.34222486\n",
            "Iteration 87, loss = 0.34396095\n",
            "Iteration 88, loss = 0.34326512\n",
            "Iteration 89, loss = 0.34353019\n",
            "Iteration 90, loss = 0.34249392\n",
            "Iteration 91, loss = 0.34218939\n",
            "Iteration 92, loss = 0.34289525\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.12973440\n",
            "Iteration 2, loss = 5.14921072\n",
            "Iteration 3, loss = 3.06948599\n",
            "Iteration 4, loss = 1.24488559\n",
            "Iteration 5, loss = 0.40948419\n",
            "Iteration 6, loss = 0.39504536\n",
            "Iteration 7, loss = 0.39207820\n",
            "Iteration 8, loss = 0.38826077\n",
            "Iteration 9, loss = 0.38577187\n",
            "Iteration 10, loss = 0.38370120\n",
            "Iteration 11, loss = 0.38113465\n",
            "Iteration 12, loss = 0.37954058\n",
            "Iteration 13, loss = 0.37777971\n",
            "Iteration 14, loss = 0.37614341\n",
            "Iteration 15, loss = 0.37389712\n",
            "Iteration 16, loss = 0.37232432\n",
            "Iteration 17, loss = 0.37087507\n",
            "Iteration 18, loss = 0.36919725\n",
            "Iteration 19, loss = 0.36763603\n",
            "Iteration 20, loss = 0.36749431\n",
            "Iteration 21, loss = 0.36586090\n",
            "Iteration 22, loss = 0.36502270\n",
            "Iteration 23, loss = 0.36514113\n",
            "Iteration 24, loss = 0.36296524\n",
            "Iteration 25, loss = 0.36219892\n",
            "Iteration 26, loss = 0.36052957\n",
            "Iteration 27, loss = 0.36026499\n",
            "Iteration 28, loss = 0.36072871\n",
            "Iteration 29, loss = 0.35968938\n",
            "Iteration 30, loss = 0.35872425\n",
            "Iteration 31, loss = 0.35798762\n",
            "Iteration 32, loss = 0.35686917\n",
            "Iteration 33, loss = 0.35622204\n",
            "Iteration 34, loss = 0.35661306\n",
            "Iteration 35, loss = 0.35459598\n",
            "Iteration 36, loss = 0.35580764\n",
            "Iteration 37, loss = 0.35323171\n",
            "Iteration 38, loss = 0.35316987\n",
            "Iteration 39, loss = 0.35254266\n",
            "Iteration 40, loss = 0.35226281\n",
            "Iteration 41, loss = 0.35062740\n",
            "Iteration 42, loss = 0.35080275\n",
            "Iteration 43, loss = 0.35158401\n",
            "Iteration 44, loss = 0.35076969\n",
            "Iteration 45, loss = 0.34994362\n",
            "Iteration 46, loss = 0.34966243\n",
            "Iteration 47, loss = 0.34928693\n",
            "Iteration 48, loss = 0.34802350\n",
            "Iteration 49, loss = 0.35119028\n",
            "Iteration 50, loss = 0.34737381\n",
            "Iteration 51, loss = 0.34800515\n",
            "Iteration 52, loss = 0.34643619\n",
            "Iteration 53, loss = 0.34611725\n",
            "Iteration 54, loss = 0.34605343\n",
            "Iteration 55, loss = 0.34648944\n",
            "Iteration 56, loss = 0.34742700\n",
            "Iteration 57, loss = 0.34672001\n",
            "Iteration 58, loss = 0.34504790\n",
            "Iteration 59, loss = 0.34631068\n",
            "Iteration 60, loss = 0.34307417\n",
            "Iteration 61, loss = 0.34682021\n",
            "Iteration 62, loss = 0.34366982\n",
            "Iteration 63, loss = 0.34307323\n",
            "Iteration 64, loss = 0.34330774\n",
            "Iteration 65, loss = 0.34281449\n",
            "Iteration 66, loss = 0.34300248\n",
            "Iteration 67, loss = 0.34225053\n",
            "Iteration 68, loss = 0.34223322\n",
            "Iteration 69, loss = 0.34292991\n",
            "Iteration 70, loss = 0.34181061\n",
            "Iteration 71, loss = 0.34237354\n",
            "Iteration 72, loss = 0.34211502\n",
            "Iteration 73, loss = 0.34233410\n",
            "Iteration 74, loss = 0.34241336\n",
            "Iteration 75, loss = 0.34157735\n",
            "Iteration 76, loss = 0.34165148\n",
            "Iteration 77, loss = 0.34182148\n",
            "Iteration 78, loss = 0.34376747\n",
            "Iteration 79, loss = 0.34038144\n",
            "Iteration 80, loss = 0.33985359\n",
            "Iteration 81, loss = 0.34120756\n",
            "Iteration 82, loss = 0.34014048\n",
            "Iteration 83, loss = 0.34140110\n",
            "Iteration 84, loss = 0.34011642\n",
            "Iteration 85, loss = 0.34052947\n",
            "Iteration 86, loss = 0.34001562\n",
            "Iteration 87, loss = 0.34102604\n",
            "Iteration 88, loss = 0.34013788\n",
            "Iteration 89, loss = 0.34096137\n",
            "Iteration 90, loss = 0.34085171\n",
            "Iteration 91, loss = 0.33955697\n",
            "Iteration 92, loss = 0.33915056\n",
            "Iteration 93, loss = 0.33971515\n",
            "Iteration 94, loss = 0.34012463\n",
            "Iteration 95, loss = 0.34048238\n",
            "Iteration 96, loss = 0.34176010\n",
            "Iteration 97, loss = 0.34093783\n",
            "Iteration 98, loss = 0.34040123\n",
            "Iteration 99, loss = 0.34261635\n",
            "Iteration 100, loss = 0.33856527\n",
            "Iteration 101, loss = 0.34033037\n",
            "Iteration 102, loss = 0.33885173\n",
            "Iteration 103, loss = 0.34022498\n",
            "Iteration 104, loss = 0.34127936\n",
            "Iteration 105, loss = 0.33865801\n",
            "Iteration 106, loss = 0.33898614\n",
            "Iteration 107, loss = 0.34010316\n",
            "Iteration 108, loss = 0.33966151\n",
            "Iteration 109, loss = 0.33833037\n",
            "Iteration 110, loss = 0.33931457\n",
            "Iteration 111, loss = 0.33860688\n",
            "Iteration 112, loss = 0.33963327\n",
            "Iteration 113, loss = 0.33929273\n",
            "Iteration 114, loss = 0.34072419\n",
            "Iteration 115, loss = 0.33911518\n",
            "Iteration 116, loss = 0.33882565\n",
            "Iteration 117, loss = 0.34021843\n",
            "Iteration 118, loss = 0.34187623\n",
            "Iteration 119, loss = 0.33996449\n",
            "Iteration 120, loss = 0.33981101\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.10743892\n",
            "Iteration 2, loss = 5.05560699\n",
            "Iteration 3, loss = 2.94660885\n",
            "Iteration 4, loss = 1.13317170\n",
            "Iteration 5, loss = 0.40232919\n",
            "Iteration 6, loss = 0.39483006\n",
            "Iteration 7, loss = 0.39299138\n",
            "Iteration 8, loss = 0.38871942\n",
            "Iteration 9, loss = 0.38650760\n",
            "Iteration 10, loss = 0.38449279\n",
            "Iteration 11, loss = 0.38084648\n",
            "Iteration 12, loss = 0.37887276\n",
            "Iteration 13, loss = 0.37670254\n",
            "Iteration 14, loss = 0.37552944\n",
            "Iteration 15, loss = 0.37430573\n",
            "Iteration 16, loss = 0.37150347\n",
            "Iteration 17, loss = 0.37109227\n",
            "Iteration 18, loss = 0.36966302\n",
            "Iteration 19, loss = 0.36835581\n",
            "Iteration 20, loss = 0.36710615\n",
            "Iteration 21, loss = 0.36695074\n",
            "Iteration 22, loss = 0.36477009\n",
            "Iteration 23, loss = 0.36375933\n",
            "Iteration 24, loss = 0.36347373\n",
            "Iteration 25, loss = 0.36242735\n",
            "Iteration 26, loss = 0.36105255\n",
            "Iteration 27, loss = 0.36062407\n",
            "Iteration 28, loss = 0.36002695\n",
            "Iteration 29, loss = 0.35868857\n",
            "Iteration 30, loss = 0.35799963\n",
            "Iteration 31, loss = 0.35677410\n",
            "Iteration 32, loss = 0.35508726\n",
            "Iteration 33, loss = 0.35574187\n",
            "Iteration 34, loss = 0.35475040\n",
            "Iteration 35, loss = 0.35408053\n",
            "Iteration 36, loss = 0.35367838\n",
            "Iteration 37, loss = 0.35195099\n",
            "Iteration 38, loss = 0.35308305\n",
            "Iteration 39, loss = 0.35329323\n",
            "Iteration 40, loss = 0.35435630\n",
            "Iteration 41, loss = 0.35072053\n",
            "Iteration 42, loss = 0.35067024\n",
            "Iteration 43, loss = 0.35051039\n",
            "Iteration 44, loss = 0.35040226\n",
            "Iteration 45, loss = 0.34868197\n",
            "Iteration 46, loss = 0.34767889\n",
            "Iteration 47, loss = 0.34925557\n",
            "Iteration 48, loss = 0.34864417\n",
            "Iteration 49, loss = 0.34734935\n",
            "Iteration 50, loss = 0.34973293\n",
            "Iteration 51, loss = 0.34725005\n",
            "Iteration 52, loss = 0.34633501\n",
            "Iteration 53, loss = 0.34711336\n",
            "Iteration 54, loss = 0.34681215\n",
            "Iteration 55, loss = 0.34527500\n",
            "Iteration 56, loss = 0.34504103\n",
            "Iteration 57, loss = 0.34535223\n",
            "Iteration 58, loss = 0.34496559\n",
            "Iteration 59, loss = 0.34545968\n",
            "Iteration 60, loss = 0.34599870\n",
            "Iteration 61, loss = 0.34434493\n",
            "Iteration 62, loss = 0.34303983\n",
            "Iteration 63, loss = 0.34270626\n",
            "Iteration 64, loss = 0.34392407\n",
            "Iteration 65, loss = 0.34278204\n",
            "Iteration 66, loss = 0.34278727\n",
            "Iteration 67, loss = 0.34292109\n",
            "Iteration 68, loss = 0.34184977\n",
            "Iteration 69, loss = 0.34210218\n",
            "Iteration 70, loss = 0.34197080\n",
            "Iteration 71, loss = 0.34413593\n",
            "Iteration 72, loss = 0.34222834\n",
            "Iteration 73, loss = 0.34095911\n",
            "Iteration 74, loss = 0.34194885\n",
            "Iteration 75, loss = 0.34389484\n",
            "Iteration 76, loss = 0.34096325\n",
            "Iteration 77, loss = 0.34280107\n",
            "Iteration 78, loss = 0.34170428\n",
            "Iteration 79, loss = 0.34201574\n",
            "Iteration 80, loss = 0.34105586\n",
            "Iteration 81, loss = 0.34012719\n",
            "Iteration 82, loss = 0.34125871\n",
            "Iteration 83, loss = 0.34127721\n",
            "Iteration 84, loss = 0.34082575\n",
            "Iteration 85, loss = 0.33931961\n",
            "Iteration 86, loss = 0.34218359\n",
            "Iteration 87, loss = 0.33961847\n",
            "Iteration 88, loss = 0.34031382\n",
            "Iteration 89, loss = 0.34046943\n",
            "Iteration 90, loss = 0.33951054\n",
            "Iteration 91, loss = 0.34071133\n",
            "Iteration 92, loss = 0.33928527\n",
            "Iteration 93, loss = 0.33954983\n",
            "Iteration 94, loss = 0.33950730\n",
            "Iteration 95, loss = 0.34139412\n",
            "Iteration 96, loss = 0.34094115\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 6.10748594\n",
            "Iteration 2, loss = 4.97910264\n",
            "Iteration 3, loss = 2.84138522\n",
            "Iteration 4, loss = 1.03265637\n",
            "Iteration 5, loss = 0.39649624\n",
            "Iteration 6, loss = 0.39240079\n",
            "Iteration 7, loss = 0.38965319\n",
            "Iteration 8, loss = 0.38674349\n",
            "Iteration 9, loss = 0.38417291\n",
            "Iteration 10, loss = 0.38161224\n",
            "Iteration 11, loss = 0.37964720\n",
            "Iteration 12, loss = 0.37623334\n",
            "Iteration 13, loss = 0.37591903\n",
            "Iteration 14, loss = 0.37284013\n",
            "Iteration 15, loss = 0.37034817\n",
            "Iteration 16, loss = 0.36598720\n",
            "Iteration 17, loss = 0.36243947\n",
            "Iteration 18, loss = 0.36049910\n",
            "Iteration 19, loss = 0.35750650\n",
            "Iteration 20, loss = 0.35631173\n",
            "Iteration 21, loss = 0.35678135\n",
            "Iteration 22, loss = 0.35329099\n",
            "Iteration 23, loss = 0.35214809\n",
            "Iteration 24, loss = 0.35064490\n",
            "Iteration 25, loss = 0.34950784\n",
            "Iteration 26, loss = 0.34993954\n",
            "Iteration 27, loss = 0.34866523\n",
            "Iteration 28, loss = 0.34777082\n",
            "Iteration 29, loss = 0.34604296\n",
            "Iteration 30, loss = 0.34776353\n",
            "Iteration 31, loss = 0.34725088\n",
            "Iteration 32, loss = 0.34529482\n",
            "Iteration 33, loss = 0.34422909\n",
            "Iteration 34, loss = 0.34455021\n",
            "Iteration 35, loss = 0.34219232\n",
            "Iteration 36, loss = 0.34287232\n",
            "Iteration 37, loss = 0.34122528\n",
            "Iteration 38, loss = 0.34243460\n",
            "Iteration 39, loss = 0.34100276\n",
            "Iteration 40, loss = 0.34258926\n",
            "Iteration 41, loss = 0.34168225\n",
            "Iteration 42, loss = 0.33939371\n",
            "Iteration 43, loss = 0.33921092\n",
            "Iteration 44, loss = 0.34154113\n",
            "Iteration 45, loss = 0.34120124\n",
            "Iteration 46, loss = 0.34076283\n",
            "Iteration 47, loss = 0.33926167\n",
            "Iteration 48, loss = 0.34082266\n",
            "Iteration 49, loss = 0.33816761\n",
            "Iteration 50, loss = 0.33914747\n",
            "Iteration 51, loss = 0.33752887\n",
            "Iteration 52, loss = 0.33980920\n",
            "Iteration 53, loss = 0.34031128\n",
            "Iteration 54, loss = 0.33854294\n",
            "Iteration 55, loss = 0.33760338\n",
            "Iteration 56, loss = 0.33964062\n",
            "Iteration 57, loss = 0.33959982\n",
            "Iteration 58, loss = 0.34447833\n",
            "Iteration 59, loss = 0.33854761\n",
            "Iteration 60, loss = 0.33890537\n",
            "Iteration 61, loss = 0.34039078\n",
            "Iteration 62, loss = 0.33911104\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sizes_abs"
      ],
      "metadata": {
        "id": "iWeL1DCdwrJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618acc9a-78c6-48c2-bb9d-4968d3e68351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 450,  900, 1351, 1801, 2252, 2702, 3152, 3603, 4053, 4278, 4368,\n",
              "       4458])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_scores"
      ],
      "metadata": {
        "id": "u4BwCVwDwyZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb6fcf0-e8ee-4ef3-bd88-ed6d9f6ec698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.82666667, 0.82222222, 0.82222222, 0.82222222, 0.82222222],\n",
              "       [0.85222222, 0.84      , 0.84      , 0.84      , 0.84      ],\n",
              "       [0.85566247, 0.85936343, 0.84678016, 0.84678016, 0.84678016],\n",
              "       [0.84952804, 0.85563576, 0.85452526, 0.85452526, 0.85452526],\n",
              "       [0.85834813, 0.86012433, 0.86234458, 0.86056838, 0.86056838],\n",
              "       [0.8623242 , 0.85973353, 0.85640266, 0.86343449, 0.86343449],\n",
              "       [0.87024112, 0.86516497, 0.86516497, 0.86294416, 0.86294416],\n",
              "       [0.86400222, 0.87066334, 0.86344713, 0.85983902, 0.86427977],\n",
              "       [0.86454478, 0.86701209, 0.8662719 , 0.86183074, 0.85689613],\n",
              "       [0.86699392, 0.86395512, 0.86979897, 0.86231884, 0.86465638],\n",
              "       [0.86492674, 0.86744505, 0.86378205, 0.86767399, 0.86401099],\n",
              "       [0.86608345, 0.86765366, 0.86810229, 0.86742934, 0.86047555]])"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores"
      ],
      "metadata": {
        "id": "0I4GU48ew734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669816c6-6df2-4d41-dbee-49c9b05de79a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8401421 , 0.84547069, 0.84635879, 0.84547069, 0.8383659 ],\n",
              "       [0.85435169, 0.85968028, 0.86678508, 0.86145648, 0.86056838],\n",
              "       [0.85790409, 0.86589698, 0.86056838, 0.86145648, 0.86056838],\n",
              "       [0.85346359, 0.86767318, 0.85879218, 0.86323268, 0.86589698],\n",
              "       [0.85523979, 0.86056838, 0.86323268, 0.86856128, 0.86944938],\n",
              "       [0.86412078, 0.86056838, 0.86234458, 0.87033748, 0.86944938],\n",
              "       [0.86412078, 0.86234458, 0.86412078, 0.87033748, 0.87122558],\n",
              "       [0.86056838, 0.86856128, 0.86323268, 0.86145648, 0.87655417],\n",
              "       [0.85968028, 0.86323268, 0.86412078, 0.87388988, 0.86767318],\n",
              "       [0.86234458, 0.86056838, 0.86678508, 0.86944938, 0.87122558],\n",
              "       [0.85968028, 0.86145648, 0.86323268, 0.87833037, 0.87300178],\n",
              "       [0.85879218, 0.86412078, 0.86323268, 0.87300178, 0.86856128]])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_scores_mean = np.mean(train_scores, axis=1)\n",
        "train_scores_std = np.std(train_scores, axis=1)\n",
        "test_scores_mean = np.mean(test_scores, axis=1)\n",
        "test_scores_std = np.std(test_scores, axis=1)"
      ],
      "metadata": {
        "id": "sTJjBTbYpeW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.title(\"Curva de Aprendizagem\")\n",
        "plt.xlabel(\"Tamanho do Conjunto de Treinamento\")\n",
        "plt.ylabel(\"Pontuação\")\n",
        "plt.grid()\n",
        "\n",
        "plt.fill_between(train_sizes_abs, train_scores_mean - train_scores_std,\n",
        "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "plt.fill_between(train_sizes_abs, test_scores_mean - test_scores_std,\n",
        "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "plt.plot(train_sizes_abs, train_scores_mean, 'o-', color=\"r\",\n",
        "         label=\"Pontuação de Treinamento\")\n",
        "plt.plot(train_sizes_abs, test_scores_mean, 'o-', color=\"g\",\n",
        "         label=\"Pontuação de Validação Cruzada\")\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W4Lx1IrEpjiR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "34338f4c-1d43-46ea-81ac-ccc1a47495f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que a pontuação da curva de aprendizagem tende a uma estabilização com o aumento do tamanho do conjunto de treinamento da rede, o que expressa que a inclusão de novos dados de treinamento não trará melhoria significativa ao aprendizado de máquina."
      ],
      "metadata": {
        "id": "9YwabKQoH7IW"
      }
    }
  ]
}